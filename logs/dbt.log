2021-04-30 17:16:14.784782 (MainThread): Running with dbt=0.19.1
2021-04-30 17:16:15.742966 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 17:16:15.744298 (MainThread): Tracking: tracking
2021-04-30 17:16:15.744997 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0b7af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0999a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f099ca0>]}
2021-04-30 17:16:15.762557 (MainThread): Partial parsing not enabled
2021-04-30 17:16:15.764657 (MainThread): Parsing macros/catalog.sql
2021-04-30 17:16:15.768277 (MainThread): Parsing macros/adapters.sql
2021-04-30 17:16:15.814380 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 17:16:15.817263 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 17:16:15.820818 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 17:16:15.826164 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 17:16:15.842269 (MainThread): Parsing macros/core.sql
2021-04-30 17:16:15.847602 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 17:16:15.860230 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 17:16:15.863093 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 17:16:15.887820 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 17:16:15.930364 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 17:16:15.959576 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 17:16:15.962332 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 17:16:15.972479 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 17:16:15.993263 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 17:16:16.003063 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 17:16:16.012115 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 17:16:16.020368 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 17:16:16.022029 (MainThread): Parsing macros/etc/query.sql
2021-04-30 17:16:16.023848 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 17:16:16.026562 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 17:16:16.038702 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 17:16:16.042213 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 17:16:16.044566 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 17:16:16.101462 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 17:16:16.104920 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 17:16:16.107929 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 17:16:16.115827 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 17:16:16.127165 (MainThread): Partial parsing not enabled
2021-04-30 17:16:16.158907 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:16:16.172386 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:16:16.334815 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 17:16:16.336340 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'acfe4e4e-b2b8-47de-89f6-9b842da7fef6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d8bdc0>]}
2021-04-30 17:16:16.360228 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'acfe4e4e-b2b8-47de-89f6-9b842da7fef6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d6ecd0>]}
2021-04-30 17:16:16.361133 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 17:16:16.363502 (MainThread): 
2021-04-30 17:16:16.364712 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:16:16.367902 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 17:16:16.409785 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 17:16:16.410002 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 17:16:16.410204 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 17:16:17.443748 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.03 seconds
2021-04-30 17:16:17.448352 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 17:16:17.572161 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-04-30 17:16:17.572542 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-04-30 17:16:17.572772 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-04-30 17:16:17.579040 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-04-30 17:16:17.579204 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-04-30 17:16:17.579316 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-04-30 17:16:18.383912 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.80 seconds
2021-04-30 17:16:18.384263 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-04-30 17:16:18.384475 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-04-30 17:16:18.624556 (ThreadPoolExecutor-0_0): Snowflake query id: 019befec-0400-5bb7-0000-00313e833069
2021-04-30 17:16:18.624991 (ThreadPoolExecutor-0_0): Snowflake error: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
2021-04-30 17:16:18.625503 (ThreadPoolExecutor-0_0): Error running SQL: macro create_schema
2021-04-30 17:16:18.625669 (ThreadPoolExecutor-0_0): Rolling back transaction.
2021-04-30 17:16:18.625817 (ThreadPoolExecutor-0_0): On create_analytics_dbt: ROLLBACK
2021-04-30 17:16:18.703373 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-04-30 17:16:18.839506 (MainThread): Connection 'master' was properly closed.
2021-04-30 17:16:18.839792 (MainThread): Connection 'create_analytics_dbt' was properly closed.
2021-04-30 17:16:18.840035 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c7d580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c53370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e25460>]}
2021-04-30 17:16:18.840399 (MainThread): Flushing usage events
2021-04-30 17:16:19.530956 (MainThread): Encountered an error:
2021-04-30 17:16:19.531277 (MainThread): Database Error
  003041 (42710): SQL compilation error:
  Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
2021-04-30 17:16:19.630548 (MainThread): Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 162, in exception_handler
    yield
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 603, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 125, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 85, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/runnable.py", line 538, in create_schemas
    create_future.result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/runnable.py", line 500, in create_schema
    adapter.create_schema(relation)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/impl.py", line 182, in create_schema
    self.execute_macro(CREATE_SCHEMA_MACRO_NAME, kwargs=kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 1002, in execute_macro
    result = macro_function(**kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 28, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 314, in add_query
    connection, cursor = super().add_query(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 179, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  003041 (42710): SQL compilation error:
  Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.

2021-04-30 17:18:33.624631 (MainThread): Running with dbt=0.19.1
2021-04-30 17:18:34.584923 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 17:18:34.586347 (MainThread): Tracking: tracking
2021-04-30 17:18:34.586697 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105461fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106402c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106402d00>]}
2021-04-30 17:18:34.599866 (MainThread): Partial parsing not enabled
2021-04-30 17:18:34.601561 (MainThread): Parsing macros/catalog.sql
2021-04-30 17:18:34.604574 (MainThread): Parsing macros/adapters.sql
2021-04-30 17:18:34.640988 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 17:18:34.643664 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 17:18:34.646176 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 17:18:34.652346 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 17:18:34.665373 (MainThread): Parsing macros/core.sql
2021-04-30 17:18:34.670928 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 17:18:34.682268 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 17:18:34.685182 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 17:18:34.706241 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 17:18:34.751978 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 17:18:34.777004 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 17:18:34.779704 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 17:18:34.787986 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 17:18:34.804915 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 17:18:34.814018 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 17:18:34.823946 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 17:18:34.830402 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 17:18:34.831874 (MainThread): Parsing macros/etc/query.sql
2021-04-30 17:18:34.833574 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 17:18:34.835868 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 17:18:34.846355 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 17:18:34.849507 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 17:18:34.852201 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 17:18:34.907904 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 17:18:34.910706 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 17:18:34.913101 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 17:18:34.916036 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 17:18:34.925359 (MainThread): Partial parsing not enabled
2021-04-30 17:18:34.952684 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:18:34.964820 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:18:35.047722 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 17:18:35.048136 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7476c19-97d3-4645-a235-42b555d75a43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108141f70>]}
2021-04-30 17:18:35.053243 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7476c19-97d3-4645-a235-42b555d75a43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803c670>]}
2021-04-30 17:18:35.053508 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 17:18:35.054300 (MainThread): 
2021-04-30 17:18:35.054796 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:18:35.055601 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 17:18:35.070043 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 17:18:35.070187 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 17:18:35.070276 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 17:18:36.091914 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.02 seconds
2021-04-30 17:18:36.097459 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 17:18:36.215535 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 17:18:36.224614 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 17:18:36.224778 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 17:18:36.224893 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 17:18:36.780557 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.56 seconds
2021-04-30 17:18:36.781123 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 17:18:36.900770 (MainThread): Using snowflake connection "master".
2021-04-30 17:18:36.900975 (MainThread): On master: BEGIN
2021-04-30 17:18:36.901100 (MainThread): Opening a new connection, currently in state init
2021-04-30 17:18:37.731708 (MainThread): SQL status: SUCCESS 1 in 0.83 seconds
2021-04-30 17:18:37.731917 (MainThread): On master: COMMIT
2021-04-30 17:18:37.732100 (MainThread): Using snowflake connection "master".
2021-04-30 17:18:37.732199 (MainThread): On master: COMMIT
2021-04-30 17:18:37.974888 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-04-30 17:18:37.975205 (MainThread): On master: Close
2021-04-30 17:18:38.119549 (MainThread): 10:18:38 | Concurrency: 1 threads (target='dev')
2021-04-30 17:18:38.119740 (MainThread): 10:18:38 | 
2021-04-30 17:18:38.120857 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 17:18:38.121162 (Thread-1): 10:18:38 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 17:18:38.121463 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:18:38.121586 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 17:18:38.124361 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 17:18:38.125055 (Thread-1): finished collecting timing info
2021-04-30 17:18:38.155481 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 17:18:38.156920 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:18:38.157060 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 17:18:38.157153 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 17:18:39.227082 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2021-04-30 17:18:39.227362 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:18:39.227524 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 17:18:39.363544 (Thread-1): Snowflake query id: 019befee-0400-5bb7-0000-00313e83309d
2021-04-30 17:18:39.363772 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-04-30 17:18:39.364063 (Thread-1): finished collecting timing info
2021-04-30 17:18:39.364286 (Thread-1): On model.learn_dbt.my_first_dbt_model: ROLLBACK
2021-04-30 17:18:39.664616 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 17:18:39.801496 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 162, in exception_handler
    yield
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 603, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 125, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 85, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 314, in add_query
    connection, cursor = super().add_query(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 179, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
2021-04-30 17:18:39.864404 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7476c19-97d3-4645-a235-42b555d75a43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10812e550>]}
2021-04-30 17:18:39.864896 (Thread-1): 10:18:39 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 1.74s]
2021-04-30 17:18:39.865062 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 17:18:39.865860 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 17:18:39.866057 (Thread-1): 10:18:39 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-04-30 17:18:39.866192 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 17:18:39.867209 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:18:39.867450 (MainThread): Using snowflake connection "master".
2021-04-30 17:18:39.867541 (MainThread): On master: BEGIN
2021-04-30 17:18:39.867626 (MainThread): Opening a new connection, currently in state closed
2021-04-30 17:18:40.695077 (MainThread): SQL status: SUCCESS 1 in 0.83 seconds
2021-04-30 17:18:40.695380 (MainThread): On master: COMMIT
2021-04-30 17:18:40.695590 (MainThread): Using snowflake connection "master".
2021-04-30 17:18:40.695709 (MainThread): On master: COMMIT
2021-04-30 17:18:40.990899 (MainThread): SQL status: SUCCESS 1 in 0.30 seconds
2021-04-30 17:18:40.991113 (MainThread): On master: Close
2021-04-30 17:18:41.116581 (MainThread): 10:18:41 | 
2021-04-30 17:18:41.116793 (MainThread): 10:18:41 | Finished running 1 table model, 1 view model in 6.06s.
2021-04-30 17:18:41.116943 (MainThread): Connection 'master' was properly closed.
2021-04-30 17:18:41.117035 (MainThread): Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
2021-04-30 17:18:41.121840 (MainThread): 
2021-04-30 17:18:41.122006 (MainThread): Completed with 1 error and 0 warnings:
2021-04-30 17:18:41.122114 (MainThread): 
2021-04-30 17:18:41.122218 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 17:18:41.122407 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-04-30 17:18:41.122591 (MainThread):   
2021-04-30 17:18:41.122782 (MainThread):   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
2021-04-30 17:18:41.122953 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-04-30 17:18:41.123139 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108011400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10812e4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10812e820>]}
2021-04-30 17:18:41.123345 (MainThread): Flushing usage events
2021-04-30 17:20:49.745211 (MainThread): Running with dbt=0.19.1
2021-04-30 17:20:50.697072 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 17:20:50.698296 (MainThread): Tracking: tracking
2021-04-30 17:20:50.698720 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e1b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e1be0>]}
2021-04-30 17:20:50.715855 (MainThread): Partial parsing not enabled
2021-04-30 17:20:50.717918 (MainThread): Parsing macros/catalog.sql
2021-04-30 17:20:50.724486 (MainThread): Parsing macros/adapters.sql
2021-04-30 17:20:50.765018 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 17:20:50.767812 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 17:20:50.770879 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 17:20:50.776702 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 17:20:50.791620 (MainThread): Parsing macros/core.sql
2021-04-30 17:20:50.796819 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 17:20:50.809074 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 17:20:50.812001 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 17:20:50.835682 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 17:20:50.880875 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 17:20:50.907266 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 17:20:50.910088 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 17:20:50.918404 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 17:20:50.941804 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 17:20:50.958140 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 17:20:50.967461 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 17:20:50.975287 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 17:20:50.976958 (MainThread): Parsing macros/etc/query.sql
2021-04-30 17:20:50.978800 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 17:20:50.981862 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 17:20:50.995457 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 17:20:50.998867 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 17:20:51.001806 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 17:20:51.059004 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 17:20:51.061967 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 17:20:51.064709 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 17:20:51.067786 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 17:20:51.078121 (MainThread): Partial parsing not enabled
2021-04-30 17:20:51.106694 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:20:51.118388 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:20:51.202723 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 17:20:51.203381 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c78178c-fb66-4801-9b45-fc85e96e6b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d30bd60>]}
2021-04-30 17:20:51.209525 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c78178c-fb66-4801-9b45-fc85e96e6b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2de1c0>]}
2021-04-30 17:20:51.209858 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 17:20:51.210756 (MainThread): 
2021-04-30 17:20:51.211099 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:20:51.211934 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 17:20:51.231163 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 17:20:51.231380 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 17:20:51.231481 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 17:20:52.553080 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.32 seconds
2021-04-30 17:20:52.558888 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 17:20:52.708140 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-04-30 17:20:52.708484 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-04-30 17:20:52.708669 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-04-30 17:20:52.714689 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-04-30 17:20:52.714861 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-04-30 17:20:52.714973 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-04-30 17:20:53.263086 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.55 seconds
2021-04-30 17:20:53.263266 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-04-30 17:20:53.263356 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-04-30 17:20:53.485651 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.22 seconds
2021-04-30 17:20:53.487052 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-04-30 17:20:53.487336 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-04-30 17:20:53.487434 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-04-30 17:20:53.661620 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.17 seconds
2021-04-30 17:20:53.661875 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-04-30 17:20:53.777036 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 17:20:53.786540 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 17:20:53.786912 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 17:20:53.787120 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 17:20:54.644948 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.86 seconds
2021-04-30 17:20:54.645363 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 17:20:54.764090 (MainThread): Using snowflake connection "master".
2021-04-30 17:20:54.764292 (MainThread): On master: BEGIN
2021-04-30 17:20:54.764416 (MainThread): Opening a new connection, currently in state init
2021-04-30 17:20:55.309807 (MainThread): SQL status: SUCCESS 1 in 0.55 seconds
2021-04-30 17:20:55.310101 (MainThread): On master: COMMIT
2021-04-30 17:20:55.310371 (MainThread): Using snowflake connection "master".
2021-04-30 17:20:55.310559 (MainThread): On master: COMMIT
2021-04-30 17:20:55.665804 (MainThread): SQL status: SUCCESS 1 in 0.35 seconds
2021-04-30 17:20:55.666060 (MainThread): On master: Close
2021-04-30 17:20:55.802632 (MainThread): 10:20:55 | Concurrency: 1 threads (target='dev')
2021-04-30 17:20:55.802911 (MainThread): 10:20:55 | 
2021-04-30 17:20:55.804950 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 17:20:55.805370 (Thread-1): 10:20:55 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 17:20:55.805903 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:20:55.806086 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 17:20:55.809166 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 17:20:55.809796 (Thread-1): finished collecting timing info
2021-04-30 17:20:55.847971 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 17:20:55.849255 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:20:55.849377 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 17:20:55.849472 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 17:20:56.433233 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2021-04-30 17:20:56.433443 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:20:56.433615 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 17:20:56.888396 (Thread-1): Snowflake query id: 019beff0-0400-5b63-0000-00313e8340a9
2021-04-30 17:20:56.888572 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-04-30 17:20:56.888747 (Thread-1): finished collecting timing info
2021-04-30 17:20:56.888908 (Thread-1): On model.learn_dbt.my_first_dbt_model: ROLLBACK
2021-04-30 17:20:57.213446 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 17:20:57.350551 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 162, in exception_handler
    yield
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 603, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 125, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 85, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 314, in add_query
    connection, cursor = super().add_query(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 179, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
2021-04-30 17:20:57.426158 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c78178c-fb66-4801-9b45-fc85e96e6b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d331d30>]}
2021-04-30 17:20:57.426507 (Thread-1): 10:20:57 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 1.62s]
2021-04-30 17:20:57.426640 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 17:20:57.427356 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 17:20:57.427573 (Thread-1): 10:20:57 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-04-30 17:20:57.427781 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 17:20:57.428665 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:20:57.428865 (MainThread): Using snowflake connection "master".
2021-04-30 17:20:57.428947 (MainThread): On master: BEGIN
2021-04-30 17:20:57.429025 (MainThread): Opening a new connection, currently in state closed
2021-04-30 17:20:58.321466 (MainThread): SQL status: SUCCESS 1 in 0.89 seconds
2021-04-30 17:20:58.321710 (MainThread): On master: COMMIT
2021-04-30 17:20:58.321917 (MainThread): Using snowflake connection "master".
2021-04-30 17:20:58.322035 (MainThread): On master: COMMIT
2021-04-30 17:20:58.649967 (MainThread): SQL status: SUCCESS 1 in 0.33 seconds
2021-04-30 17:20:58.650277 (MainThread): On master: Close
2021-04-30 17:20:58.755529 (MainThread): 10:20:58 | 
2021-04-30 17:20:58.755765 (MainThread): 10:20:58 | Finished running 1 table model, 1 view model in 7.54s.
2021-04-30 17:20:58.755918 (MainThread): Connection 'master' was properly closed.
2021-04-30 17:20:58.756029 (MainThread): Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
2021-04-30 17:20:58.761496 (MainThread): 
2021-04-30 17:20:58.761691 (MainThread): Completed with 1 error and 0 warnings:
2021-04-30 17:20:58.761826 (MainThread): 
2021-04-30 17:20:58.761963 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 17:20:58.762082 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-04-30 17:20:58.762191 (MainThread):   
2021-04-30 17:20:58.762304 (MainThread):   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
2021-04-30 17:20:58.762419 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-04-30 17:20:58.762627 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cad8730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cad8340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cad8070>]}
2021-04-30 17:20:58.762863 (MainThread): Flushing usage events
2021-04-30 17:23:29.396968 (MainThread): Running with dbt=0.19.1
2021-04-30 17:23:30.462456 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 17:23:30.464200 (MainThread): Tracking: tracking
2021-04-30 17:23:30.464610 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d93caf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8e3bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8e3c70>]}
2021-04-30 17:23:30.477939 (MainThread): Partial parsing not enabled
2021-04-30 17:23:30.479736 (MainThread): Parsing macros/catalog.sql
2021-04-30 17:23:30.483228 (MainThread): Parsing macros/adapters.sql
2021-04-30 17:23:30.519213 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 17:23:30.522144 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 17:23:30.524396 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 17:23:30.529118 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 17:23:30.545735 (MainThread): Parsing macros/core.sql
2021-04-30 17:23:30.550552 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 17:23:30.561198 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 17:23:30.564121 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 17:23:30.585220 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 17:23:30.622950 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 17:23:30.650765 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 17:23:30.653485 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 17:23:30.660942 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 17:23:30.678319 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 17:23:30.686592 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 17:23:30.694321 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 17:23:30.700839 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 17:23:30.702821 (MainThread): Parsing macros/etc/query.sql
2021-04-30 17:23:30.704842 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 17:23:30.707560 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 17:23:30.718299 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 17:23:30.722446 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 17:23:30.725823 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 17:23:30.777901 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 17:23:30.780888 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 17:23:30.783361 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 17:23:30.786029 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 17:23:30.794567 (MainThread): Partial parsing not enabled
2021-04-30 17:23:30.823459 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:23:30.835383 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:23:30.913934 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82f9d2c2-58b3-4b41-ac04-46c2f2774bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11060ddc0>]}
2021-04-30 17:23:30.919612 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82f9d2c2-58b3-4b41-ac04-46c2f2774bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105f1cd0>]}
2021-04-30 17:23:30.919903 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 17:23:30.921080 (MainThread): 
2021-04-30 17:23:30.921608 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:23:30.922446 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 17:23:30.936274 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 17:23:30.936443 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 17:23:30.936528 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 17:23:31.887761 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 0.95 seconds
2021-04-30 17:23:31.892818 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 17:23:32.018277 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 17:23:32.027270 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 17:23:32.027499 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 17:23:32.027622 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 17:23:33.531444 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.50 seconds
2021-04-30 17:23:33.532120 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 17:23:33.736370 (MainThread): Using snowflake connection "master".
2021-04-30 17:23:33.736567 (MainThread): On master: BEGIN
2021-04-30 17:23:33.736693 (MainThread): Opening a new connection, currently in state init
2021-04-30 17:23:34.709324 (MainThread): SQL status: SUCCESS 1 in 0.97 seconds
2021-04-30 17:23:34.709621 (MainThread): On master: COMMIT
2021-04-30 17:23:34.709885 (MainThread): Using snowflake connection "master".
2021-04-30 17:23:34.710034 (MainThread): On master: COMMIT
2021-04-30 17:23:34.999007 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2021-04-30 17:23:34.999259 (MainThread): On master: Close
2021-04-30 17:23:35.116874 (MainThread): 10:23:35 | Concurrency: 1 threads (target='dev')
2021-04-30 17:23:35.117090 (MainThread): 10:23:35 | 
2021-04-30 17:23:35.118438 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 17:23:35.118871 (Thread-1): 10:23:35 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 17:23:35.119232 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:23:35.119373 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 17:23:35.122239 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 17:23:35.128664 (Thread-1): finished collecting timing info
2021-04-30 17:23:35.163073 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 17:23:35.164170 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:23:35.164264 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 17:23:35.164345 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 17:23:35.901401 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2021-04-30 17:23:35.901679 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:23:35.901832 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 17:23:38.184981 (Thread-1): SQL status: SUCCESS 1 in 2.28 seconds
2021-04-30 17:23:38.186551 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 17:23:38.186772 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 17:23:38.186896 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 17:23:38.652995 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2021-04-30 17:23:38.667755 (Thread-1): finished collecting timing info
2021-04-30 17:23:38.668001 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 17:23:39.082219 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82f9d2c2-58b3-4b41-ac04-46c2f2774bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106219d0>]}
2021-04-30 17:23:39.082706 (Thread-1): 10:23:39 | 1 of 2 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 3.96s]
2021-04-30 17:23:39.082888 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 17:23:39.083568 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 17:23:39.084148 (Thread-1): 10:23:39 | 2 of 2 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 17:23:39.084689 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:23:39.084839 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 17:23:39.087921 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 17:23:39.088527 (Thread-1): finished collecting timing info
2021-04-30 17:23:39.115977 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 17:23:39.116903 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:23:39.117013 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 17:23:39.117108 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 17:23:40.505301 (Thread-1): SQL status: SUCCESS 1 in 1.39 seconds
2021-04-30 17:23:40.505578 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:23:40.505736 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 17:23:40.958915 (Thread-1): SQL status: SUCCESS 1 in 0.45 seconds
2021-04-30 17:23:40.960588 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 17:23:40.960814 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 17:23:40.960936 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 17:23:41.243561 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2021-04-30 17:23:41.245052 (Thread-1): finished collecting timing info
2021-04-30 17:23:41.245294 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 17:23:41.366668 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82f9d2c2-58b3-4b41-ac04-46c2f2774bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104478b0>]}
2021-04-30 17:23:41.367146 (Thread-1): 10:23:41 | 2 of 2 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.28s]
2021-04-30 17:23:41.367319 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 17:23:41.368907 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 17:23:41.369203 (MainThread): Using snowflake connection "master".
2021-04-30 17:23:41.369329 (MainThread): On master: BEGIN
2021-04-30 17:23:41.369431 (MainThread): Opening a new connection, currently in state closed
2021-04-30 17:23:42.002164 (MainThread): SQL status: SUCCESS 1 in 0.63 seconds
2021-04-30 17:23:42.002403 (MainThread): On master: COMMIT
2021-04-30 17:23:42.002613 (MainThread): Using snowflake connection "master".
2021-04-30 17:23:42.002729 (MainThread): On master: COMMIT
2021-04-30 17:23:42.216624 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-04-30 17:23:42.216992 (MainThread): On master: Close
2021-04-30 17:23:42.349186 (MainThread): 10:23:42 | 
2021-04-30 17:23:42.349429 (MainThread): 10:23:42 | Finished running 1 table model, 1 view model in 11.43s.
2021-04-30 17:23:42.349585 (MainThread): Connection 'master' was properly closed.
2021-04-30 17:23:42.349693 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 17:23:42.355171 (MainThread): 
2021-04-30 17:23:42.355364 (MainThread): Completed successfully
2021-04-30 17:23:42.355504 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-04-30 17:23:42.355746 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11066ef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110539670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105398b0>]}
2021-04-30 17:23:42.355980 (MainThread): Flushing usage events
2021-04-30 18:16:12.646792 (MainThread): Running with dbt=0.19.1
2021-04-30 18:16:13.672866 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:16:13.674138 (MainThread): Tracking: tracking
2021-04-30 18:16:13.674882 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b45f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b2ac10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b2acd0>]}
2021-04-30 18:16:13.694149 (MainThread): Partial parsing not enabled
2021-04-30 18:16:13.695990 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:16:13.699365 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:16:13.742487 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:16:13.746200 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:16:13.748659 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:16:13.754229 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:16:13.770414 (MainThread): Parsing macros/core.sql
2021-04-30 18:16:13.775766 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:16:13.807991 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:16:13.812815 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:16:13.847727 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:16:13.905031 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:16:13.937124 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:16:13.940170 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:16:13.950011 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:16:13.969939 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:16:13.980219 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:16:13.990353 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:16:14.001269 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:16:14.003395 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:16:14.005468 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:16:14.008158 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:16:14.020487 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:16:14.024102 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:16:14.027323 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:16:14.086010 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:16:14.090535 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:16:14.094130 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:16:14.097251 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:16:14.106680 (MainThread): Partial parsing not enabled
2021-04-30 18:16:14.136359 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:16:14.151087 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:16:14.158045 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:16:14.258016 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:16:14.258580 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb2987a3-9c67-4a8a-b82f-20510aa0d0e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11397dd00>]}
2021-04-30 18:16:14.267195 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb2987a3-9c67-4a8a-b82f-20510aa0d0e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11396aeb0>]}
2021-04-30 18:16:14.267581 (MainThread): Found 3 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:16:14.268700 (MainThread): 
2021-04-30 18:16:14.269087 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:16:14.270309 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:16:14.287561 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:16:14.287874 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:16:14.288061 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:16:16.088649 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.80 seconds
2021-04-30 18:16:16.093695 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:16:16.216183 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:16:16.224785 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:16:16.224968 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:16:16.225088 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:16:16.883550 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 2 in 0.66 seconds
2021-04-30 18:16:16.884983 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:16:17.009218 (MainThread): Using snowflake connection "master".
2021-04-30 18:16:17.009477 (MainThread): On master: BEGIN
2021-04-30 18:16:17.009635 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:16:17.774415 (MainThread): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 18:16:17.774781 (MainThread): On master: COMMIT
2021-04-30 18:16:17.775031 (MainThread): Using snowflake connection "master".
2021-04-30 18:16:17.775163 (MainThread): On master: COMMIT
2021-04-30 18:16:18.070619 (MainThread): SQL status: SUCCESS 1 in 0.30 seconds
2021-04-30 18:16:18.070936 (MainThread): On master: Close
2021-04-30 18:16:18.192936 (MainThread): 11:16:18 | Concurrency: 1 threads (target='dev')
2021-04-30 18:16:18.193195 (MainThread): 11:16:18 | 
2021-04-30 18:16:18.194737 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:16:18.195156 (Thread-1): 11:16:18 | 1 of 3 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 18:16:18.195577 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:16:18.195731 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:16:18.198826 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:16:18.205102 (Thread-1): finished collecting timing info
2021-04-30 18:16:18.242877 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:16:18.245548 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:16:18.245719 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:16:18.245824 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:16:18.978104 (Thread-1): SQL status: SUCCESS 1 in 0.73 seconds
2021-04-30 18:16:18.978584 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:16:18.978793 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 18:16:19.850782 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2021-04-30 18:16:19.852650 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:16:19.852917 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:16:19.853052 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:16:19.959624 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2021-04-30 18:16:19.972467 (Thread-1): finished collecting timing info
2021-04-30 18:16:19.972686 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:16:20.154290 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb2987a3-9c67-4a8a-b82f-20510aa0d0e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111af8490>]}
2021-04-30 18:16:20.154810 (Thread-1): 11:16:20 | 1 of 3 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 1.96s]
2021-04-30 18:16:20.155009 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:16:20.155207 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:16:20.155509 (Thread-1): 11:16:20 | 2 of 3 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 18:16:20.156323 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:16:20.156530 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:16:20.160185 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:16:20.160700 (Thread-1): finished collecting timing info
2021-04-30 18:16:20.162818 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:16:20.164091 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:16:20.164220 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:16:20.164334 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:16:20.831299 (Thread-1): SQL status: SUCCESS 1 in 0.67 seconds
2021-04-30 18:16:20.831592 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:16:20.831752 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (

SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey;
2021-04-30 18:16:20.928495 (Thread-1): Snowflake query id: 019bf028-0400-5bdb-0000-00313e8390b9
2021-04-30 18:16:20.928852 (Thread-1): Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 12 at position 45 unexpected ';'.
2021-04-30 18:16:20.929193 (Thread-1): finished collecting timing info
2021-04-30 18:16:20.929439 (Thread-1): On model.learn_dbt.sf_customer_purchases: ROLLBACK
2021-04-30 18:16:21.174309 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:16:21.306524 (Thread-1): Database Error in model sf_customer_purchases (models/example/sf_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 12 at position 45 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/sf_customer_purchases.sql
Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 162, in exception_handler
    yield
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 603, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 125, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 85, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 12 at position 45 unexpected ';'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 314, in add_query
    connection, cursor = super().add_query(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 179, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model sf_customer_purchases (models/example/sf_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 12 at position 45 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/sf_customer_purchases.sql
2021-04-30 18:16:21.380886 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb2987a3-9c67-4a8a-b82f-20510aa0d0e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113920d00>]}
2021-04-30 18:16:21.381276 (Thread-1): 11:16:21 | 2 of 3 ERROR creating table model dbt.sf_customer_purchases.......... [ERROR in 1.22s]
2021-04-30 18:16:21.381427 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:16:21.381626 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:16:21.381919 (Thread-1): 11:16:21 | 3 of 3 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:16:21.382500 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:16:21.382639 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:16:21.385152 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:16:21.386150 (Thread-1): finished collecting timing info
2021-04-30 18:16:21.406046 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:16:21.407681 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:16:21.407834 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:16:21.407931 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:16:22.090962 (Thread-1): SQL status: SUCCESS 1 in 0.68 seconds
2021-04-30 18:16:22.091258 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:16:22.091425 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:16:22.486628 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2021-04-30 18:16:22.488345 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:16:22.488586 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:16:22.488715 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:16:22.618157 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:16:22.619328 (Thread-1): finished collecting timing info
2021-04-30 18:16:22.619646 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:16:22.858549 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb2987a3-9c67-4a8a-b82f-20510aa0d0e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131e5160>]}
2021-04-30 18:16:22.859084 (Thread-1): 11:16:22 | 3 of 3 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.48s]
2021-04-30 18:16:22.859292 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:16:22.860722 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:16:22.860983 (MainThread): Using snowflake connection "master".
2021-04-30 18:16:22.861094 (MainThread): On master: BEGIN
2021-04-30 18:16:22.861197 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:16:23.641862 (MainThread): SQL status: SUCCESS 1 in 0.78 seconds
2021-04-30 18:16:23.642046 (MainThread): On master: COMMIT
2021-04-30 18:16:23.642202 (MainThread): Using snowflake connection "master".
2021-04-30 18:16:23.642289 (MainThread): On master: COMMIT
2021-04-30 18:16:23.901953 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 18:16:23.902143 (MainThread): On master: Close
2021-04-30 18:16:24.039351 (MainThread): 11:16:24 | 
2021-04-30 18:16:24.039539 (MainThread): 11:16:24 | Finished running 2 table models, 1 view model in 9.77s.
2021-04-30 18:16:24.039652 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:16:24.039732 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:16:24.045083 (MainThread): 
2021-04-30 18:16:24.045254 (MainThread): Completed with 1 error and 0 warnings:
2021-04-30 18:16:24.045383 (MainThread): 
2021-04-30 18:16:24.045557 (MainThread): Database Error in model sf_customer_purchases (models/example/sf_customer_purchases.sql)
2021-04-30 18:16:24.045672 (MainThread):   001003 (42000): SQL compilation error:
2021-04-30 18:16:24.045775 (MainThread):   syntax error line 12 at position 45 unexpected ';'.
2021-04-30 18:16:24.045912 (MainThread):   compiled SQL at target/run/learn_dbt/models/example/sf_customer_purchases.sql
2021-04-30 18:16:24.046081 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-04-30 18:16:24.046360 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113810400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11399a370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11399a9d0>]}
2021-04-30 18:16:24.046583 (MainThread): Flushing usage events
2021-04-30 18:18:02.407377 (MainThread): Running with dbt=0.19.1
2021-04-30 18:18:03.329777 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:18:03.330966 (MainThread): Tracking: tracking
2021-04-30 18:18:03.331326 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104939dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105902a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105902eb0>]}
2021-04-30 18:18:03.344285 (MainThread): Partial parsing not enabled
2021-04-30 18:18:03.345735 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:18:03.349355 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:18:03.388161 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:18:03.391063 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:18:03.393587 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:18:03.398596 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:18:03.411410 (MainThread): Parsing macros/core.sql
2021-04-30 18:18:03.416450 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:18:03.427305 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:18:03.430761 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:18:03.453760 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:18:03.495964 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:18:03.521023 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:18:03.525434 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:18:03.535247 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:18:03.552723 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:18:03.561956 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:18:03.570398 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:18:03.577297 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:18:03.579142 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:18:03.581254 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:18:03.583843 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:18:03.594857 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:18:03.597847 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:18:03.600573 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:18:03.652889 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:18:03.655831 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:18:03.658148 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:18:03.660645 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:18:03.669681 (MainThread): Partial parsing not enabled
2021-04-30 18:18:03.701067 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:03.712717 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:03.718325 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:03.801513 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example

2021-04-30 18:18:03.801966 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '84c3eca4-88a3-4967-bc6d-ed07f25c98f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107640190>]}
2021-04-30 18:18:03.807399 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '84c3eca4-88a3-4967-bc6d-ed07f25c98f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076223d0>]}
2021-04-30 18:18:03.807676 (MainThread): Found 3 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:18:03.808549 (MainThread): 
2021-04-30 18:18:03.808913 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:18:03.810022 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:18:03.824606 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:18:03.824774 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:18:03.824865 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:18:05.091798 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.27 seconds
2021-04-30 18:18:05.096805 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:18:05.233508 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:18:05.242462 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:18:05.242657 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:18:05.242790 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:18:06.024340 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 2 in 0.78 seconds
2021-04-30 18:18:06.025508 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:18:06.183040 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:06.183275 (MainThread): On master: BEGIN
2021-04-30 18:18:06.183414 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:18:07.436570 (MainThread): SQL status: SUCCESS 1 in 1.25 seconds
2021-04-30 18:18:07.436877 (MainThread): On master: COMMIT
2021-04-30 18:18:07.437171 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:07.437298 (MainThread): On master: COMMIT
2021-04-30 18:18:07.686143 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-04-30 18:18:07.686457 (MainThread): On master: Close
2021-04-30 18:18:07.797288 (MainThread): 11:18:07 | Concurrency: 1 threads (target='dev')
2021-04-30 18:18:07.797547 (MainThread): 11:18:07 | 
2021-04-30 18:18:07.799149 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:18:07.799559 (Thread-1): 11:18:07 | 1 of 3 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 18:18:07.799972 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:07.800129 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:18:07.803257 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:18:07.803850 (Thread-1): finished collecting timing info
2021-04-30 18:18:07.840926 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:18:07.842083 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:07.842210 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:18:07.842308 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:18:08.541106 (Thread-1): SQL status: SUCCESS 1 in 0.70 seconds
2021-04-30 18:18:08.541409 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:08.541574 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 18:18:09.548881 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-04-30 18:18:09.550424 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:18:09.550664 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:09.550790 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:18:09.676846 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:18:09.690300 (Thread-1): finished collecting timing info
2021-04-30 18:18:09.690532 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:18:09.798642 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84c3eca4-88a3-4967-bc6d-ed07f25c98f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107402eb0>]}
2021-04-30 18:18:09.799179 (Thread-1): 11:18:09 | 1 of 3 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 2.00s]
2021-04-30 18:18:09.799378 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:18:09.799573 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:18:09.800440 (Thread-1): 11:18:09 | 2 of 3 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 18:18:09.801161 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:09.801404 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:18:09.805305 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:18:09.805923 (Thread-1): finished collecting timing info
2021-04-30 18:18:09.807939 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:18:09.809838 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:09.810025 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:18:09.810200 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:18:10.648792 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-04-30 18:18:10.649099 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:10.649226 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (

SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 18:18:13.405576 (Thread-1): SQL status: SUCCESS 1 in 2.76 seconds
2021-04-30 18:18:13.407339 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:18:13.407570 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:13.407698 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:18:13.843828 (Thread-1): SQL status: SUCCESS 1 in 0.44 seconds
2021-04-30 18:18:13.844863 (Thread-1): finished collecting timing info
2021-04-30 18:18:13.845076 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:18:13.966810 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84c3eca4-88a3-4967-bc6d-ed07f25c98f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058c0a30>]}
2021-04-30 18:18:13.967347 (Thread-1): 11:18:13 | 2 of 3 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 4.17s]
2021-04-30 18:18:13.967541 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:18:13.967737 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:18:13.968015 (Thread-1): 11:18:13 | 3 of 3 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:18:13.968702 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:13.968885 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:18:13.972123 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:18:13.972704 (Thread-1): finished collecting timing info
2021-04-30 18:18:13.998544 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:18:13.999658 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:13.999794 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:18:13.999903 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:18:15.396461 (Thread-1): SQL status: SUCCESS 1 in 1.40 seconds
2021-04-30 18:18:15.396695 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:15.396822 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:18:15.805198 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2021-04-30 18:18:15.806736 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:18:15.807004 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:15.807136 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:18:15.932604 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:18:15.934132 (Thread-1): finished collecting timing info
2021-04-30 18:18:15.934393 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:18:16.066206 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84c3eca4-88a3-4967-bc6d-ed07f25c98f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761dc10>]}
2021-04-30 18:18:16.066726 (Thread-1): 11:18:16 | 3 of 3 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.10s]
2021-04-30 18:18:16.066920 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:18:16.068269 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:18:16.068540 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:16.068653 (MainThread): On master: BEGIN
2021-04-30 18:18:16.068765 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:18:16.712931 (MainThread): SQL status: SUCCESS 1 in 0.64 seconds
2021-04-30 18:18:16.718780 (MainThread): On master: COMMIT
2021-04-30 18:18:16.719178 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:16.719367 (MainThread): On master: COMMIT
2021-04-30 18:18:17.325186 (MainThread): SQL status: SUCCESS 1 in 0.61 seconds
2021-04-30 18:18:17.325503 (MainThread): On master: Close
2021-04-30 18:18:17.453081 (MainThread): 11:18:17 | 
2021-04-30 18:18:17.453327 (MainThread): 11:18:17 | Finished running 2 table models, 1 view model in 13.64s.
2021-04-30 18:18:17.453511 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:18:17.453631 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:18:17.459370 (MainThread): 
2021-04-30 18:18:17.459574 (MainThread): Completed successfully
2021-04-30 18:18:17.459727 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-30 18:18:17.459935 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d1490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10596e5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076208b0>]}
2021-04-30 18:18:17.460184 (MainThread): Flushing usage events
2021-04-30 18:18:31.618829 (MainThread): Running with dbt=0.19.1
2021-04-30 18:18:32.480049 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:18:32.481328 (MainThread): Tracking: tracking
2021-04-30 18:18:32.481671 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034e49a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044c3ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044c3dc0>]}
2021-04-30 18:18:32.495580 (MainThread): Partial parsing not enabled
2021-04-30 18:18:32.497200 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:18:32.500289 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:18:32.537024 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:18:32.539840 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:18:32.542125 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:18:32.547350 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:18:32.559843 (MainThread): Parsing macros/core.sql
2021-04-30 18:18:32.565176 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:18:32.577177 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:18:32.580162 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:18:32.602680 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:18:32.640985 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:18:32.665871 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:18:32.670229 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:18:32.680029 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:18:32.698258 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:18:32.706819 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:18:32.714648 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:18:32.720908 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:18:32.722817 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:18:32.724943 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:18:32.727665 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:18:32.738350 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:18:32.741200 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:18:32.744026 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:18:32.794322 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:18:32.798898 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:18:32.802272 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:18:32.805575 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:18:32.815206 (MainThread): Partial parsing not enabled
2021-04-30 18:18:32.840997 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:32.852727 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:32.858791 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:32.942726 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:18:32.943275 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa1adff5-1059-494a-9b83-965348425eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061fdd00>]}
2021-04-30 18:18:32.948679 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa1adff5-1059-494a-9b83-965348425eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061eaeb0>]}
2021-04-30 18:18:32.948991 (MainThread): Found 3 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:18:32.949901 (MainThread): 
2021-04-30 18:18:32.950202 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:18:32.951111 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:18:32.965041 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:18:32.965210 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:18:32.965355 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:18:35.278183 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 2.31 seconds
2021-04-30 18:18:35.283464 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:18:35.396603 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:18:35.405299 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:18:35.405469 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:18:35.405581 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:18:36.287126 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 3 in 0.88 seconds
2021-04-30 18:18:36.288355 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:18:36.415911 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:36.416115 (MainThread): On master: BEGIN
2021-04-30 18:18:36.416245 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:18:37.389670 (MainThread): SQL status: SUCCESS 1 in 0.97 seconds
2021-04-30 18:18:37.389976 (MainThread): On master: COMMIT
2021-04-30 18:18:37.390253 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:37.390410 (MainThread): On master: COMMIT
2021-04-30 18:18:37.570997 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2021-04-30 18:18:37.571328 (MainThread): On master: Close
2021-04-30 18:18:37.702891 (MainThread): 11:18:37 | Concurrency: 1 threads (target='dev')
2021-04-30 18:18:37.703140 (MainThread): 11:18:37 | 
2021-04-30 18:18:37.704729 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:18:37.705146 (Thread-1): 11:18:37 | 1 of 3 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 18:18:37.705533 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:37.705687 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:18:37.708919 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:18:37.709447 (Thread-1): finished collecting timing info
2021-04-30 18:18:37.747695 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:18:37.749089 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:37.749236 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:18:37.749338 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:18:38.572900 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-04-30 18:18:38.573136 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:38.573264 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 18:18:40.057079 (Thread-1): SQL status: SUCCESS 1 in 1.48 seconds
2021-04-30 18:18:40.058656 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:18:40.058882 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:18:40.059005 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:18:40.561711 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-04-30 18:18:40.575231 (Thread-1): finished collecting timing info
2021-04-30 18:18:40.575448 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:18:40.692450 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa1adff5-1059-494a-9b83-965348425eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061544f0>]}
2021-04-30 18:18:40.692973 (Thread-1): 11:18:40 | 1 of 3 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 2.99s]
2021-04-30 18:18:40.693171 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:18:40.693365 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:18:40.693707 (Thread-1): 11:18:40 | 2 of 3 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 18:18:40.694371 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:40.694881 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:18:40.698815 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:18:40.699384 (Thread-1): finished collecting timing info
2021-04-30 18:18:40.701592 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:18:40.702903 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:40.703020 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:18:40.703127 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:18:41.473458 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2021-04-30 18:18:41.478994 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:41.479269 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (

SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 18:18:43.397158 (Thread-1): SQL status: SUCCESS 1 in 1.92 seconds
2021-04-30 18:18:43.398886 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:18:43.399105 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:18:43.399228 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:18:43.741696 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-04-30 18:18:43.742961 (Thread-1): finished collecting timing info
2021-04-30 18:18:43.743195 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:18:43.864619 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa1adff5-1059-494a-9b83-965348425eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061a05e0>]}
2021-04-30 18:18:43.865137 (Thread-1): 11:18:43 | 2 of 3 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.17s]
2021-04-30 18:18:43.865330 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:18:43.865526 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:18:43.865799 (Thread-1): 11:18:43 | 3 of 3 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:18:43.866414 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:43.866818 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:18:43.870062 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:18:43.870606 (Thread-1): finished collecting timing info
2021-04-30 18:18:43.901616 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:18:43.903041 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:43.903246 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:18:43.903356 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:18:44.505990 (Thread-1): SQL status: SUCCESS 1 in 0.60 seconds
2021-04-30 18:18:44.506273 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:44.506434 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:18:44.848501 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-04-30 18:18:44.850149 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:18:44.850374 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:18:44.850496 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:18:44.977703 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:18:44.979039 (Thread-1): finished collecting timing info
2021-04-30 18:18:44.979264 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:18:45.104282 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa1adff5-1059-494a-9b83-965348425eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b55e0>]}
2021-04-30 18:18:45.104786 (Thread-1): 11:18:45 | 3 of 3 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.24s]
2021-04-30 18:18:45.105049 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:18:45.106789 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:18:45.107125 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:45.107240 (MainThread): On master: BEGIN
2021-04-30 18:18:45.107342 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:18:45.889477 (MainThread): SQL status: SUCCESS 1 in 0.78 seconds
2021-04-30 18:18:45.889748 (MainThread): On master: COMMIT
2021-04-30 18:18:45.889988 (MainThread): Using snowflake connection "master".
2021-04-30 18:18:45.890121 (MainThread): On master: COMMIT
2021-04-30 18:18:46.149091 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 18:18:46.149349 (MainThread): On master: Close
2021-04-30 18:18:46.261959 (MainThread): 11:18:46 | 
2021-04-30 18:18:46.262207 (MainThread): 11:18:46 | Finished running 2 table models, 1 view model in 13.31s.
2021-04-30 18:18:46.262366 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:18:46.262480 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:18:46.268481 (MainThread): 
2021-04-30 18:18:46.268680 (MainThread): Completed successfully
2021-04-30 18:18:46.268859 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-30 18:18:46.269166 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106091400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044f0b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044f0ca0>]}
2021-04-30 18:18:46.269423 (MainThread): Flushing usage events
2021-04-30 18:24:12.739709 (MainThread): Running with dbt=0.19.1
2021-04-30 18:24:13.816082 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:24:13.817748 (MainThread): Tracking: tracking
2021-04-30 18:24:13.820635 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f704dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106d7d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106d7e80>]}
2021-04-30 18:24:13.846546 (MainThread): Partial parsing not enabled
2021-04-30 18:24:13.848593 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:24:13.854174 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:24:13.900891 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:24:13.903859 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:24:13.906383 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:24:13.911746 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:24:13.927586 (MainThread): Parsing macros/core.sql
2021-04-30 18:24:13.934390 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:24:13.945619 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:24:13.948498 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:24:13.971668 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:24:14.012391 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:24:14.037126 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:24:14.039949 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:24:14.048435 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:24:14.067673 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:24:14.076243 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:24:14.084508 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:24:14.092186 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:24:14.093674 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:24:14.095414 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:24:14.097632 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:24:14.110104 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:24:14.112930 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:24:14.115416 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:24:14.175392 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:24:14.178222 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:24:14.180570 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:24:14.182896 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:24:14.192275 (MainThread): Partial parsing not enabled
2021-04-30 18:24:14.226889 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:24:14.247133 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:24:14.256120 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:24:14.261313 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:24:14.373700 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:24:14.374653 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30ed2e1f-3e1a-4567-9bc8-a51a35222cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123e4d30>]}
2021-04-30 18:24:14.384261 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30ed2e1f-3e1a-4567-9bc8-a51a35222cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f5b80>]}
2021-04-30 18:24:14.384573 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:24:14.386358 (MainThread): 
2021-04-30 18:24:14.386949 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:24:14.389218 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:24:14.423929 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:24:14.424271 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:24:14.424485 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:24:15.714884 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.29 seconds
2021-04-30 18:24:15.720188 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:24:15.857054 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:24:15.869254 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:24:15.869510 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:24:15.869675 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:24:16.944773 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 3 in 1.08 seconds
2021-04-30 18:24:16.946226 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:24:17.073041 (MainThread): Using snowflake connection "master".
2021-04-30 18:24:17.073239 (MainThread): On master: BEGIN
2021-04-30 18:24:17.073366 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:24:17.760521 (MainThread): SQL status: SUCCESS 1 in 0.69 seconds
2021-04-30 18:24:17.760817 (MainThread): On master: COMMIT
2021-04-30 18:24:17.761115 (MainThread): Using snowflake connection "master".
2021-04-30 18:24:17.761272 (MainThread): On master: COMMIT
2021-04-30 18:24:17.991024 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-04-30 18:24:17.991285 (MainThread): On master: Close
2021-04-30 18:24:18.111703 (MainThread): 11:24:18 | Concurrency: 1 threads (target='dev')
2021-04-30 18:24:18.111993 (MainThread): 11:24:18 | 
2021-04-30 18:24:18.113860 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:24:18.114219 (Thread-1): 11:24:18 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 18:24:18.114576 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:24:18.114717 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:24:18.117863 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:24:18.118490 (Thread-1): finished collecting timing info
2021-04-30 18:24:18.150876 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:24:18.152210 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:24:18.152347 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:24:18.152437 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:24:18.880294 (Thread-1): SQL status: SUCCESS 1 in 0.73 seconds
2021-04-30 18:24:18.880529 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:24:18.880665 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 18:24:19.725534 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-04-30 18:24:19.726962 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:24:19.727342 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:24:19.727524 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:24:19.848532 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 18:24:19.861729 (Thread-1): finished collecting timing info
2021-04-30 18:24:19.861936 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:24:19.992817 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ed2e1f-3e1a-4567-9bc8-a51a35222cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112423760>]}
2021-04-30 18:24:19.993507 (Thread-1): 11:24:19 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 1.88s]
2021-04-30 18:24:19.993855 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:24:19.994352 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:24:19.995291 (Thread-1): 11:24:19 | 2 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-04-30 18:24:19.996261 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:24:19.996651 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:24:20.001798 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:24:20.002416 (Thread-1): finished collecting timing info
2021-04-30 18:24:20.006829 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:24:20.009116 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:24:20.009286 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:24:20.009388 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:24:20.892671 (Thread-1): SQL status: SUCCESS 1 in 0.88 seconds
2021-04-30 18:24:20.898537 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:24:20.898990 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
      );
2021-04-30 18:24:22.087664 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-04-30 18:24:22.088800 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:24:22.089005 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:24:22.089093 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:24:22.556038 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2021-04-30 18:24:22.557213 (Thread-1): finished collecting timing info
2021-04-30 18:24:22.557476 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:24:22.692549 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ed2e1f-3e1a-4567-9bc8-a51a35222cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107433d0>]}
2021-04-30 18:24:22.693202 (Thread-1): 11:24:22 | 2 of 4 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 2.70s]
2021-04-30 18:24:22.693480 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:24:22.693719 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:24:22.694728 (Thread-1): 11:24:22 | 3 of 4 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 18:24:22.695453 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:24:22.695621 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:24:22.700070 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:24:22.701223 (Thread-1): finished collecting timing info
2021-04-30 18:24:22.704676 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:24:22.706864 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:24:22.707176 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:24:22.707374 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:24:23.658088 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2021-04-30 18:24:23.658354 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:24:23.658521 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (

SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 18:24:25.327819 (Thread-1): SQL status: SUCCESS 1 in 1.67 seconds
2021-04-30 18:24:25.328999 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:24:25.329251 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:24:25.329350 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:24:26.315043 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-04-30 18:24:26.315991 (Thread-1): finished collecting timing info
2021-04-30 18:24:26.316201 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:24:26.490138 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ed2e1f-3e1a-4567-9bc8-a51a35222cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110743d90>]}
2021-04-30 18:24:26.490561 (Thread-1): 11:24:26 | 3 of 4 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.79s]
2021-04-30 18:24:26.490704 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:24:26.490839 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:24:26.491037 (Thread-1): 11:24:26 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:24:26.491657 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:24:26.491851 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:24:26.495956 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:24:26.502215 (Thread-1): finished collecting timing info
2021-04-30 18:24:26.521926 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:24:26.522971 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:24:26.523114 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:24:26.523211 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:24:27.793048 (Thread-1): SQL status: SUCCESS 1 in 1.27 seconds
2021-04-30 18:24:27.793399 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:24:27.793549 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:24:28.316886 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2021-04-30 18:24:28.318045 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:24:28.318246 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:24:28.318349 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:24:28.400122 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2021-04-30 18:24:28.401131 (Thread-1): finished collecting timing info
2021-04-30 18:24:28.401338 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:24:28.536757 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ed2e1f-3e1a-4567-9bc8-a51a35222cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113613280>]}
2021-04-30 18:24:28.537251 (Thread-1): 11:24:28 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.05s]
2021-04-30 18:24:28.537430 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:24:28.538982 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:24:28.539264 (MainThread): Using snowflake connection "master".
2021-04-30 18:24:28.539365 (MainThread): On master: BEGIN
2021-04-30 18:24:28.539454 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:24:29.484321 (MainThread): SQL status: SUCCESS 1 in 0.94 seconds
2021-04-30 18:24:29.484616 (MainThread): On master: COMMIT
2021-04-30 18:24:29.484845 (MainThread): Using snowflake connection "master".
2021-04-30 18:24:29.484993 (MainThread): On master: COMMIT
2021-04-30 18:24:29.654538 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2021-04-30 18:24:29.654863 (MainThread): On master: Close
2021-04-30 18:24:29.794354 (MainThread): 11:24:29 | 
2021-04-30 18:24:29.794672 (MainThread): 11:24:29 | Finished running 3 table models, 1 view model in 15.41s.
2021-04-30 18:24:29.794886 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:24:29.795046 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:24:29.801600 (MainThread): 
2021-04-30 18:24:29.801811 (MainThread): Completed successfully
2021-04-30 18:24:29.801959 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:24:29.802165 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113613520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113613d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113613190>]}
2021-04-30 18:24:29.802406 (MainThread): Flushing usage events
2021-04-30 18:26:09.784252 (MainThread): Running with dbt=0.19.1
2021-04-30 18:26:10.651799 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:26:10.653268 (MainThread): Tracking: tracking
2021-04-30 18:26:10.653639 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c286550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1ffd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1ffdf0>]}
2021-04-30 18:26:10.667627 (MainThread): Partial parsing not enabled
2021-04-30 18:26:10.669093 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:26:10.672825 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:26:10.709582 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:26:10.712344 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:26:10.714398 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:26:10.719401 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:26:10.732243 (MainThread): Parsing macros/core.sql
2021-04-30 18:26:10.737866 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:26:10.751119 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:26:10.754066 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:26:10.778145 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:26:10.816872 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:26:10.842547 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:26:10.846031 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:26:10.855681 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:26:10.873251 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:26:10.882682 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:26:10.891049 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:26:10.897528 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:26:10.899190 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:26:10.900951 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:26:10.903469 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:26:10.914313 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:26:10.917478 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:26:10.920275 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:26:10.976548 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:26:10.979947 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:26:10.982220 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:26:10.984935 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:26:10.994458 (MainThread): Partial parsing not enabled
2021-04-30 18:26:11.021486 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:26:11.033507 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:26:11.039434 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:26:11.043904 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:26:11.129118 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:26:11.129830 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20172d4b-ee91-4c22-ac21-580e2ceba9c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee2e250>]}
2021-04-30 18:26:11.136620 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20172d4b-ee91-4c22-ac21-580e2ceba9c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee41670>]}
2021-04-30 18:26:11.136968 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:26:11.138712 (MainThread): 
2021-04-30 18:26:11.139363 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:26:11.141106 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:26:11.169728 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:26:11.170022 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:26:11.170123 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:26:12.902404 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.73 seconds
2021-04-30 18:26:12.908107 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:26:13.136035 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:26:13.144460 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:26:13.144647 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:26:13.144753 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:26:14.157242 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.01 seconds
2021-04-30 18:26:14.158531 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:26:14.269970 (MainThread): Using snowflake connection "master".
2021-04-30 18:26:14.270175 (MainThread): On master: BEGIN
2021-04-30 18:26:14.270299 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:26:15.606422 (MainThread): SQL status: SUCCESS 1 in 1.34 seconds
2021-04-30 18:26:15.606747 (MainThread): On master: COMMIT
2021-04-30 18:26:15.607032 (MainThread): Using snowflake connection "master".
2021-04-30 18:26:15.607225 (MainThread): On master: COMMIT
2021-04-30 18:26:15.830939 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-04-30 18:26:15.831249 (MainThread): On master: Close
2021-04-30 18:26:15.993099 (MainThread): 11:26:15 | Concurrency: 1 threads (target='dev')
2021-04-30 18:26:15.993394 (MainThread): 11:26:15 | 
2021-04-30 18:26:15.995216 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:26:15.995663 (Thread-1): 11:26:15 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 18:26:15.996167 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:26:15.996373 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:26:16.000627 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:26:16.001210 (Thread-1): finished collecting timing info
2021-04-30 18:26:16.036561 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:26:16.037809 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:26:16.037946 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:26:16.038050 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:26:17.595010 (Thread-1): SQL status: SUCCESS 1 in 1.56 seconds
2021-04-30 18:26:17.595309 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:26:17.595562 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 18:26:18.414535 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-04-30 18:26:18.416135 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:26:18.416354 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:26:18.416480 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:26:18.602862 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-04-30 18:26:18.616290 (Thread-1): finished collecting timing info
2021-04-30 18:26:18.616512 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:26:18.739351 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20172d4b-ee91-4c22-ac21-580e2ceba9c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee2e7f0>]}
2021-04-30 18:26:18.739886 (Thread-1): 11:26:18 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 2.74s]
2021-04-30 18:26:18.740081 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:26:18.740270 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:26:18.740570 (Thread-1): 11:26:18 | 2 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-04-30 18:26:18.741347 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:26:18.741604 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:26:18.744687 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:26:18.745236 (Thread-1): finished collecting timing info
2021-04-30 18:26:18.747387 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:26:18.748879 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:26:18.748998 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:26:18.749103 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:26:19.358461 (Thread-1): SQL status: SUCCESS 1 in 0.61 seconds
2021-04-30 18:26:19.358745 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:26:19.358904 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
      );
2021-04-30 18:26:20.490010 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2021-04-30 18:26:20.491398 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:26:20.491622 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:26:20.491753 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:26:20.846857 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2021-04-30 18:26:20.847868 (Thread-1): finished collecting timing info
2021-04-30 18:26:20.848069 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:26:21.001154 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20172d4b-ee91-4c22-ac21-580e2ceba9c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef6db20>]}
2021-04-30 18:26:21.001623 (Thread-1): 11:26:21 | 2 of 4 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 2.26s]
2021-04-30 18:26:21.001793 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:26:21.001956 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:26:21.002510 (Thread-1): 11:26:21 | 3 of 4 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 18:26:21.002988 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:26:21.003135 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:26:21.006169 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:26:21.012080 (Thread-1): finished collecting timing info
2021-04-30 18:26:21.014398 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:26:21.015735 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:26:21.015914 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:26:21.016038 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:26:21.670715 (Thread-1): SQL status: SUCCESS 1 in 0.65 seconds
2021-04-30 18:26:21.671045 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:26:21.671184 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (

SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 18:26:23.098869 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-04-30 18:26:23.100274 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:26:23.100503 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:26:23.100630 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:26:23.546093 (Thread-1): SQL status: SUCCESS 1 in 0.45 seconds
2021-04-30 18:26:23.546965 (Thread-1): finished collecting timing info
2021-04-30 18:26:23.547144 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:26:23.667555 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20172d4b-ee91-4c22-ac21-580e2ceba9c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7cda30>]}
2021-04-30 18:26:23.668129 (Thread-1): 11:26:23 | 3 of 4 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 2.66s]
2021-04-30 18:26:23.668338 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:26:23.668547 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:26:23.668845 (Thread-1): 11:26:23 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:26:23.669258 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:26:23.669416 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:26:23.677042 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:26:23.678149 (Thread-1): finished collecting timing info
2021-04-30 18:26:23.705156 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:26:23.706172 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:26:23.706303 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:26:23.706426 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:26:24.874281 (Thread-1): SQL status: SUCCESS 1 in 1.17 seconds
2021-04-30 18:26:24.874460 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:26:24.874596 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:26:25.232205 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-04-30 18:26:25.233174 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:26:25.233341 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:26:25.233425 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:26:25.370129 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-04-30 18:26:25.370974 (Thread-1): finished collecting timing info
2021-04-30 18:26:25.371193 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:26:25.478691 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20172d4b-ee91-4c22-ac21-580e2ceba9c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11013e4c0>]}
2021-04-30 18:26:25.479137 (Thread-1): 11:26:25 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.81s]
2021-04-30 18:26:25.479285 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:26:25.480473 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:26:25.480704 (MainThread): Using snowflake connection "master".
2021-04-30 18:26:25.480794 (MainThread): On master: BEGIN
2021-04-30 18:26:25.480877 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:26:26.659318 (MainThread): SQL status: SUCCESS 1 in 1.18 seconds
2021-04-30 18:26:26.659820 (MainThread): On master: COMMIT
2021-04-30 18:26:26.659985 (MainThread): Using snowflake connection "master".
2021-04-30 18:26:26.660067 (MainThread): On master: COMMIT
2021-04-30 18:26:26.890346 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-04-30 18:26:26.890556 (MainThread): On master: Close
2021-04-30 18:26:26.984002 (MainThread): 11:26:26 | 
2021-04-30 18:26:26.984191 (MainThread): 11:26:26 | Finished running 3 table models, 1 view model in 15.84s.
2021-04-30 18:26:26.984307 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:26:26.984386 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:26:26.990433 (MainThread): 
2021-04-30 18:26:26.990614 (MainThread): Completed successfully
2021-04-30 18:26:26.990825 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:26:26.991113 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee10580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef00460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d21c910>]}
2021-04-30 18:26:26.991355 (MainThread): Flushing usage events
2021-04-30 18:51:35.423732 (MainThread): Running with dbt=0.19.1
2021-04-30 18:51:36.652336 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:51:36.659253 (MainThread): Tracking: tracking
2021-04-30 18:51:36.681968 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092838e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21ad30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21ae20>]}
2021-04-30 18:51:36.710505 (MainThread): Partial parsing not enabled
2021-04-30 18:51:36.713613 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:51:36.725527 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:51:36.832464 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:51:36.835626 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:51:36.838196 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:51:36.844470 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:51:36.861821 (MainThread): Parsing macros/core.sql
2021-04-30 18:51:36.867688 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:51:36.879922 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:51:36.883007 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:51:36.905507 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:51:36.945509 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:51:36.970746 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:51:36.973400 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:51:36.984408 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:51:37.004018 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:51:37.013361 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:51:37.022058 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:51:37.028575 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:51:37.030219 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:51:37.031843 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:51:37.034047 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:51:37.047033 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:51:37.050000 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:51:37.052697 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:51:37.110455 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:51:37.116959 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:51:37.128610 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:51:37.134511 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:51:37.156767 (MainThread): Partial parsing not enabled
2021-04-30 18:51:37.233154 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:51:37.252652 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:51:37.263721 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:51:37.268676 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:51:37.360347 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:51:37.361076 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '56ba0506-86f4-44a1-a9ed-72f414e4b801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf7f9d0>]}
2021-04-30 18:51:37.366544 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '56ba0506-86f4-44a1-a9ed-72f414e4b801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf92820>]}
2021-04-30 18:51:37.366835 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:51:37.367806 (MainThread): 
2021-04-30 18:51:37.368177 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:51:37.369186 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:51:37.385557 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:51:37.385763 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:51:37.385970 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:51:38.318947 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 0.93 seconds
2021-04-30 18:51:38.324339 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:51:38.439410 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:51:38.448470 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:51:38.448658 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:51:38.448775 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:51:39.160579 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.71 seconds
2021-04-30 18:51:39.162079 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:51:39.285730 (MainThread): Using snowflake connection "master".
2021-04-30 18:51:39.285908 (MainThread): On master: BEGIN
2021-04-30 18:51:39.286021 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:51:39.817656 (MainThread): SQL status: SUCCESS 1 in 0.53 seconds
2021-04-30 18:51:39.817969 (MainThread): On master: COMMIT
2021-04-30 18:51:39.818251 (MainThread): Using snowflake connection "master".
2021-04-30 18:51:39.818394 (MainThread): On master: COMMIT
2021-04-30 18:51:40.005953 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2021-04-30 18:51:40.006272 (MainThread): On master: Close
2021-04-30 18:51:40.113132 (MainThread): 11:51:40 | Concurrency: 1 threads (target='dev')
2021-04-30 18:51:40.113492 (MainThread): 11:51:40 | 
2021-04-30 18:51:40.115197 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:51:40.115630 (Thread-1): 11:51:40 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-04-30 18:51:40.116112 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:51:40.116290 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:51:40.119436 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:51:40.121774 (Thread-1): finished collecting timing info
2021-04-30 18:51:40.160006 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:51:40.160206 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop table if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
2021-04-30 18:51:40.160317 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:51:41.792576 (Thread-1): SQL status: SUCCESS 1 in 1.63 seconds
2021-04-30 18:51:41.799908 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:51:41.801084 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:51:41.801202 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:51:41.924779 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 18:51:41.924990 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:51:41.925109 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-04-30 18:51:42.457416 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-04-30 18:51:42.459057 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:51:42.459282 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:51:42.459405 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:51:42.585383 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:51:42.594341 (Thread-1): finished collecting timing info
2021-04-30 18:51:42.594566 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:51:42.711813 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56ba0506-86f4-44a1-a9ed-72f414e4b801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2aa940>]}
2021-04-30 18:51:42.712330 (Thread-1): 11:51:42 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 2.60s]
2021-04-30 18:51:42.712525 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:51:42.712721 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:51:42.713027 (Thread-1): 11:51:42 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 18:51:42.713918 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:51:42.714154 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:51:42.716776 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:51:42.723154 (Thread-1): finished collecting timing info
2021-04-30 18:51:42.728310 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:51:42.728486 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */
drop table if exists "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" cascade
2021-04-30 18:51:42.728618 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:51:43.337433 (Thread-1): SQL status: SUCCESS 1 in 0.61 seconds
2021-04-30 18:51:43.339396 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:51:43.341224 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:51:43.341368 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:51:43.467878 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:51:43.468145 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:51:43.468304 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 18:51:43.805232 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-04-30 18:51:43.806880 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:51:43.807117 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:51:43.807243 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:51:43.928640 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 18:51:43.929608 (Thread-1): finished collecting timing info
2021-04-30 18:51:43.929816 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:51:44.047989 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56ba0506-86f4-44a1-a9ed-72f414e4b801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be33f40>]}
2021-04-30 18:51:44.048507 (Thread-1): 11:51:44 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.33s]
2021-04-30 18:51:44.048704 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:51:44.048899 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:51:44.049357 (Thread-1): 11:51:44 | 3 of 4 START view model dbt.sf_customer_purchases.................... [RUN]
2021-04-30 18:51:44.050089 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:51:44.050267 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:51:44.053412 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:51:44.056213 (Thread-1): finished collecting timing info
2021-04-30 18:51:44.060554 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:51:44.060756 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */
drop table if exists "ANALYTICS"."DBT"."SF_CUSTOMER_PURCHASES" cascade
2021-04-30 18:51:44.060879 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:51:45.087111 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-04-30 18:51:45.089203 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:51:45.093296 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:51:45.093549 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:51:45.405477 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-04-30 18:51:45.405750 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:51:45.405908 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */

  create or replace  view analytics.dbt.sf_customer_purchases  as (
    

SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
  );
2021-04-30 18:51:45.745445 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-04-30 18:51:45.747071 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:51:45.747310 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:51:45.747435 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:51:45.869410 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 18:51:45.870736 (Thread-1): finished collecting timing info
2021-04-30 18:51:45.870959 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:51:45.972245 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56ba0506-86f4-44a1-a9ed-72f414e4b801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c174d90>]}
2021-04-30 18:51:45.972769 (Thread-1): 11:51:45 | 3 of 4 OK created view model dbt.sf_customer_purchases............... [SUCCESS 1 in 1.92s]
2021-04-30 18:51:45.972963 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:51:45.973179 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:51:45.973649 (Thread-1): 11:51:45 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:51:45.974221 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:51:45.974427 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:51:45.978387 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:51:45.984389 (Thread-1): finished collecting timing info
2021-04-30 18:51:45.987484 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:51:45.988811 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:51:45.988960 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:51:45.989099 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:51:46.746675 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 18:51:46.746966 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:51:46.747127 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:51:47.142329 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2021-04-30 18:51:47.143949 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:51:47.144210 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:51:47.144408 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:51:47.277658 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:51:47.279671 (Thread-1): finished collecting timing info
2021-04-30 18:51:47.280010 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:51:47.394031 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56ba0506-86f4-44a1-a9ed-72f414e4b801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c174b50>]}
2021-04-30 18:51:47.394593 (Thread-1): 11:51:47 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.42s]
2021-04-30 18:51:47.394895 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:51:47.396638 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:51:47.396954 (MainThread): Using snowflake connection "master".
2021-04-30 18:51:47.397080 (MainThread): On master: BEGIN
2021-04-30 18:51:47.397184 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:51:48.033561 (MainThread): SQL status: SUCCESS 1 in 0.64 seconds
2021-04-30 18:51:48.033774 (MainThread): On master: COMMIT
2021-04-30 18:51:48.033954 (MainThread): Using snowflake connection "master".
2021-04-30 18:51:48.034055 (MainThread): On master: COMMIT
2021-04-30 18:51:48.289121 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-04-30 18:51:48.289410 (MainThread): On master: Close
2021-04-30 18:51:48.518761 (MainThread): 11:51:48 | 
2021-04-30 18:51:48.519036 (MainThread): 11:51:48 | Finished running 4 view models in 11.15s.
2021-04-30 18:51:48.519205 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:51:48.519323 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:51:48.526292 (MainThread): 
2021-04-30 18:51:48.526511 (MainThread): Completed successfully
2021-04-30 18:51:48.526663 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:51:48.526884 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be51460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a299670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2993a0>]}
2021-04-30 18:51:48.527134 (MainThread): Flushing usage events
2021-04-30 18:52:06.318581 (MainThread): Running with dbt=0.19.1
2021-04-30 18:52:07.207877 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:52:07.208831 (MainThread): Tracking: tracking
2021-04-30 18:52:07.209165 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a90dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a63d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a63e80>]}
2021-04-30 18:52:07.222265 (MainThread): Partial parsing not enabled
2021-04-30 18:52:07.223937 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:52:07.226966 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:52:07.265010 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:52:07.267959 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:52:07.270341 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:52:07.275757 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:52:07.288115 (MainThread): Parsing macros/core.sql
2021-04-30 18:52:07.293941 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:52:07.304824 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:52:07.307349 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:52:07.329176 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:52:07.372273 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:52:07.401791 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:52:07.404807 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:52:07.412385 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:52:07.429618 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:52:07.437748 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:52:07.446334 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:52:07.453174 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:52:07.455298 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:52:07.457394 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:52:07.460155 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:52:07.471304 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:52:07.474243 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:52:07.477739 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:52:07.527943 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:52:07.530870 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:52:07.533363 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:52:07.536067 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:52:07.545001 (MainThread): Partial parsing not enabled
2021-04-30 18:52:07.572187 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:52:07.584042 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:52:07.589200 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:52:07.593237 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:52:07.676987 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:52:07.677547 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9448e48c-5bbb-44c0-9a2f-0f397468372a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067928b0>]}
2021-04-30 18:52:07.683654 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9448e48c-5bbb-44c0-9a2f-0f397468372a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676cc40>]}
2021-04-30 18:52:07.683993 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:52:07.685109 (MainThread): 
2021-04-30 18:52:07.685418 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:52:07.686291 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:52:07.702212 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:52:07.702414 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:52:07.702594 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:52:08.668233 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 0.97 seconds
2021-04-30 18:52:08.674048 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:52:08.810316 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:52:08.820045 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:52:08.820241 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:52:08.820360 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:52:09.863905 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.04 seconds
2021-04-30 18:52:09.865449 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:52:09.980185 (MainThread): Using snowflake connection "master".
2021-04-30 18:52:09.980399 (MainThread): On master: BEGIN
2021-04-30 18:52:09.980527 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:52:10.917361 (MainThread): SQL status: SUCCESS 1 in 0.94 seconds
2021-04-30 18:52:10.917596 (MainThread): On master: COMMIT
2021-04-30 18:52:10.917796 (MainThread): Using snowflake connection "master".
2021-04-30 18:52:10.917902 (MainThread): On master: COMMIT
2021-04-30 18:52:11.549905 (MainThread): SQL status: SUCCESS 1 in 0.63 seconds
2021-04-30 18:52:11.550193 (MainThread): On master: Close
2021-04-30 18:52:11.714910 (MainThread): 11:52:11 | Concurrency: 1 threads (target='dev')
2021-04-30 18:52:11.715163 (MainThread): 11:52:11 | 
2021-04-30 18:52:11.716623 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:52:11.717033 (Thread-1): 11:52:11 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-04-30 18:52:11.717438 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:52:11.717592 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:52:11.720848 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:52:11.721392 (Thread-1): finished collecting timing info
2021-04-30 18:52:11.754953 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:52:11.756146 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:52:11.756274 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:52:11.756370 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:52:12.518204 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 18:52:12.518482 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:52:12.518640 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-04-30 18:52:13.585808 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2021-04-30 18:52:13.587289 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:52:13.587514 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:52:13.587634 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:52:13.714011 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:52:13.723075 (Thread-1): finished collecting timing info
2021-04-30 18:52:13.723274 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:52:14.138822 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9448e48c-5bbb-44c0-9a2f-0f397468372a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069290a0>]}
2021-04-30 18:52:14.139274 (Thread-1): 11:52:14 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 2.42s]
2021-04-30 18:52:14.139449 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:52:14.139615 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:52:14.139881 (Thread-1): 11:52:14 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 18:52:14.140514 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:52:14.140855 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:52:14.143881 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:52:14.144377 (Thread-1): finished collecting timing info
2021-04-30 18:52:14.146466 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:52:14.148385 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:52:14.148502 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:52:14.148603 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:52:15.418547 (Thread-1): SQL status: SUCCESS 1 in 1.27 seconds
2021-04-30 18:52:15.418782 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:52:15.418932 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 18:52:15.786038 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 18:52:15.787687 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:52:15.787932 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:52:15.788054 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:52:15.922085 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:52:15.923362 (Thread-1): finished collecting timing info
2021-04-30 18:52:15.923597 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:52:16.028671 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9448e48c-5bbb-44c0-9a2f-0f397468372a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f90d0>]}
2021-04-30 18:52:16.029199 (Thread-1): 11:52:16 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.89s]
2021-04-30 18:52:16.029572 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:52:16.029844 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:52:16.030312 (Thread-1): 11:52:16 | 3 of 4 START view model dbt.sf_customer_purchases.................... [RUN]
2021-04-30 18:52:16.030799 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:52:16.030940 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:52:16.032313 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:52:16.032775 (Thread-1): finished collecting timing info
2021-04-30 18:52:16.035231 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:52:16.036318 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:52:16.036424 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:52:16.036519 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:52:16.654159 (Thread-1): SQL status: SUCCESS 1 in 0.62 seconds
2021-04-30 18:52:16.654442 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:52:16.654597 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */

  create or replace  view analytics.dbt.sf_customer_purchases  as (
    SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
  );
2021-04-30 18:52:17.025575 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 18:52:17.026787 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:52:17.026988 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:52:17.027089 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:52:17.154626 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:52:17.155861 (Thread-1): finished collecting timing info
2021-04-30 18:52:17.156057 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:52:17.276040 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9448e48c-5bbb-44c0-9a2f-0f397468372a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f92e0>]}
2021-04-30 18:52:17.276631 (Thread-1): 11:52:17 | 3 of 4 OK created view model dbt.sf_customer_purchases............... [SUCCESS 1 in 1.25s]
2021-04-30 18:52:17.276901 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:52:17.277084 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:52:17.277517 (Thread-1): 11:52:17 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:52:17.278329 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:52:17.278545 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:52:17.282127 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:52:17.282682 (Thread-1): finished collecting timing info
2021-04-30 18:52:17.285644 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:52:17.286902 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:52:17.287075 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:52:17.287238 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:52:18.037182 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2021-04-30 18:52:18.037361 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:52:18.037451 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:52:18.370063 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2021-04-30 18:52:18.371478 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:52:18.371706 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:52:18.371825 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:52:18.501516 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:52:18.502301 (Thread-1): finished collecting timing info
2021-04-30 18:52:18.502467 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:52:18.624571 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9448e48c-5bbb-44c0-9a2f-0f397468372a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10697bdc0>]}
2021-04-30 18:52:18.625045 (Thread-1): 11:52:18 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.35s]
2021-04-30 18:52:18.625221 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:52:18.626697 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:52:18.626980 (MainThread): Using snowflake connection "master".
2021-04-30 18:52:18.627100 (MainThread): On master: BEGIN
2021-04-30 18:52:18.627205 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:52:19.338234 (MainThread): SQL status: SUCCESS 1 in 0.71 seconds
2021-04-30 18:52:19.338531 (MainThread): On master: COMMIT
2021-04-30 18:52:19.338793 (MainThread): Using snowflake connection "master".
2021-04-30 18:52:19.338944 (MainThread): On master: COMMIT
2021-04-30 18:52:19.622025 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-04-30 18:52:19.622334 (MainThread): On master: Close
2021-04-30 18:52:19.734859 (MainThread): 11:52:19 | 
2021-04-30 18:52:19.735103 (MainThread): 11:52:19 | Finished running 4 view models in 12.05s.
2021-04-30 18:52:19.735257 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:52:19.735365 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:52:19.741433 (MainThread): 
2021-04-30 18:52:19.741639 (MainThread): Completed successfully
2021-04-30 18:52:19.741797 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:52:19.742014 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066524c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10697b370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10697bfd0>]}
2021-04-30 18:52:19.742266 (MainThread): Flushing usage events
2021-04-30 18:53:48.873602 (MainThread): Running with dbt=0.19.1
2021-04-30 18:53:49.488510 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:53:49.489353 (MainThread): Tracking: tracking
2021-04-30 18:53:49.489719 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bc4af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ba0cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ba0460>]}
2021-04-30 18:53:49.501442 (MainThread): Partial parsing not enabled
2021-04-30 18:53:49.502585 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:53:49.505276 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:53:49.542245 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:53:49.544850 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:53:49.546858 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:53:49.551343 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:53:49.562803 (MainThread): Parsing macros/core.sql
2021-04-30 18:53:49.567566 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:53:49.579248 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:53:49.581595 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:53:49.601921 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:53:49.640377 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:53:49.664979 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:53:49.667231 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:53:49.674971 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:53:49.691753 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:53:49.699508 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:53:49.706456 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:53:49.712028 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:53:49.713055 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:53:49.714180 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:53:49.715921 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:53:49.725403 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:53:49.727430 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:53:49.729149 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:53:49.777236 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:53:49.779450 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:53:49.781417 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:53:49.783255 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:53:49.791428 (MainThread): Partial parsing not enabled
2021-04-30 18:53:49.817910 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:53:49.827740 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:53:49.831346 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:53:49.834189 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:53:49.911473 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:53:49.912145 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97a56f63-eee6-4d48-8e32-adc671358eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088adbb0>]}
2021-04-30 18:53:49.917705 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97a56f63-eee6-4d48-8e32-adc671358eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088a3c70>]}
2021-04-30 18:53:49.917971 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:53:49.919058 (MainThread): 
2021-04-30 18:53:49.919485 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:53:49.920336 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:53:49.934072 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:53:49.934241 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:53:49.934340 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:53:51.037390 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.10 seconds
2021-04-30 18:53:51.042574 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:53:51.154310 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:53:51.162232 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:53:51.162395 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:53:51.162493 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:53:51.784859 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.62 seconds
2021-04-30 18:53:51.786341 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:53:51.894153 (MainThread): Using snowflake connection "master".
2021-04-30 18:53:51.894361 (MainThread): On master: BEGIN
2021-04-30 18:53:51.894490 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:53:52.911848 (MainThread): SQL status: SUCCESS 1 in 1.02 seconds
2021-04-30 18:53:52.912155 (MainThread): On master: COMMIT
2021-04-30 18:53:52.912428 (MainThread): Using snowflake connection "master".
2021-04-30 18:53:52.912584 (MainThread): On master: COMMIT
2021-04-30 18:53:53.157139 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-04-30 18:53:53.157457 (MainThread): On master: Close
2021-04-30 18:53:53.281551 (MainThread): 11:53:53 | Concurrency: 1 threads (target='dev')
2021-04-30 18:53:53.281808 (MainThread): 11:53:53 | 
2021-04-30 18:53:53.283469 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:53:53.283874 (Thread-1): 11:53:53 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-04-30 18:53:53.284305 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:53:53.284474 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:53:53.286477 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:53:53.287039 (Thread-1): finished collecting timing info
2021-04-30 18:53:53.321255 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:53:53.323001 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:53:53.323261 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:53:53.323418 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:53:53.927614 (Thread-1): SQL status: SUCCESS 1 in 0.60 seconds
2021-04-30 18:53:53.927901 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:53:53.928071 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-04-30 18:53:54.385866 (Thread-1): SQL status: SUCCESS 1 in 0.46 seconds
2021-04-30 18:53:54.387577 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:53:54.387812 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:53:54.387938 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:53:54.567878 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-04-30 18:53:54.577861 (Thread-1): finished collecting timing info
2021-04-30 18:53:54.578096 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:53:54.710393 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97a56f63-eee6-4d48-8e32-adc671358eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10812b460>]}
2021-04-30 18:53:54.710940 (Thread-1): 11:53:54 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 1.43s]
2021-04-30 18:53:54.711113 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:53:54.711282 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:53:54.711583 (Thread-1): 11:53:54 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 18:53:54.712300 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:53:54.712476 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:53:54.715208 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:53:54.715735 (Thread-1): finished collecting timing info
2021-04-30 18:53:54.717788 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:53:54.719197 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:53:54.719315 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:53:54.719423 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:53:55.467931 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2021-04-30 18:53:55.468220 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:53:55.468388 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 18:53:55.836057 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 18:53:55.837766 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:53:55.837991 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:53:55.838114 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:53:55.975507 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-04-30 18:53:55.977012 (Thread-1): finished collecting timing info
2021-04-30 18:53:55.977262 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:53:56.082764 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97a56f63-eee6-4d48-8e32-adc671358eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bed1c0>]}
2021-04-30 18:53:56.083230 (Thread-1): 11:53:56 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.37s]
2021-04-30 18:53:56.083400 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:53:56.083566 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:53:56.083863 (Thread-1): 11:53:56 | 3 of 4 START view model dbt.sf_customer_purchases.................... [RUN]
2021-04-30 18:53:56.084441 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:53:56.084596 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:53:56.086003 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:53:56.086493 (Thread-1): finished collecting timing info
2021-04-30 18:53:56.089051 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:53:56.090229 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:53:56.090347 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:53:56.090453 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:53:57.535728 (Thread-1): SQL status: SUCCESS 1 in 1.45 seconds
2021-04-30 18:53:57.536022 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:53:57.536190 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */

  create or replace  view analytics.dbt.sf_customer_purchases  as (
    SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
  );
2021-04-30 18:53:57.951975 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2021-04-30 18:53:57.953715 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:53:57.953972 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:53:57.954101 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:53:58.079773 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:53:58.081083 (Thread-1): finished collecting timing info
2021-04-30 18:53:58.081284 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:53:58.201057 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97a56f63-eee6-4d48-8e32-adc671358eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bed340>]}
2021-04-30 18:53:58.201575 (Thread-1): 11:53:58 | 3 of 4 OK created view model dbt.sf_customer_purchases............... [SUCCESS 1 in 2.12s]
2021-04-30 18:53:58.201771 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:53:58.201965 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:53:58.202307 (Thread-1): 11:53:58 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:53:58.202782 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:53:58.203069 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:53:58.206174 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:53:58.206733 (Thread-1): finished collecting timing info
2021-04-30 18:53:58.208920 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:53:58.209817 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:53:58.209938 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:53:58.210048 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:53:59.183895 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-04-30 18:53:59.184137 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:53:59.184264 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:53:59.688020 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-04-30 18:53:59.690039 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:53:59.690331 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:53:59.690461 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:53:59.819776 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:53:59.821070 (Thread-1): finished collecting timing info
2021-04-30 18:53:59.821317 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:53:59.925327 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97a56f63-eee6-4d48-8e32-adc671358eb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088d9130>]}
2021-04-30 18:53:59.926069 (Thread-1): 11:53:59 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.72s]
2021-04-30 18:53:59.926388 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:53:59.927857 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:53:59.928130 (MainThread): Using snowflake connection "master".
2021-04-30 18:53:59.928244 (MainThread): On master: BEGIN
2021-04-30 18:53:59.928347 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:54:00.564008 (MainThread): SQL status: SUCCESS 1 in 0.64 seconds
2021-04-30 18:54:00.564323 (MainThread): On master: COMMIT
2021-04-30 18:54:00.564594 (MainThread): Using snowflake connection "master".
2021-04-30 18:54:00.564752 (MainThread): On master: COMMIT
2021-04-30 18:54:00.975726 (MainThread): SQL status: SUCCESS 1 in 0.41 seconds
2021-04-30 18:54:00.975982 (MainThread): On master: Close
2021-04-30 18:54:01.102499 (MainThread): 11:54:01 | 
2021-04-30 18:54:01.102768 (MainThread): 11:54:01 | Finished running 4 view models in 11.18s.
2021-04-30 18:54:01.102945 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:54:01.103128 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:54:01.110978 (MainThread): 
2021-04-30 18:54:01.111249 (MainThread): Completed successfully
2021-04-30 18:54:01.111455 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:54:01.111771 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10808a2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10808afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10808a340>]}
2021-04-30 18:54:01.112099 (MainThread): Flushing usage events
2021-04-30 18:54:48.608036 (MainThread): Running with dbt=0.19.1
2021-04-30 18:54:49.273299 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:54:49.274290 (MainThread): Tracking: tracking
2021-04-30 18:54:49.274578 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f410880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103efb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103efc40>]}
2021-04-30 18:54:49.286879 (MainThread): Partial parsing not enabled
2021-04-30 18:54:49.287999 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:54:49.290668 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:54:49.325719 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:54:49.328119 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:54:49.330294 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:54:49.335457 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:54:49.347273 (MainThread): Parsing macros/core.sql
2021-04-30 18:54:49.351823 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:54:49.362619 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:54:49.364730 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:54:49.389115 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:54:49.429214 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:54:49.455833 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:54:49.458046 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:54:49.465915 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:54:49.483637 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:54:49.493236 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:54:49.500840 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:54:49.506813 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:54:49.507945 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:54:49.509648 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:54:49.512175 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:54:49.522658 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:54:49.525025 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:54:49.527434 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:54:49.585410 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:54:49.587774 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:54:49.589559 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:54:49.591905 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:54:49.602446 (MainThread): Partial parsing not enabled
2021-04-30 18:54:49.633034 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:54:49.644857 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:54:49.648975 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:54:49.652825 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:54:49.744545 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake-test-db.example

2021-04-30 18:54:49.745112 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7837ea7b-a97c-4e4a-bf6c-b1d75783ce45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110817b80>]}
2021-04-30 18:54:49.750538 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7837ea7b-a97c-4e4a-bf6c-b1d75783ce45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11080dc40>]}
2021-04-30 18:54:49.750898 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:54:49.751811 (MainThread): 
2021-04-30 18:54:49.752122 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:54:49.753001 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:54:49.767881 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:54:49.768057 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:54:49.768156 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:54:50.805236 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.04 seconds
2021-04-30 18:54:50.810824 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:54:50.919285 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:54:50.927597 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:54:50.927774 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:54:50.927876 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:54:51.921381 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.99 seconds
2021-04-30 18:54:51.922861 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:54:52.255810 (MainThread): Using snowflake connection "master".
2021-04-30 18:54:52.255997 (MainThread): On master: BEGIN
2021-04-30 18:54:52.256110 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:54:53.372911 (MainThread): SQL status: SUCCESS 1 in 1.12 seconds
2021-04-30 18:54:53.373291 (MainThread): On master: COMMIT
2021-04-30 18:54:53.373727 (MainThread): Using snowflake connection "master".
2021-04-30 18:54:53.373983 (MainThread): On master: COMMIT
2021-04-30 18:54:53.664375 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2021-04-30 18:54:53.664674 (MainThread): On master: Close
2021-04-30 18:54:53.823598 (MainThread): 11:54:53 | Concurrency: 1 threads (target='dev')
2021-04-30 18:54:53.823981 (MainThread): 11:54:53 | 
2021-04-30 18:54:53.825754 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:54:53.826293 (Thread-1): 11:54:53 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-04-30 18:54:53.826714 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:54:53.826877 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:54:53.829354 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:54:53.829910 (Thread-1): finished collecting timing info
2021-04-30 18:54:53.864081 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:54:53.865221 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:54:53.865337 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:54:53.865433 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:54:54.405135 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2021-04-30 18:54:54.405486 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:54:54.405694 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-04-30 18:54:54.772468 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 18:54:54.773872 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:54:54.774077 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:54:54.774185 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:54:54.903570 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:54:54.911820 (Thread-1): finished collecting timing info
2021-04-30 18:54:54.912028 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:54:55.071478 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7837ea7b-a97c-4e4a-bf6c-b1d75783ce45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107ef4f0>]}
2021-04-30 18:54:55.071988 (Thread-1): 11:54:55 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 1.24s]
2021-04-30 18:54:55.072156 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:54:55.072321 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:54:55.072571 (Thread-1): 11:54:55 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 18:54:55.073107 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:54:55.073396 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:54:55.076726 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:54:55.077277 (Thread-1): finished collecting timing info
2021-04-30 18:54:55.079318 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:54:55.081070 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:54:55.081192 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:54:55.081293 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:54:55.788347 (Thread-1): SQL status: SUCCESS 1 in 0.71 seconds
2021-04-30 18:54:55.788591 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:54:55.788719 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 18:54:56.120274 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2021-04-30 18:54:56.121728 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:54:56.121975 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:54:56.122101 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:54:56.316984 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-04-30 18:54:56.318034 (Thread-1): finished collecting timing info
2021-04-30 18:54:56.318260 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:54:56.442950 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7837ea7b-a97c-4e4a-bf6c-b1d75783ce45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d8e50>]}
2021-04-30 18:54:56.443557 (Thread-1): 11:54:56 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.37s]
2021-04-30 18:54:56.443822 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:54:56.444003 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:54:56.444351 (Thread-1): 11:54:56 | 3 of 4 START view model dbt.sf_customer_purchases.................... [RUN]
2021-04-30 18:54:56.445183 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:54:56.445370 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:54:56.446786 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:54:56.447299 (Thread-1): finished collecting timing info
2021-04-30 18:54:56.449992 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:54:56.451221 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:54:56.451359 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:54:56.451459 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:54:57.243112 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-04-30 18:54:57.243405 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:54:57.243564 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */

  create or replace  view analytics.dbt.sf_customer_purchases  as (
    SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
  );
2021-04-30 18:54:57.524691 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2021-04-30 18:54:57.526422 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:54:57.526780 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:54:57.526957 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:54:57.623666 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2021-04-30 18:54:57.624860 (Thread-1): finished collecting timing info
2021-04-30 18:54:57.625094 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:54:57.733322 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7837ea7b-a97c-4e4a-bf6c-b1d75783ce45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e5520>]}
2021-04-30 18:54:57.733986 (Thread-1): 11:54:57 | 3 of 4 OK created view model dbt.sf_customer_purchases............... [SUCCESS 1 in 1.29s]
2021-04-30 18:54:57.734230 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:54:57.734521 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:54:57.735216 (Thread-1): 11:54:57 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-04-30 18:54:57.735839 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:54:57.736032 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:54:57.739999 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:54:57.740705 (Thread-1): finished collecting timing info
2021-04-30 18:54:57.744214 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:54:57.745411 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:54:57.745563 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:54:57.745680 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:54:58.423499 (Thread-1): SQL status: SUCCESS 1 in 0.68 seconds
2021-04-30 18:54:58.423855 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:54:58.424056 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-04-30 18:54:58.740877 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-04-30 18:54:58.742383 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:54:58.742654 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:54:58.742787 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:54:58.869061 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:54:58.870155 (Thread-1): finished collecting timing info
2021-04-30 18:54:58.870474 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:54:58.998072 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7837ea7b-a97c-4e4a-bf6c-b1d75783ce45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e5520>]}
2021-04-30 18:54:58.998550 (Thread-1): 11:54:58 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.26s]
2021-04-30 18:54:58.998728 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:54:59.000087 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:54:59.000483 (MainThread): Using snowflake connection "master".
2021-04-30 18:54:59.000611 (MainThread): On master: BEGIN
2021-04-30 18:54:59.000714 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:54:59.667422 (MainThread): SQL status: SUCCESS 1 in 0.67 seconds
2021-04-30 18:54:59.667734 (MainThread): On master: COMMIT
2021-04-30 18:54:59.667980 (MainThread): Using snowflake connection "master".
2021-04-30 18:54:59.668102 (MainThread): On master: COMMIT
2021-04-30 18:54:59.929011 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 18:54:59.929271 (MainThread): On master: Close
2021-04-30 18:55:00.228790 (MainThread): 11:55:00 | 
2021-04-30 18:55:00.229038 (MainThread): 11:55:00 | Finished running 4 view models in 10.48s.
2021-04-30 18:55:00.229200 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:55:00.229315 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:55:00.235145 (MainThread): 
2021-04-30 18:55:00.235346 (MainThread): Completed successfully
2021-04-30 18:55:00.235499 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:55:00.235739 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107ef8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107ef6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107ef070>]}
2021-04-30 18:55:00.235992 (MainThread): Flushing usage events
2021-04-30 18:58:07.123436 (MainThread): Running with dbt=0.19.1
2021-04-30 18:58:08.023648 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 18:58:08.028680 (MainThread): Tracking: tracking
2021-04-30 18:58:08.029085 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c81880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c1fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c1ff10>]}
2021-04-30 18:58:08.042152 (MainThread): Partial parsing not enabled
2021-04-30 18:58:08.043659 (MainThread): Parsing macros/catalog.sql
2021-04-30 18:58:08.046735 (MainThread): Parsing macros/adapters.sql
2021-04-30 18:58:08.089866 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 18:58:08.092644 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 18:58:08.095143 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 18:58:08.100578 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 18:58:08.114919 (MainThread): Parsing macros/core.sql
2021-04-30 18:58:08.120723 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 18:58:08.133012 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 18:58:08.136190 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 18:58:08.157648 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 18:58:08.197583 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 18:58:08.222823 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 18:58:08.225531 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 18:58:08.233234 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 18:58:08.250753 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 18:58:08.259742 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 18:58:08.267982 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 18:58:08.274933 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 18:58:08.276598 (MainThread): Parsing macros/etc/query.sql
2021-04-30 18:58:08.278621 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 18:58:08.281249 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 18:58:08.292758 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 18:58:08.295537 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 18:58:08.297822 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 18:58:08.350439 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 18:58:08.353635 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 18:58:08.356463 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 18:58:08.359420 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 18:58:08.369479 (MainThread): Partial parsing not enabled
2021-04-30 18:58:08.396004 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:58:08.406936 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:58:08.412160 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:58:08.416102 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:58:08.499651 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f392902-fdfd-45f7-9e0d-5d6b5c066536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106993580>]}
2021-04-30 18:58:08.504541 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f392902-fdfd-45f7-9e0d-5d6b5c066536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10696ec70>]}
2021-04-30 18:58:08.504806 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 18:58:08.506387 (MainThread): 
2021-04-30 18:58:08.506849 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:58:08.507807 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 18:58:08.520986 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 18:58:08.521119 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 18:58:08.521208 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 18:58:14.020009 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 5.50 seconds
2021-04-30 18:58:14.025553 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 18:58:17.170609 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 18:58:17.179392 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 18:58:17.179576 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 18:58:17.179691 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 18:58:17.908216 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.73 seconds
2021-04-30 18:58:17.909692 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 18:58:18.041825 (MainThread): Using snowflake connection "master".
2021-04-30 18:58:18.042028 (MainThread): On master: BEGIN
2021-04-30 18:58:18.042156 (MainThread): Opening a new connection, currently in state init
2021-04-30 18:58:19.578323 (MainThread): SQL status: SUCCESS 1 in 1.54 seconds
2021-04-30 18:58:19.578559 (MainThread): On master: COMMIT
2021-04-30 18:58:19.578755 (MainThread): Using snowflake connection "master".
2021-04-30 18:58:19.578857 (MainThread): On master: COMMIT
2021-04-30 18:58:20.112882 (MainThread): SQL status: SUCCESS 1 in 0.53 seconds
2021-04-30 18:58:20.113220 (MainThread): On master: Close
2021-04-30 18:58:20.360581 (MainThread): 11:58:20 | Concurrency: 1 threads (target='dev')
2021-04-30 18:58:20.360833 (MainThread): 11:58:20 | 
2021-04-30 18:58:20.362323 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:58:20.362721 (Thread-1): 11:58:20 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 18:58:20.363103 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:58:20.363253 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 18:58:20.365256 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:58:20.365855 (Thread-1): finished collecting timing info
2021-04-30 18:58:20.389366 (Thread-1): Dropping relation "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" because it is of type view
2021-04-30 18:58:20.396598 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:58:20.396764 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
2021-04-30 18:58:20.396863 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:58:21.363871 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-04-30 18:58:21.377793 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 18:58:21.378899 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:58:21.379000 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 18:58:21.507422 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:58:21.507691 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:58:21.507843 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 18:58:23.020420 (Thread-1): SQL status: SUCCESS 1 in 1.51 seconds
2021-04-30 18:58:23.022240 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:58:23.022636 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 18:58:23.022788 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 18:58:24.344633 (Thread-1): SQL status: SUCCESS 1 in 1.32 seconds
2021-04-30 18:58:24.358720 (Thread-1): finished collecting timing info
2021-04-30 18:58:24.358938 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 18:58:24.577435 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f392902-fdfd-45f7-9e0d-5d6b5c066536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10681b130>]}
2021-04-30 18:58:24.577913 (Thread-1): 11:58:24 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 4.21s]
2021-04-30 18:58:24.578082 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 18:58:24.578248 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:58:24.578931 (Thread-1): 11:58:24 | 2 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-04-30 18:58:24.579638 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:58:24.579874 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:58:24.581245 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:58:24.585933 (Thread-1): finished collecting timing info
2021-04-30 18:58:24.588046 (Thread-1): Dropping relation "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" because it is of type view
2021-04-30 18:58:24.589924 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:58:24.590122 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */
drop view if exists "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" cascade
2021-04-30 18:58:24.590314 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:58:29.744941 (Thread-1): SQL status: SUCCESS 1 in 5.15 seconds
2021-04-30 18:58:29.746876 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 18:58:29.748747 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:58:29.748879 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 18:58:31.124596 (Thread-1): SQL status: SUCCESS 1 in 1.38 seconds
2021-04-30 18:58:31.124828 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:58:31.124931 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
      );
2021-04-30 18:58:32.984403 (Thread-1): SQL status: SUCCESS 1 in 1.86 seconds
2021-04-30 18:58:32.985669 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:58:32.985881 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 18:58:32.985980 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 18:58:33.835144 (Thread-1): SQL status: SUCCESS 1 in 0.85 seconds
2021-04-30 18:58:33.836646 (Thread-1): finished collecting timing info
2021-04-30 18:58:33.836940 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 18:58:33.955265 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f392902-fdfd-45f7-9e0d-5d6b5c066536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10682d730>]}
2021-04-30 18:58:33.955816 (Thread-1): 11:58:33 | 2 of 4 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 9.38s]
2021-04-30 18:58:33.956038 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 18:58:33.956337 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:58:33.956972 (Thread-1): 11:58:33 | 3 of 4 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 18:58:33.957525 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:58:33.957735 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 18:58:33.960127 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:58:33.960708 (Thread-1): finished collecting timing info
2021-04-30 18:58:33.963250 (Thread-1): Dropping relation "ANALYTICS"."DBT"."SF_CUSTOMER_PURCHASES" because it is of type view
2021-04-30 18:58:33.965666 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:58:33.965849 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */
drop view if exists "ANALYTICS"."DBT"."SF_CUSTOMER_PURCHASES" cascade
2021-04-30 18:58:33.965966 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:58:34.812904 (Thread-1): SQL status: SUCCESS 1 in 0.85 seconds
2021-04-30 18:58:34.814839 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 18:58:34.816311 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:58:34.816443 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 18:58:34.940918 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 18:58:34.941191 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:58:34.941355 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 18:58:37.493012 (Thread-1): SQL status: SUCCESS 1 in 2.55 seconds
2021-04-30 18:58:37.494649 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:58:37.494877 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 18:58:37.494995 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 18:58:38.879882 (Thread-1): SQL status: SUCCESS 1 in 1.38 seconds
2021-04-30 18:58:38.880915 (Thread-1): finished collecting timing info
2021-04-30 18:58:38.881127 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 18:58:40.003604 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f392902-fdfd-45f7-9e0d-5d6b5c066536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10682dbe0>]}
2021-04-30 18:58:40.004137 (Thread-1): 11:58:40 | 3 of 4 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 6.05s]
2021-04-30 18:58:40.004305 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 18:58:40.004463 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:58:40.004937 (Thread-1): 11:58:40 | 4 of 4 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 18:58:40.005551 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:58:40.005863 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 18:58:40.009028 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:58:40.009539 (Thread-1): finished collecting timing info
2021-04-30 18:58:40.011166 (Thread-1): Dropping relation "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" because it is of type view
2021-04-30 18:58:40.012778 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:58:40.012889 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" cascade
2021-04-30 18:58:40.012990 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 18:58:41.058510 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-04-30 18:58:41.060486 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 18:58:41.061631 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:58:41.061768 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 18:58:41.188544 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 18:58:41.188898 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:58:41.189088 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-04-30 18:58:42.843152 (Thread-1): SQL status: SUCCESS 1 in 1.65 seconds
2021-04-30 18:58:42.844795 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:58:42.845007 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 18:58:42.845129 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 18:58:43.669192 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-04-30 18:58:43.670464 (Thread-1): finished collecting timing info
2021-04-30 18:58:43.670696 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 18:58:43.814754 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f392902-fdfd-45f7-9e0d-5d6b5c066536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bbaf40>]}
2021-04-30 18:58:43.815264 (Thread-1): 11:58:43 | 4 of 4 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.81s]
2021-04-30 18:58:43.815453 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 18:58:43.816961 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 18:58:43.817227 (MainThread): Using snowflake connection "master".
2021-04-30 18:58:43.817342 (MainThread): On master: BEGIN
2021-04-30 18:58:43.817451 (MainThread): Opening a new connection, currently in state closed
2021-04-30 18:58:45.033256 (MainThread): SQL status: SUCCESS 1 in 1.22 seconds
2021-04-30 18:58:45.033566 (MainThread): On master: COMMIT
2021-04-30 18:58:45.033828 (MainThread): Using snowflake connection "master".
2021-04-30 18:58:45.033980 (MainThread): On master: COMMIT
2021-04-30 18:58:45.315270 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-04-30 18:58:45.315576 (MainThread): On master: Close
2021-04-30 18:58:45.448850 (MainThread): 11:58:45 | 
2021-04-30 18:58:45.449103 (MainThread): 11:58:45 | Finished running 4 table models in 36.94s.
2021-04-30 18:58:45.449313 (MainThread): Connection 'master' was properly closed.
2021-04-30 18:58:45.449429 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 18:58:45.454962 (MainThread): 
2021-04-30 18:58:45.455154 (MainThread): Completed successfully
2021-04-30 18:58:45.455304 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 18:58:45.455503 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bbb4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068514f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b83130>]}
2021-04-30 18:58:45.455738 (MainThread): Flushing usage events
2021-04-30 19:00:36.417790 (MainThread): Running with dbt=0.19.1
2021-04-30 19:00:37.331656 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:00:37.333050 (MainThread): Tracking: tracking
2021-04-30 19:00:37.333538 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb1c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb1d00>]}
2021-04-30 19:00:37.346105 (MainThread): Partial parsing not enabled
2021-04-30 19:00:37.347558 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:00:37.350537 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:00:37.388777 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:00:37.391606 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:00:37.394021 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:00:37.399428 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:00:37.411692 (MainThread): Parsing macros/core.sql
2021-04-30 19:00:37.416753 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:00:37.427392 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:00:37.430544 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:00:37.453481 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:00:37.492728 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:00:37.517106 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:00:37.521561 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:00:37.530385 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:00:37.549322 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:00:37.558143 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:00:37.567031 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:00:37.573711 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:00:37.575519 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:00:37.577597 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:00:37.580204 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:00:37.591496 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:00:37.594544 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:00:37.597355 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:00:37.651865 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:00:37.654944 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:00:37.657367 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:00:37.659881 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:00:37.669015 (MainThread): Partial parsing not enabled
2021-04-30 19:00:37.696985 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:00:37.707230 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:00:37.712696 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:00:37.716083 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:00:37.801033 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25571e22-6b0f-4610-bf13-b8497c95338c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dac0a60>]}
2021-04-30 19:00:37.805969 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25571e22-6b0f-4610-bf13-b8497c95338c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10daadc10>]}
2021-04-30 19:00:37.806280 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:00:37.807563 (MainThread): 
2021-04-30 19:00:37.808045 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:00:37.808975 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:00:37.823434 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:00:37.823645 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:00:37.823762 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:00:39.074674 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.25 seconds
2021-04-30 19:00:39.079370 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:00:39.315086 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:00:39.323813 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:00:39.324004 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:00:39.324118 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:00:39.930764 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.61 seconds
2021-04-30 19:00:39.932254 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:00:40.088202 (MainThread): Using snowflake connection "master".
2021-04-30 19:00:40.088409 (MainThread): On master: BEGIN
2021-04-30 19:00:40.088540 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:00:41.503395 (MainThread): SQL status: SUCCESS 1 in 1.41 seconds
2021-04-30 19:00:41.503704 (MainThread): On master: COMMIT
2021-04-30 19:00:41.503984 (MainThread): Using snowflake connection "master".
2021-04-30 19:00:41.504137 (MainThread): On master: COMMIT
2021-04-30 19:00:41.874776 (MainThread): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 19:00:41.875036 (MainThread): On master: Close
2021-04-30 19:00:42.027090 (MainThread): 12:00:42 | Concurrency: 1 threads (target='dev')
2021-04-30 19:00:42.027346 (MainThread): 12:00:42 | 
2021-04-30 19:00:42.028920 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:00:42.029341 (Thread-1): 12:00:42 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 19:00:42.029715 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:00:42.029869 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:00:42.031740 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:00:42.032317 (Thread-1): finished collecting timing info
2021-04-30 19:00:42.068316 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:00:42.069498 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:00:42.069627 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:00:42.069727 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:00:43.011077 (Thread-1): SQL status: SUCCESS 1 in 0.94 seconds
2021-04-30 19:00:43.011319 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:00:43.011444 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:00:47.917563 (Thread-1): SQL status: SUCCESS 1 in 4.91 seconds
2021-04-30 19:00:47.919358 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:00:47.919576 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:00:47.919700 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:00:48.672499 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2021-04-30 19:00:48.685835 (Thread-1): finished collecting timing info
2021-04-30 19:00:48.686042 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:00:48.970582 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25571e22-6b0f-4610-bf13-b8497c95338c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3839a0>]}
2021-04-30 19:00:48.971036 (Thread-1): 12:00:48 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 6.94s]
2021-04-30 19:00:48.971206 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:00:48.971375 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:00:48.971668 (Thread-1): 12:00:48 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:00:48.972320 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:00:48.972477 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:00:48.975546 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:00:48.976067 (Thread-1): finished collecting timing info
2021-04-30 19:00:49.003347 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:00:49.003702 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */
drop table if exists "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" cascade
2021-04-30 19:00:49.003844 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:00:49.963030 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2021-04-30 19:00:49.971053 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:00:49.972622 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:00:49.972753 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:00:50.099778 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:00:50.100051 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:00:50.100211 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:00:50.835535 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2021-04-30 19:00:50.837175 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:00:50.837413 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:00:50.837536 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:00:51.083318 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-04-30 19:00:51.084367 (Thread-1): finished collecting timing info
2021-04-30 19:00:51.084574 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:00:51.195493 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25571e22-6b0f-4610-bf13-b8497c95338c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d383370>]}
2021-04-30 19:00:51.195881 (Thread-1): 12:00:51 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 2.22s]
2021-04-30 19:00:51.196024 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:00:51.196211 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:00:51.196688 (Thread-1): 12:00:51 | 3 of 4 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:00:51.197104 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:00:51.197227 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:00:51.199079 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:00:51.199565 (Thread-1): finished collecting timing info
2021-04-30 19:00:51.201379 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:00:51.202504 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:00:51.202661 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:00:51.202775 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:00:52.092076 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2021-04-30 19:00:52.092362 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:00:52.092519 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:00:55.887464 (Thread-1): SQL status: SUCCESS 1 in 3.79 seconds
2021-04-30 19:00:55.889085 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:00:55.889327 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:00:55.889454 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:00:57.075129 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-04-30 19:00:57.076144 (Thread-1): finished collecting timing info
2021-04-30 19:00:57.076345 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:00:57.207463 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25571e22-6b0f-4610-bf13-b8497c95338c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d383c40>]}
2021-04-30 19:00:57.208078 (Thread-1): 12:00:57 | 3 of 4 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 6.01s]
2021-04-30 19:00:57.208287 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:00:57.208476 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:00:57.208731 (Thread-1): 12:00:57 | 4 of 4 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:00:57.209183 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:00:57.209331 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:00:57.212401 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:00:57.213039 (Thread-1): finished collecting timing info
2021-04-30 19:00:57.215173 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:00:57.216140 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:00:57.216260 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:00:57.216367 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:00:58.019683 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2021-04-30 19:00:58.019967 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:00:58.020139 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-04-30 19:00:58.979659 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2021-04-30 19:00:58.981318 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:00:58.981537 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:00:58.981660 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:00:59.107049 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:00:59.107986 (Thread-1): finished collecting timing info
2021-04-30 19:00:59.108182 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:00:59.221522 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25571e22-6b0f-4610-bf13-b8497c95338c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed0b940>]}
2021-04-30 19:00:59.222044 (Thread-1): 12:00:59 | 4 of 4 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.01s]
2021-04-30 19:00:59.222247 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:00:59.223738 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:00:59.224013 (MainThread): Using snowflake connection "master".
2021-04-30 19:00:59.224128 (MainThread): On master: BEGIN
2021-04-30 19:00:59.224236 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:00:59.819640 (MainThread): SQL status: SUCCESS 1 in 0.60 seconds
2021-04-30 19:00:59.819952 (MainThread): On master: COMMIT
2021-04-30 19:00:59.820218 (MainThread): Using snowflake connection "master".
2021-04-30 19:00:59.820341 (MainThread): On master: COMMIT
2021-04-30 19:01:00.051517 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-04-30 19:01:00.051799 (MainThread): On master: Close
2021-04-30 19:01:00.171913 (MainThread): 12:01:00 | 
2021-04-30 19:01:00.172441 (MainThread): 12:01:00 | Finished running 3 table models, 1 view model in 22.36s.
2021-04-30 19:01:00.172742 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:01:00.172953 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:01:00.179062 (MainThread): 
2021-04-30 19:01:00.179265 (MainThread): Completed successfully
2021-04-30 19:01:00.179470 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 19:01:00.179823 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da80940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da807f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da80e80>]}
2021-04-30 19:01:00.180078 (MainThread): Flushing usage events
2021-04-30 19:08:39.509456 (MainThread): Running with dbt=0.19.1
2021-04-30 19:08:40.551085 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:08:40.552340 (MainThread): Tracking: tracking
2021-04-30 19:08:40.552654 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7f8c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7ccdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7ccee0>]}
2021-04-30 19:08:40.567208 (MainThread): Partial parsing not enabled
2021-04-30 19:08:40.568654 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:08:40.571674 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:08:40.613523 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:08:40.618067 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:08:40.620911 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:08:40.627227 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:08:40.642870 (MainThread): Parsing macros/core.sql
2021-04-30 19:08:40.648313 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:08:40.660197 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:08:40.663197 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:08:40.688043 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:08:40.731628 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:08:40.759967 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:08:40.762840 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:08:40.771997 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:08:40.791779 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:08:40.801137 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:08:40.809072 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:08:40.815707 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:08:40.817973 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:08:40.819867 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:08:40.822754 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:08:40.835573 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:08:40.838578 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:08:40.841293 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:08:40.899726 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:08:40.903290 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:08:40.905928 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:08:40.908769 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:08:40.921448 (MainThread): Partial parsing not enabled
2021-04-30 19:08:40.953313 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:08:40.965950 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:08:40.972665 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:08:40.976584 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:08:40.981815 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:08:41.079525 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4996a0>]}
2021-04-30 19:08:41.085517 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4bbf10>]}
2021-04-30 19:08:41.085818 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:08:41.086911 (MainThread): 
2021-04-30 19:08:41.087287 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:08:41.088366 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:08:41.102974 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:08:41.103127 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:08:41.103218 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:08:42.741811 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.64 seconds
2021-04-30 19:08:42.746587 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:08:42.914730 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:08:42.924402 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:08:42.924602 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:08:42.924726 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:08:43.792210 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.87 seconds
2021-04-30 19:08:43.793708 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:08:43.895257 (MainThread): Using snowflake connection "master".
2021-04-30 19:08:43.895475 (MainThread): On master: BEGIN
2021-04-30 19:08:43.895612 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:08:44.401786 (MainThread): SQL status: SUCCESS 1 in 0.51 seconds
2021-04-30 19:08:44.402048 (MainThread): On master: COMMIT
2021-04-30 19:08:44.402273 (MainThread): Using snowflake connection "master".
2021-04-30 19:08:44.402397 (MainThread): On master: COMMIT
2021-04-30 19:08:44.661184 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 19:08:44.661503 (MainThread): On master: Close
2021-04-30 19:08:44.789006 (MainThread): 12:08:44 | Concurrency: 1 threads (target='dev')
2021-04-30 19:08:44.789270 (MainThread): 12:08:44 | 
2021-04-30 19:08:44.790727 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:08:44.791102 (Thread-1): 12:08:44 | 1 of 5 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 19:08:44.791494 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:08:44.791656 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:08:44.793608 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:08:44.794172 (Thread-1): finished collecting timing info
2021-04-30 19:08:44.834316 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:08:44.835565 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:08:44.835680 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:08:44.835779 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:08:45.705944 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2021-04-30 19:08:45.706188 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:08:45.706312 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:08:47.078071 (Thread-1): SQL status: SUCCESS 1 in 1.37 seconds
2021-04-30 19:08:47.079629 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:08:47.079855 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:08:47.079983 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:08:47.469517 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2021-04-30 19:08:47.481922 (Thread-1): finished collecting timing info
2021-04-30 19:08:47.482312 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:08:47.611612 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd4ef10>]}
2021-04-30 19:08:47.612172 (Thread-1): 12:08:47 | 1 of 5 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 2.82s]
2021-04-30 19:08:47.612380 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:08:47.612576 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:08:47.613018 (Thread-1): 12:08:47 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:08:47.613802 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:08:47.614150 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:08:47.618051 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:08:47.618686 (Thread-1): finished collecting timing info
2021-04-30 19:08:47.643296 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:08:47.644935 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:08:47.645060 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:08:47.645170 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:08:48.360306 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2021-04-30 19:08:48.360516 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:08:48.360633 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:08:48.830143 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2021-04-30 19:08:48.831823 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:08:48.832101 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:08:48.832479 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:08:49.057642 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-04-30 19:08:49.058540 (Thread-1): finished collecting timing info
2021-04-30 19:08:49.058717 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:08:49.210298 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5faaf0>]}
2021-04-30 19:08:49.210777 (Thread-1): 12:08:49 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.60s]
2021-04-30 19:08:49.210943 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:08:49.211106 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:08:49.211388 (Thread-1): 12:08:49 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:08:49.212007 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:08:49.212176 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:08:49.216889 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:08:49.217433 (Thread-1): finished collecting timing info
2021-04-30 19:08:49.246688 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:08:49.247713 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:08:49.247868 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:08:49.247984 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:08:49.878137 (Thread-1): SQL status: SUCCESS 1 in 0.63 seconds
2021-04-30 19:08:49.878378 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:08:49.878505 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE;
2021-04-30 19:08:49.962386 (Thread-1): Snowflake query id: 019bf05c-0400-5bdb-0000-00313e8391b1
2021-04-30 19:08:49.962636 (Thread-1): Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 6 at position 28 unexpected ';'.
2021-04-30 19:08:49.962890 (Thread-1): finished collecting timing info
2021-04-30 19:08:49.963131 (Thread-1): On model.learn_dbt.dates: ROLLBACK
2021-04-30 19:08:50.234652 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:08:50.444805 (Thread-1): Database Error in model dates (models/example/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 6 at position 28 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/dates.sql
Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 162, in exception_handler
    yield
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 603, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 125, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/snowflake/connector/errors.py", line 85, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 6 at position 28 unexpected ';'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 120, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 314, in add_query
    connection, cursor = super().add_query(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 179, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model dates (models/example/dates.sql)
  001003 (42000): SQL compilation error:
  syntax error line 6 at position 28 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/dates.sql
2021-04-30 19:08:50.533122 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5fa9d0>]}
2021-04-30 19:08:50.533632 (Thread-1): 12:08:50 | 3 of 5 ERROR creating incremental model dbt.dates.................... [ERROR in 1.32s]
2021-04-30 19:08:50.533806 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:08:50.533944 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:08:50.534189 (Thread-1): 12:08:50 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:08:50.534759 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:08:50.534906 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:08:50.536075 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:08:50.537097 (Thread-1): finished collecting timing info
2021-04-30 19:08:50.540341 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:08:50.541810 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:08:50.541999 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:08:50.542099 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:08:51.246388 (Thread-1): SQL status: SUCCESS 1 in 0.70 seconds
2021-04-30 19:08:51.246676 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:08:51.246840 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:08:53.672342 (Thread-1): SQL status: SUCCESS 1 in 2.43 seconds
2021-04-30 19:08:53.674095 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:08:53.674333 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:08:53.674459 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:08:54.350758 (Thread-1): SQL status: SUCCESS 1 in 0.68 seconds
2021-04-30 19:08:54.351997 (Thread-1): finished collecting timing info
2021-04-30 19:08:54.352215 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:08:54.484699 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5fa130>]}
2021-04-30 19:08:54.485171 (Thread-1): 12:08:54 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.95s]
2021-04-30 19:08:54.485348 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:08:54.485521 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:08:54.486071 (Thread-1): 12:08:54 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:08:54.486451 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:08:54.486582 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:08:54.490286 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:08:54.490809 (Thread-1): finished collecting timing info
2021-04-30 19:08:54.492697 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:08:54.493614 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:08:54.493727 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:08:54.493819 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:08:55.263350 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2021-04-30 19:08:55.263645 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:08:55.263808 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-04-30 19:08:56.210297 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2021-04-30 19:08:56.211684 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:08:56.211911 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:08:56.212038 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:08:56.681275 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2021-04-30 19:08:56.682162 (Thread-1): finished collecting timing info
2021-04-30 19:08:56.682602 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:08:56.836632 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed04d40a-f7f7-482b-86bb-2ec8c0549abf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6c61f0>]}
2021-04-30 19:08:56.837160 (Thread-1): 12:08:56 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.35s]
2021-04-30 19:08:56.837362 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:08:56.838862 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:08:56.839157 (MainThread): Using snowflake connection "master".
2021-04-30 19:08:56.839279 (MainThread): On master: BEGIN
2021-04-30 19:08:56.839389 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:08:57.662897 (MainThread): SQL status: SUCCESS 1 in 0.82 seconds
2021-04-30 19:08:57.663377 (MainThread): On master: COMMIT
2021-04-30 19:08:57.663733 (MainThread): Using snowflake connection "master".
2021-04-30 19:08:57.663907 (MainThread): On master: COMMIT
2021-04-30 19:08:57.839300 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2021-04-30 19:08:57.839532 (MainThread): On master: Close
2021-04-30 19:08:58.111595 (MainThread): 12:08:58 | 
2021-04-30 19:08:58.111851 (MainThread): 12:08:58 | Finished running 3 table models, 1 view model, 1 incremental model in 17.02s.
2021-04-30 19:08:58.112004 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:08:58.112107 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:08:58.119190 (MainThread): 
2021-04-30 19:08:58.119395 (MainThread): Completed with 1 error and 0 warnings:
2021-04-30 19:08:58.119533 (MainThread): 
2021-04-30 19:08:58.119663 (MainThread): Database Error in model dates (models/example/dates.sql)
2021-04-30 19:08:58.119779 (MainThread):   001003 (42000): SQL compilation error:
2021-04-30 19:08:58.119885 (MainThread):   syntax error line 6 at position 28 unexpected ';'.
2021-04-30 19:08:58.119989 (MainThread):   compiled SQL at target/run/learn_dbt/models/example/dates.sql
2021-04-30 19:08:58.120112 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-04-30 19:08:58.120302 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d48aac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e70be80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7a8c10>]}
2021-04-30 19:08:58.120539 (MainThread): Flushing usage events
2021-04-30 19:09:10.700373 (MainThread): Running with dbt=0.19.1
2021-04-30 19:09:11.297272 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:09:11.298504 (MainThread): Tracking: tracking
2021-04-30 19:09:11.298918 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057cbaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067acbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067acd00>]}
2021-04-30 19:09:11.314823 (MainThread): Partial parsing not enabled
2021-04-30 19:09:11.315999 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:09:11.318887 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:09:11.354196 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:09:11.356969 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:09:11.359144 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:09:11.363819 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:09:11.375749 (MainThread): Parsing macros/core.sql
2021-04-30 19:09:11.380176 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:09:11.391092 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:09:11.393179 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:09:11.413512 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:09:11.449105 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:09:11.473972 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:09:11.476183 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:09:11.483278 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:09:11.500715 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:09:11.509313 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:09:11.516541 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:09:11.522002 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:09:11.523008 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:09:11.524127 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:09:11.525860 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:09:11.535907 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:09:11.538073 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:09:11.539889 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:09:11.592520 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:09:11.594875 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:09:11.596582 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:09:11.598474 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:09:11.607083 (MainThread): Partial parsing not enabled
2021-04-30 19:09:11.633265 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:09:11.644093 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:09:11.649203 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:09:11.652945 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:09:11.657072 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:09:11.744943 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108487970>]}
2021-04-30 19:09:11.750575 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084bbdf0>]}
2021-04-30 19:09:11.750875 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:09:11.752284 (MainThread): 
2021-04-30 19:09:11.752758 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:09:11.753937 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:09:11.767589 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:09:11.767737 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:09:11.767825 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:09:12.654683 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 0.89 seconds
2021-04-30 19:09:12.659195 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:09:12.765100 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:09:12.772236 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:09:12.772390 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:09:12.772479 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:09:13.891613 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.12 seconds
2021-04-30 19:09:13.892821 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:09:14.026346 (MainThread): Using snowflake connection "master".
2021-04-30 19:09:14.026547 (MainThread): On master: BEGIN
2021-04-30 19:09:14.026673 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:09:14.760303 (MainThread): SQL status: SUCCESS 1 in 0.73 seconds
2021-04-30 19:09:14.760602 (MainThread): On master: COMMIT
2021-04-30 19:09:14.760871 (MainThread): Using snowflake connection "master".
2021-04-30 19:09:14.761019 (MainThread): On master: COMMIT
2021-04-30 19:09:14.988967 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-04-30 19:09:14.989273 (MainThread): On master: Close
2021-04-30 19:09:15.101763 (MainThread): 12:09:15 | Concurrency: 1 threads (target='dev')
2021-04-30 19:09:15.102037 (MainThread): 12:09:15 | 
2021-04-30 19:09:15.104003 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:09:15.104631 (Thread-1): 12:09:15 | 1 of 5 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 19:09:15.105058 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:09:15.105218 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:09:15.107176 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:09:15.107736 (Thread-1): finished collecting timing info
2021-04-30 19:09:15.147921 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:09:15.149189 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:09:15.149329 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:09:15.149424 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:09:15.866199 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2021-04-30 19:09:15.866418 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:09:15.866530 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:09:17.360271 (Thread-1): SQL status: SUCCESS 1 in 1.49 seconds
2021-04-30 19:09:17.362099 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:09:17.362320 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:09:17.362440 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:09:17.855012 (Thread-1): SQL status: SUCCESS 1 in 0.49 seconds
2021-04-30 19:09:17.868800 (Thread-1): finished collecting timing info
2021-04-30 19:09:17.869157 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:09:17.970615 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d36ac0>]}
2021-04-30 19:09:17.971127 (Thread-1): 12:09:17 | 1 of 5 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 2.87s]
2021-04-30 19:09:17.971320 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:09:17.971564 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:09:17.971850 (Thread-1): 12:09:17 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:09:17.972609 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:09:17.972977 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:09:17.975951 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:09:17.976448 (Thread-1): finished collecting timing info
2021-04-30 19:09:17.998186 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:09:18.000219 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:09:18.000426 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:09:18.000581 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:09:18.591158 (Thread-1): SQL status: SUCCESS 1 in 0.59 seconds
2021-04-30 19:09:18.591442 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:09:18.591598 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:09:18.950781 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-04-30 19:09:18.952189 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:09:18.952409 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:09:18.952530 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:09:19.078872 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:09:19.079947 (Thread-1): finished collecting timing info
2021-04-30 19:09:19.080144 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:09:19.231687 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d36520>]}
2021-04-30 19:09:19.232516 (Thread-1): 12:09:19 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.26s]
2021-04-30 19:09:19.232889 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:09:19.233193 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:09:19.233831 (Thread-1): 12:09:19 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:09:19.234565 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:09:19.234883 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:09:19.244243 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:09:19.245080 (Thread-1): finished collecting timing info
2021-04-30 19:09:19.308084 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:09:19.309615 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:09:19.309781 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:09:19.309893 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:09:20.123299 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-04-30 19:09:20.123529 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:09:20.123648 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


      );
2021-04-30 19:09:21.451978 (Thread-1): SQL status: SUCCESS 1 in 1.33 seconds
2021-04-30 19:09:21.453799 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:09:21.454113 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:09:21.454250 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:09:21.974520 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2021-04-30 19:09:21.975505 (Thread-1): finished collecting timing info
2021-04-30 19:09:21.975676 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:09:22.090876 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d36ee0>]}
2021-04-30 19:09:22.091397 (Thread-1): 12:09:22 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 1 in 2.86s]
2021-04-30 19:09:22.091582 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:09:22.091748 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:09:22.092005 (Thread-1): 12:09:22 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:09:22.092597 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:09:22.092773 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:09:22.094696 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:09:22.095297 (Thread-1): finished collecting timing info
2021-04-30 19:09:22.097508 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:09:22.099010 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:09:22.099189 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:09:22.099317 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:09:22.675050 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2021-04-30 19:09:22.675332 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:09:22.675484 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:09:24.821174 (Thread-1): SQL status: SUCCESS 1 in 2.15 seconds
2021-04-30 19:09:24.823276 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:09:24.823571 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:09:24.823705 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:09:25.335188 (Thread-1): SQL status: SUCCESS 1 in 0.51 seconds
2021-04-30 19:09:25.336104 (Thread-1): finished collecting timing info
2021-04-30 19:09:25.336284 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:09:25.458991 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096abac0>]}
2021-04-30 19:09:25.459555 (Thread-1): 12:09:25 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.37s]
2021-04-30 19:09:25.459738 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:09:25.459990 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:09:25.460751 (Thread-1): 12:09:25 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:09:25.461397 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:09:25.461571 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:09:25.464937 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:09:25.465769 (Thread-1): finished collecting timing info
2021-04-30 19:09:25.469382 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:09:25.470534 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:09:25.470674 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:09:25.470793 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:09:26.521417 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-04-30 19:09:26.521804 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:09:26.521974 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-04-30 19:09:28.063592 (Thread-1): SQL status: SUCCESS 1 in 1.54 seconds
2021-04-30 19:09:28.064992 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:09:28.065337 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:09:28.065551 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:09:29.095566 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-04-30 19:09:29.096432 (Thread-1): finished collecting timing info
2021-04-30 19:09:29.096617 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:09:30.546475 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3919f65-bc38-4aa1-936b-e7de67282583', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106771100>]}
2021-04-30 19:09:30.546888 (Thread-1): 12:09:30 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 5.09s]
2021-04-30 19:09:30.547057 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:09:30.548645 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:09:30.549215 (MainThread): Using snowflake connection "master".
2021-04-30 19:09:30.549535 (MainThread): On master: BEGIN
2021-04-30 19:09:30.549781 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:09:31.315951 (MainThread): SQL status: SUCCESS 1 in 0.77 seconds
2021-04-30 19:09:31.316307 (MainThread): On master: COMMIT
2021-04-30 19:09:31.316595 (MainThread): Using snowflake connection "master".
2021-04-30 19:09:31.316804 (MainThread): On master: COMMIT
2021-04-30 19:09:31.608260 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2021-04-30 19:09:31.608514 (MainThread): On master: Close
2021-04-30 19:09:31.740705 (MainThread): 12:09:31 | 
2021-04-30 19:09:31.740950 (MainThread): 12:09:31 | Finished running 3 table models, 1 view model, 1 incremental model in 19.99s.
2021-04-30 19:09:31.741120 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:09:31.741231 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:09:31.747344 (MainThread): 
2021-04-30 19:09:31.747551 (MainThread): Completed successfully
2021-04-30 19:09:31.747722 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-30 19:09:31.747925 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057cbaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057cbee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10674eb80>]}
2021-04-30 19:09:31.748170 (MainThread): Flushing usage events
2021-04-30 19:10:18.768260 (MainThread): Running with dbt=0.19.1
2021-04-30 19:10:19.409248 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:10:19.410186 (MainThread): Tracking: tracking
2021-04-30 19:10:19.410559 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122718e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113246d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113246e20>]}
2021-04-30 19:10:19.423474 (MainThread): Partial parsing not enabled
2021-04-30 19:10:19.424641 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:10:19.427332 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:10:19.466732 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:10:19.469295 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:10:19.471086 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:10:19.475987 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:10:19.489713 (MainThread): Parsing macros/core.sql
2021-04-30 19:10:19.494922 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:10:19.507041 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:10:19.509142 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:10:19.539268 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:10:19.579446 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:10:19.606734 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:10:19.609204 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:10:19.618686 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:10:19.635972 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:10:19.644105 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:10:19.652259 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:10:19.658289 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:10:19.659359 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:10:19.660788 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:10:19.662680 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:10:19.674969 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:10:19.677447 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:10:19.679389 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:10:19.732240 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:10:19.735210 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:10:19.737011 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:10:19.738913 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:10:19.747704 (MainThread): Partial parsing not enabled
2021-04-30 19:10:19.776821 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:10:19.787976 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:10:19.792922 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:10:19.796076 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:10:19.801721 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:19.893647 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150239d0>]}
2021-04-30 19:10:19.899729 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115057e50>]}
2021-04-30 19:10:19.900333 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:10:19.901629 (MainThread): 
2021-04-30 19:10:19.902017 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:10:19.903045 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:10:19.918006 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:10:19.918167 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:10:19.918260 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:10:21.067434 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.15 seconds
2021-04-30 19:10:21.071769 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:10:21.186256 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:10:21.195345 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:10:21.195532 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:10:21.195644 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:10:21.882106 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.69 seconds
2021-04-30 19:10:21.884423 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:10:22.007560 (MainThread): Using snowflake connection "master".
2021-04-30 19:10:22.007763 (MainThread): On master: BEGIN
2021-04-30 19:10:22.007886 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:10:22.817705 (MainThread): SQL status: SUCCESS 1 in 0.81 seconds
2021-04-30 19:10:22.818119 (MainThread): On master: COMMIT
2021-04-30 19:10:22.818555 (MainThread): Using snowflake connection "master".
2021-04-30 19:10:22.818731 (MainThread): On master: COMMIT
2021-04-30 19:10:23.068356 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-04-30 19:10:23.068617 (MainThread): On master: Close
2021-04-30 19:10:23.192528 (MainThread): 12:10:23 | Concurrency: 1 threads (target='dev')
2021-04-30 19:10:23.192760 (MainThread): 12:10:23 | 
2021-04-30 19:10:23.194112 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:10:23.194472 (Thread-1): 12:10:23 | 1 of 5 START table model dbt.my_first_dbt_model...................... [RUN]
2021-04-30 19:10:23.194832 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:10:23.194978 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:10:23.197157 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:10:23.197731 (Thread-1): finished collecting timing info
2021-04-30 19:10:23.237097 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:10:23.238353 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:10:23.238496 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:10:23.238600 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:10:24.823835 (Thread-1): SQL status: SUCCESS 1 in 1.59 seconds
2021-04-30 19:10:24.824067 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:10:24.824193 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:10:26.316522 (Thread-1): SQL status: SUCCESS 1 in 1.49 seconds
2021-04-30 19:10:26.318557 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:10:26.318849 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:10:26.319065 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:10:27.188552 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2021-04-30 19:10:27.201668 (Thread-1): finished collecting timing info
2021-04-30 19:10:27.201892 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:10:27.304813 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147b1340>]}
2021-04-30 19:10:27.305333 (Thread-1): 12:10:27 | 1 of 5 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 4.11s]
2021-04-30 19:10:27.305513 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:10:27.305691 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:10:27.305943 (Thread-1): 12:10:27 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:10:27.306647 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:10:27.306979 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:10:27.310074 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:10:27.310608 (Thread-1): finished collecting timing info
2021-04-30 19:10:27.341040 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:10:27.342721 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:10:27.342889 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:10:27.342999 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:10:27.896253 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-04-30 19:10:27.896536 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:10:27.896695 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:10:28.589688 (Thread-1): SQL status: SUCCESS 1 in 0.69 seconds
2021-04-30 19:10:28.590861 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:10:28.591059 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:10:28.591162 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:10:28.684657 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-04-30 19:10:28.685802 (Thread-1): finished collecting timing info
2021-04-30 19:10:28.686023 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:10:28.805955 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147dca60>]}
2021-04-30 19:10:28.806528 (Thread-1): 12:10:28 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.50s]
2021-04-30 19:10:28.806796 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:10:28.807003 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:10:28.807525 (Thread-1): 12:10:28 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:10:28.808026 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:28.808197 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:10:28.816680 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:10:28.817536 (Thread-1): finished collecting timing info
2021-04-30 19:10:28.861463 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:28.861681 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:10:28.861798 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:10:30.304259 (Thread-1): SQL status: SUCCESS 1 in 1.44 seconds
2021-04-30 19:10:30.319273 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:30.319467 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:10:30.482226 (Thread-1): SQL status: SUCCESS 28 in 0.16 seconds
2021-04-30 19:10:30.489026 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:30.489277 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:10:30.574701 (Thread-1): SQL status: SUCCESS 28 in 0.09 seconds
2021-04-30 19:10:30.579701 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:30.579873 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:10:30.678631 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-04-30 19:10:30.716059 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:10:30.719445 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:30.719590 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:10:30.850307 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:10:30.850519 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:30.850641 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:10:31.835640 (Thread-1): SQL status: SUCCESS 0 in 0.98 seconds
2021-04-30 19:10:31.836728 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:10:31.836926 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:10:31.837097 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:10:32.255859 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2021-04-30 19:10:32.256799 (Thread-1): finished collecting timing info
2021-04-30 19:10:32.256976 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:10:32.390429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11628bdc0>]}
2021-04-30 19:10:32.390893 (Thread-1): 12:10:32 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.58s]
2021-04-30 19:10:32.391063 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:10:32.391229 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:10:32.391465 (Thread-1): 12:10:32 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:10:32.392057 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:10:32.392223 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:10:32.393890 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:10:32.394390 (Thread-1): finished collecting timing info
2021-04-30 19:10:32.396489 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:10:32.397725 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:10:32.397844 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:10:32.397954 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:10:32.976467 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2021-04-30 19:10:32.976708 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:10:32.976835 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:10:34.684853 (Thread-1): SQL status: SUCCESS 1 in 1.71 seconds
2021-04-30 19:10:34.688791 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:10:34.689318 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:10:34.689587 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:10:35.184486 (Thread-1): SQL status: SUCCESS 1 in 0.49 seconds
2021-04-30 19:10:35.185771 (Thread-1): finished collecting timing info
2021-04-30 19:10:35.186028 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:10:35.315836 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e12970>]}
2021-04-30 19:10:35.316374 (Thread-1): 12:10:35 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 2.92s]
2021-04-30 19:10:35.316570 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:10:35.316780 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:10:35.317036 (Thread-1): 12:10:35 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:10:35.317463 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:10:35.317741 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:10:35.320840 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:10:35.321453 (Thread-1): finished collecting timing info
2021-04-30 19:10:35.323815 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:10:35.324844 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:10:35.324967 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:10:35.325075 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:10:36.147856 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-04-30 19:10:36.148065 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:10:36.148173 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-04-30 19:10:37.204430 (Thread-1): SQL status: SUCCESS 1 in 1.06 seconds
2021-04-30 19:10:37.205809 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:10:37.206037 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:10:37.206170 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:10:37.331617 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:10:37.333070 (Thread-1): finished collecting timing info
2021-04-30 19:10:37.333357 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:10:37.845802 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '620a037d-967a-45a4-b8fc-099f29ae30f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151a0e50>]}
2021-04-30 19:10:37.846325 (Thread-1): 12:10:37 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.53s]
2021-04-30 19:10:37.846524 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:10:37.847917 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:10:37.848346 (MainThread): Using snowflake connection "master".
2021-04-30 19:10:37.848516 (MainThread): On master: BEGIN
2021-04-30 19:10:37.848647 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:10:38.608746 (MainThread): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 19:10:38.609056 (MainThread): On master: COMMIT
2021-04-30 19:10:38.609328 (MainThread): Using snowflake connection "master".
2021-04-30 19:10:38.609485 (MainThread): On master: COMMIT
2021-04-30 19:10:38.755407 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2021-04-30 19:10:38.755722 (MainThread): On master: Close
2021-04-30 19:10:38.874899 (MainThread): 12:10:38 | 
2021-04-30 19:10:38.875148 (MainThread): 12:10:38 | Finished running 3 table models, 1 view model, 1 incremental model in 18.97s.
2021-04-30 19:10:38.875308 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:10:38.875432 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:10:38.881840 (MainThread): 
2021-04-30 19:10:38.882049 (MainThread): Completed successfully
2021-04-30 19:10:38.882277 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-30 19:10:38.882538 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e17280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150512e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147b1970>]}
2021-04-30 19:10:38.882797 (MainThread): Flushing usage events
2021-04-30 19:14:08.891165 (MainThread): Running with dbt=0.19.1
2021-04-30 19:14:09.826095 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:14:09.827415 (MainThread): Tracking: tracking
2021-04-30 19:14:09.827777 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eae910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f77d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f77e50>]}
2021-04-30 19:14:09.843251 (MainThread): Partial parsing not enabled
2021-04-30 19:14:09.844783 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:14:09.848058 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:14:09.889106 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:14:09.892112 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:14:09.894199 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:14:09.899885 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:14:09.912571 (MainThread): Parsing macros/core.sql
2021-04-30 19:14:09.918764 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:14:09.929797 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:14:09.932292 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:14:09.955373 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:14:09.998116 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:14:10.025949 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:14:10.029001 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:14:10.039028 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:14:10.059716 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:14:10.068918 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:14:10.076659 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:14:10.083610 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:14:10.085515 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:14:10.087130 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:14:10.089385 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:14:10.101298 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:14:10.104568 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:14:10.107362 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:14:10.163637 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:14:10.166798 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:14:10.169591 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:14:10.172200 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:14:10.181554 (MainThread): Partial parsing not enabled
2021-04-30 19:14:10.213631 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:14:10.228862 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:14:10.235071 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:14:10.239739 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:14:10.245529 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:10.341756 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '279985a4-af53-4963-a7c7-aff0035c94cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108543220>]}
2021-04-30 19:14:10.346711 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '279985a4-af53-4963-a7c7-aff0035c94cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108caad30>]}
2021-04-30 19:14:10.346986 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:14:10.348391 (MainThread): 
2021-04-30 19:14:10.348835 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:14:10.350284 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:14:10.364962 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:14:10.365117 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:14:10.365206 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:14:11.985805 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.62 seconds
2021-04-30 19:14:11.991074 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:14:12.139292 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:14:12.148316 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:14:12.148509 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:14:12.148633 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:14:13.169326 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.02 seconds
2021-04-30 19:14:13.170549 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:14:13.304099 (MainThread): Using snowflake connection "master".
2021-04-30 19:14:13.304319 (MainThread): On master: BEGIN
2021-04-30 19:14:13.304489 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:14:14.061835 (MainThread): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 19:14:14.062087 (MainThread): On master: COMMIT
2021-04-30 19:14:14.062303 (MainThread): Using snowflake connection "master".
2021-04-30 19:14:14.062427 (MainThread): On master: COMMIT
2021-04-30 19:14:14.200692 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2021-04-30 19:14:14.201034 (MainThread): On master: Close
2021-04-30 19:14:14.331980 (MainThread): 12:14:14 | Concurrency: 1 threads (target='dev')
2021-04-30 19:14:14.332251 (MainThread): 12:14:14 | 
2021-04-30 19:14:14.334422 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:14:14.335062 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:14:14.335261 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:14:14.338450 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:14:14.339058 (Thread-1): finished collecting timing info
2021-04-30 19:14:14.339490 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:14:14.339670 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:14:14.340206 (Thread-1): 12:14:14 | 1 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:14:14.340538 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:14:14.340675 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:14:14.343241 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:14:14.343717 (Thread-1): finished collecting timing info
2021-04-30 19:14:14.381539 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:14:14.384500 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:14:14.384750 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:14:14.384909 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:14:15.812327 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-04-30 19:14:15.812534 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:14:15.812644 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:14:16.180731 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 19:14:16.182298 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:14:16.182531 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:14:16.182658 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:14:16.319038 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-04-30 19:14:16.327819 (Thread-1): finished collecting timing info
2021-04-30 19:14:16.328053 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:14:16.437175 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '279985a4-af53-4963-a7c7-aff0035c94cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c20040>]}
2021-04-30 19:14:16.437701 (Thread-1): 12:14:16 | 1 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 2.10s]
2021-04-30 19:14:16.437897 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:14:16.438096 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:14:16.438432 (Thread-1): 12:14:16 | 2 of 4 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:14:16.439077 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:16.439240 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:14:16.446469 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:14:16.447073 (Thread-1): finished collecting timing info
2021-04-30 19:14:16.499303 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:16.499657 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:14:16.499885 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:14:17.669147 (Thread-1): SQL status: SUCCESS 1 in 1.17 seconds
2021-04-30 19:14:17.681196 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:17.681447 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:14:17.822756 (Thread-1): SQL status: SUCCESS 28 in 0.14 seconds
2021-04-30 19:14:17.828686 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:17.828975 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:14:17.933834 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-04-30 19:14:17.938931 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:17.939101 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:14:18.008720 (Thread-1): SQL status: SUCCESS 28 in 0.07 seconds
2021-04-30 19:14:18.040005 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:14:18.042968 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:18.043086 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:14:18.165247 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 19:14:18.165499 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:18.165639 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:14:18.833664 (Thread-1): SQL status: SUCCESS 0 in 0.67 seconds
2021-04-30 19:14:18.836734 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:14:18.837307 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:14:18.837597 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:14:19.104268 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-04-30 19:14:19.110526 (Thread-1): finished collecting timing info
2021-04-30 19:14:19.110758 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:14:19.240192 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '279985a4-af53-4963-a7c7-aff0035c94cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fd8880>]}
2021-04-30 19:14:19.240837 (Thread-1): 12:14:19 | 2 of 4 OK created incremental model dbt.dates........................ [SUCCESS 0 in 2.80s]
2021-04-30 19:14:19.241055 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:14:19.241263 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:14:19.241676 (Thread-1): 12:14:19 | 3 of 4 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:14:19.242407 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:14:19.242583 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:14:19.244051 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:14:19.244578 (Thread-1): finished collecting timing info
2021-04-30 19:14:19.260436 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:14:19.262864 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:14:19.263192 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:14:19.263340 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:14:19.892556 (Thread-1): SQL status: SUCCESS 1 in 0.63 seconds
2021-04-30 19:14:19.898209 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:14:19.898498 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:14:21.414782 (Thread-1): SQL status: SUCCESS 1 in 1.52 seconds
2021-04-30 19:14:21.416767 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:14:21.417096 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:14:21.417241 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:14:21.988767 (Thread-1): SQL status: SUCCESS 1 in 0.57 seconds
2021-04-30 19:14:21.989800 (Thread-1): finished collecting timing info
2021-04-30 19:14:21.990002 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:14:22.205688 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '279985a4-af53-4963-a7c7-aff0035c94cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cbd8e0>]}
2021-04-30 19:14:22.206160 (Thread-1): 12:14:22 | 3 of 4 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 2.96s]
2021-04-30 19:14:22.206339 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:14:22.206516 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:14:22.206829 (Thread-1): 12:14:22 | 4 of 4 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:14:22.207543 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:14:22.207708 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:14:22.220368 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:14:22.220964 (Thread-1): finished collecting timing info
2021-04-30 19:14:22.223307 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:14:22.228097 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:14:22.228381 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:14:22.228585 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:14:22.776722 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-04-30 19:14:22.777092 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:14:22.777388 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__CTE__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__CTE__my_first_dbt_model
where id = 1
      );
2021-04-30 19:14:23.865337 (Thread-1): SQL status: SUCCESS 1 in 1.09 seconds
2021-04-30 19:14:23.867364 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:14:23.867761 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:14:23.867914 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:14:24.301100 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-04-30 19:14:24.302197 (Thread-1): finished collecting timing info
2021-04-30 19:14:24.302379 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:14:24.444503 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '279985a4-af53-4963-a7c7-aff0035c94cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108510e80>]}
2021-04-30 19:14:24.444971 (Thread-1): 12:14:24 | 4 of 4 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.24s]
2021-04-30 19:14:24.445141 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:14:24.446651 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:14:24.446958 (MainThread): Using snowflake connection "master".
2021-04-30 19:14:24.447071 (MainThread): On master: BEGIN
2021-04-30 19:14:24.447172 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:14:25.136721 (MainThread): SQL status: SUCCESS 1 in 0.69 seconds
2021-04-30 19:14:25.136930 (MainThread): On master: COMMIT
2021-04-30 19:14:25.137097 (MainThread): Using snowflake connection "master".
2021-04-30 19:14:25.137189 (MainThread): On master: COMMIT
2021-04-30 19:14:25.408248 (MainThread): SQL status: SUCCESS 1 in 0.27 seconds
2021-04-30 19:14:25.408543 (MainThread): On master: Close
2021-04-30 19:14:25.512788 (MainThread): 12:14:25 | 
2021-04-30 19:14:25.513005 (MainThread): 12:14:25 | Finished running 1 view model, 1 incremental model, 2 table models in 15.16s.
2021-04-30 19:14:25.513137 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:14:25.513233 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:14:25.519046 (MainThread): 
2021-04-30 19:14:25.519237 (MainThread): Completed successfully
2021-04-30 19:14:25.519372 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 19:14:25.519578 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104147580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c201f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c20970>]}
2021-04-30 19:14:25.519816 (MainThread): Flushing usage events
2021-04-30 19:15:12.852445 (MainThread): Running with dbt=0.19.1
2021-04-30 19:15:13.702749 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:15:13.703911 (MainThread): Tracking: tracking
2021-04-30 19:15:13.704257 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fe68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10805dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10805de80>]}
2021-04-30 19:15:13.716722 (MainThread): Partial parsing not enabled
2021-04-30 19:15:13.718203 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:15:13.721195 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:15:13.757573 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:15:13.760369 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:15:13.762716 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:15:13.768604 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:15:13.781286 (MainThread): Parsing macros/core.sql
2021-04-30 19:15:13.786529 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:15:13.797173 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:15:13.800113 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:15:13.821524 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:15:13.861389 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:15:13.889996 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:15:13.893607 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:15:13.901669 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:15:13.918545 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:15:13.927694 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:15:13.936141 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:15:13.942870 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:15:13.944842 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:15:13.946602 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:15:13.949012 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:15:13.961024 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:15:13.964121 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:15:13.967108 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:15:14.022578 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:15:14.025890 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:15:14.028590 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:15:14.031452 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:15:14.042278 (MainThread): Partial parsing not enabled
2021-04-30 19:15:14.069596 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:15:14.082009 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:15:14.087457 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:15:14.091703 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:15:14.097049 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:14.190077 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89efc3b1-7211-449b-a836-ef2ec72b65ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c9c2b0>]}
2021-04-30 19:15:14.195236 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89efc3b1-7211-449b-a836-ef2ec72b65ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109debcd0>]}
2021-04-30 19:15:14.195513 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:15:14.196868 (MainThread): 
2021-04-30 19:15:14.197337 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:15:14.198521 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:15:14.212564 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:15:14.212715 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:15:14.212811 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:15:15.568268 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.36 seconds
2021-04-30 19:15:15.573029 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:15:15.709919 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:15:15.718730 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:15:15.718925 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:15:15.719043 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:15:16.506202 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.79 seconds
2021-04-30 19:15:16.507469 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:15:16.620392 (MainThread): Using snowflake connection "master".
2021-04-30 19:15:16.620601 (MainThread): On master: BEGIN
2021-04-30 19:15:16.620734 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:15:17.424231 (MainThread): SQL status: SUCCESS 1 in 0.80 seconds
2021-04-30 19:15:17.424537 (MainThread): On master: COMMIT
2021-04-30 19:15:17.424811 (MainThread): Using snowflake connection "master".
2021-04-30 19:15:17.424966 (MainThread): On master: COMMIT
2021-04-30 19:15:17.766428 (MainThread): SQL status: SUCCESS 1 in 0.34 seconds
2021-04-30 19:15:17.766746 (MainThread): On master: Close
2021-04-30 19:15:17.876230 (MainThread): 12:15:17 | Concurrency: 1 threads (target='dev')
2021-04-30 19:15:17.876532 (MainThread): 12:15:17 | 
2021-04-30 19:15:17.878100 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:15:17.878601 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:15:17.878768 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:15:17.881898 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:15:17.882457 (Thread-1): finished collecting timing info
2021-04-30 19:15:17.882878 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:15:17.883055 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:15:17.883331 (Thread-1): 12:15:17 | 1 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:15:17.883863 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:15:17.884213 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:15:17.886692 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:15:17.887171 (Thread-1): finished collecting timing info
2021-04-30 19:15:17.920572 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:15:17.921974 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:15:17.922106 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:15:17.922206 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:15:18.501902 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2021-04-30 19:15:18.502154 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:15:18.502288 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:15:19.168454 (Thread-1): SQL status: SUCCESS 1 in 0.67 seconds
2021-04-30 19:15:19.170146 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:15:19.170402 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:15:19.170531 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:15:19.422172 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-04-30 19:15:19.430671 (Thread-1): finished collecting timing info
2021-04-30 19:15:19.430947 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:15:19.542328 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89efc3b1-7211-449b-a836-ef2ec72b65ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c6a700>]}
2021-04-30 19:15:19.542782 (Thread-1): 12:15:19 | 1 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.66s]
2021-04-30 19:15:19.543000 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:15:19.543197 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:15:19.543564 (Thread-1): 12:15:19 | 2 of 4 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:15:19.543987 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:19.544149 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:15:19.551338 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:15:19.551997 (Thread-1): finished collecting timing info
2021-04-30 19:15:19.599966 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:19.600217 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:15:19.600340 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:15:21.298368 (Thread-1): SQL status: SUCCESS 1 in 1.70 seconds
2021-04-30 19:15:21.310323 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:21.310479 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:15:21.823523 (Thread-1): SQL status: SUCCESS 28 in 0.51 seconds
2021-04-30 19:15:21.829181 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:21.829339 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:15:22.311536 (Thread-1): SQL status: SUCCESS 28 in 0.48 seconds
2021-04-30 19:15:22.317159 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:22.317329 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:15:22.566578 (Thread-1): SQL status: SUCCESS 28 in 0.25 seconds
2021-04-30 19:15:22.593610 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:15:22.596359 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:22.596468 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:15:22.718561 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 19:15:22.718838 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:22.718997 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:15:23.224451 (Thread-1): SQL status: SUCCESS 0 in 0.51 seconds
2021-04-30 19:15:23.226106 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:15:23.226340 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:15:23.226465 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:15:23.482353 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 19:15:23.488981 (Thread-1): finished collecting timing info
2021-04-30 19:15:23.489186 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:15:23.836788 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89efc3b1-7211-449b-a836-ef2ec72b65ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108097520>]}
2021-04-30 19:15:23.837332 (Thread-1): 12:15:23 | 2 of 4 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.29s]
2021-04-30 19:15:23.837537 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:15:23.837735 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:15:23.838154 (Thread-1): 12:15:23 | 3 of 4 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:15:23.838879 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:15:23.839050 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:15:23.840496 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:15:23.841000 (Thread-1): finished collecting timing info
2021-04-30 19:15:23.854280 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:15:23.855521 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:15:23.855640 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:15:23.855740 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:15:24.846926 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-04-30 19:15:24.847219 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:15:24.847381 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:15:26.507260 (Thread-1): SQL status: SUCCESS 1 in 1.66 seconds
2021-04-30 19:15:26.508632 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:15:26.508856 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:15:26.508983 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:15:27.066673 (Thread-1): SQL status: SUCCESS 1 in 0.56 seconds
2021-04-30 19:15:27.068003 (Thread-1): finished collecting timing info
2021-04-30 19:15:27.068248 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:15:27.168239 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89efc3b1-7211-449b-a836-ef2ec72b65ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cbbe20>]}
2021-04-30 19:15:27.168755 (Thread-1): 12:15:27 | 3 of 4 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.33s]
2021-04-30 19:15:27.168956 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:15:27.169153 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:15:27.169430 (Thread-1): 12:15:27 | 4 of 4 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:15:27.170027 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:15:27.170340 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:15:27.181317 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:15:27.181822 (Thread-1): finished collecting timing info
2021-04-30 19:15:27.183806 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:15:27.185010 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:15:27.185123 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:15:27.185218 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:15:27.946428 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 19:15:27.946718 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:15:27.946878 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__CTE__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__CTE__my_first_dbt_model
where id = 1
      );
2021-04-30 19:15:28.753787 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-04-30 19:15:28.755164 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:15:28.755393 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:15:28.755520 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:15:28.838802 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2021-04-30 19:15:28.839979 (Thread-1): finished collecting timing info
2021-04-30 19:15:28.840201 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:15:28.977627 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89efc3b1-7211-449b-a836-ef2ec72b65ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0310a0>]}
2021-04-30 19:15:28.978162 (Thread-1): 12:15:28 | 4 of 4 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 1.81s]
2021-04-30 19:15:28.978365 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:15:28.979974 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:15:28.980274 (MainThread): Using snowflake connection "master".
2021-04-30 19:15:28.980410 (MainThread): On master: BEGIN
2021-04-30 19:15:28.980512 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:15:29.795239 (MainThread): SQL status: SUCCESS 1 in 0.81 seconds
2021-04-30 19:15:29.795559 (MainThread): On master: COMMIT
2021-04-30 19:15:29.795874 (MainThread): Using snowflake connection "master".
2021-04-30 19:15:29.796037 (MainThread): On master: COMMIT
2021-04-30 19:15:30.009142 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-04-30 19:15:30.009408 (MainThread): On master: Close
2021-04-30 19:15:30.119555 (MainThread): 12:15:30 | 
2021-04-30 19:15:30.119816 (MainThread): 12:15:30 | Finished running 1 view model, 1 incremental model, 2 table models in 15.92s.
2021-04-30 19:15:30.119981 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:15:30.120098 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:15:30.126387 (MainThread): 
2021-04-30 19:15:30.126608 (MainThread): Completed successfully
2021-04-30 19:15:30.126790 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-04-30 19:15:30.127135 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c6b190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c6b280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c6bc70>]}
2021-04-30 19:15:30.127400 (MainThread): Flushing usage events
2021-04-30 19:19:32.478609 (MainThread): Running with dbt=0.19.1
2021-04-30 19:19:33.525605 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:19:33.527112 (MainThread): Tracking: tracking
2021-04-30 19:19:33.527589 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110439a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112025c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112025cd0>]}
2021-04-30 19:19:33.542989 (MainThread): Partial parsing not enabled
2021-04-30 19:19:33.544618 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:19:33.550476 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:19:33.592152 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:19:33.595024 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:19:33.597200 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:19:33.603329 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:19:33.617182 (MainThread): Parsing macros/core.sql
2021-04-30 19:19:33.622874 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:19:33.635733 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:19:33.638424 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:19:33.662613 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:19:33.706516 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:19:33.734286 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:19:33.737571 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:19:33.745849 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:19:33.764577 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:19:33.773585 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:19:33.781511 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:19:33.788761 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:19:33.790467 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:19:33.792282 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:19:33.794997 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:19:33.808283 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:19:33.811119 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:19:33.813700 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:19:33.880849 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:19:33.885019 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:19:33.888489 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:19:33.891668 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:19:33.907729 (MainThread): Partial parsing not enabled
2021-04-30 19:19:33.952023 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:19:33.965825 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:19:33.973313 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:19:33.977586 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:19:33.983888 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:34.087846 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c1d6a0>]}
2021-04-30 19:19:34.093285 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c1bee0>]}
2021-04-30 19:19:34.093572 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:19:34.095231 (MainThread): 
2021-04-30 19:19:34.095680 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:19:34.096764 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:19:34.111999 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:19:34.112157 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:19:34.112251 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:19:35.536948 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.42 seconds
2021-04-30 19:19:35.541726 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:19:35.660297 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:19:35.669176 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:19:35.669371 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:19:35.669488 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:19:36.637461 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.97 seconds
2021-04-30 19:19:36.639403 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:19:36.761534 (MainThread): Using snowflake connection "master".
2021-04-30 19:19:36.761741 (MainThread): On master: BEGIN
2021-04-30 19:19:36.761874 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:19:37.819878 (MainThread): SQL status: SUCCESS 1 in 1.06 seconds
2021-04-30 19:19:37.820132 (MainThread): On master: COMMIT
2021-04-30 19:19:37.820350 (MainThread): Using snowflake connection "master".
2021-04-30 19:19:37.820474 (MainThread): On master: COMMIT
2021-04-30 19:19:38.219400 (MainThread): SQL status: SUCCESS 1 in 0.40 seconds
2021-04-30 19:19:38.219669 (MainThread): On master: Close
2021-04-30 19:19:38.462809 (MainThread): 12:19:38 | Concurrency: 1 threads (target='dev')
2021-04-30 19:19:38.463165 (MainThread): 12:19:38 | 
2021-04-30 19:19:38.465191 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:19:38.465698 (Thread-1): 12:19:38 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-04-30 19:19:38.466290 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:19:38.466584 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:19:38.470427 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:19:38.476870 (Thread-1): finished collecting timing info
2021-04-30 19:19:38.514243 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:19:38.515316 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:19:38.515427 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:19:38.515515 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:19:39.299965 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2021-04-30 19:19:39.300251 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:19:39.300411 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:19:40.048940 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2021-04-30 19:19:40.052066 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:19:40.052357 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:19:40.052475 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:19:40.143086 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-04-30 19:19:40.158450 (Thread-1): finished collecting timing info
2021-04-30 19:19:40.158687 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:19:40.325821 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135bd340>]}
2021-04-30 19:19:40.326275 (Thread-1): 12:19:40 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 1.86s]
2021-04-30 19:19:40.326440 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:19:40.326603 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:19:40.326838 (Thread-1): 12:19:40 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:19:40.327724 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:19:40.327931 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:19:40.331064 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:19:40.331625 (Thread-1): finished collecting timing info
2021-04-30 19:19:40.359425 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:19:40.361094 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:19:40.361253 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:19:40.361365 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:19:41.109725 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2021-04-30 19:19:41.109930 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:19:41.110034 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:19:41.479266 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 19:19:41.480725 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:19:41.481072 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:19:41.481220 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:19:41.610987 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:19:41.611813 (Thread-1): finished collecting timing info
2021-04-30 19:19:41.611971 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:19:41.745602 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135a0100>]}
2021-04-30 19:19:41.746076 (Thread-1): 12:19:41 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.42s]
2021-04-30 19:19:41.746241 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:19:41.746403 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:19:41.746750 (Thread-1): 12:19:41 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:19:41.747268 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:41.747430 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:19:41.756925 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:19:41.757532 (Thread-1): finished collecting timing info
2021-04-30 19:19:41.790974 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:41.791233 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:19:41.791391 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:19:42.935399 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2021-04-30 19:19:42.947689 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:42.947876 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:19:43.049624 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-04-30 19:19:43.056654 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:43.056852 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:19:43.139200 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:19:43.143674 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:43.143847 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:19:43.226288 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:19:43.259531 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:19:43.262487 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:43.262596 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:19:43.387225 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 19:19:43.387445 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:43.387558 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:19:44.215635 (Thread-1): SQL status: SUCCESS 0 in 0.83 seconds
2021-04-30 19:19:44.217421 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:19:44.217909 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:19:44.218054 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:19:44.475060 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 19:19:44.475951 (Thread-1): finished collecting timing info
2021-04-30 19:19:44.476117 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:19:44.608322 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f45c70>]}
2021-04-30 19:19:44.608852 (Thread-1): 12:19:44 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 2.86s]
2021-04-30 19:19:44.609053 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:19:44.609245 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:19:44.609523 (Thread-1): 12:19:44 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:19:44.610034 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:19:44.610193 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:19:44.611871 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:19:44.612386 (Thread-1): finished collecting timing info
2021-04-30 19:19:44.614764 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:19:44.616358 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:19:44.616513 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:19:44.616625 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:19:45.399639 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2021-04-30 19:19:45.399892 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:19:45.400037 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:19:47.079460 (Thread-1): SQL status: SUCCESS 1 in 1.68 seconds
2021-04-30 19:19:47.080848 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:19:47.081270 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:19:47.081477 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:19:47.598212 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2021-04-30 19:19:47.599379 (Thread-1): finished collecting timing info
2021-04-30 19:19:47.599668 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:19:47.730661 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f2f250>]}
2021-04-30 19:19:47.731382 (Thread-1): 12:19:47 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.12s]
2021-04-30 19:19:47.731630 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:19:47.731883 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:19:47.732493 (Thread-1): 12:19:47 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:19:47.733136 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:19:47.733419 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:19:47.739416 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:19:47.740422 (Thread-1): finished collecting timing info
2021-04-30 19:19:47.744540 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:19:47.745684 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:19:47.745861 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:19:47.746051 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:19:49.091201 (Thread-1): SQL status: SUCCESS 1 in 1.35 seconds
2021-04-30 19:19:49.091618 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:19:49.091988 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
2021-04-30 19:19:50.640906 (Thread-1): SQL status: SUCCESS 1 in 1.55 seconds
2021-04-30 19:19:50.642680 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:19:50.642940 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:19:50.643053 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:19:50.755710 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2021-04-30 19:19:50.757057 (Thread-1): finished collecting timing info
2021-04-30 19:19:50.757268 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:19:50.892275 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cc68b02-94d1-4b76-8365-6a253e16670a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f45a60>]}
2021-04-30 19:19:50.893246 (Thread-1): 12:19:50 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.16s]
2021-04-30 19:19:50.893734 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:19:50.895368 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:19:50.895662 (MainThread): Using snowflake connection "master".
2021-04-30 19:19:50.895775 (MainThread): On master: BEGIN
2021-04-30 19:19:50.895876 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:19:51.608404 (MainThread): SQL status: SUCCESS 1 in 0.71 seconds
2021-04-30 19:19:51.608792 (MainThread): On master: COMMIT
2021-04-30 19:19:51.609149 (MainThread): Using snowflake connection "master".
2021-04-30 19:19:51.609351 (MainThread): On master: COMMIT
2021-04-30 19:19:51.760437 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2021-04-30 19:19:51.760663 (MainThread): On master: Close
2021-04-30 19:19:51.913256 (MainThread): 12:19:51 | 
2021-04-30 19:19:51.913465 (MainThread): 12:19:51 | Finished running 3 table models, 1 view model, 1 incremental model in 17.82s.
2021-04-30 19:19:51.913590 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:19:51.913705 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:19:51.922831 (MainThread): 
2021-04-30 19:19:51.923104 (MainThread): Completed successfully
2021-04-30 19:19:51.923388 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-30 19:19:51.923681 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d184f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d74be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ce1430>]}
2021-04-30 19:19:51.923967 (MainThread): Flushing usage events
2021-04-30 19:20:54.532366 (MainThread): Running with dbt=0.19.1
2021-04-30 19:20:55.494492 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:20:55.496790 (MainThread): Tracking: tracking
2021-04-30 19:20:55.497281 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e47a850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f45bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f45bc10>]}
2021-04-30 19:20:55.514949 (MainThread): Partial parsing not enabled
2021-04-30 19:20:55.516702 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:20:55.520195 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:20:55.563130 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:20:55.566109 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:20:55.568524 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:20:55.573914 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:20:55.586771 (MainThread): Parsing macros/core.sql
2021-04-30 19:20:55.592067 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:20:55.604463 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:20:55.607335 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:20:55.629377 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:20:55.668298 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:20:55.697885 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:20:55.700889 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:20:55.709012 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:20:55.725449 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:20:55.733916 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:20:55.741994 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:20:55.748604 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:20:55.750663 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:20:55.753004 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:20:55.755791 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:20:55.766644 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:20:55.769709 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:20:55.772431 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:20:55.824367 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:20:55.827496 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:20:55.830083 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:20:55.832860 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:20:55.843425 (MainThread): Partial parsing not enabled
2021-04-30 19:20:55.872947 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:20:55.887137 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:20:55.894177 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:20:55.897957 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:20:55.903251 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:20:55.993993 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11101d700>]}
2021-04-30 19:20:56.001090 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11116bc40>]}
2021-04-30 19:20:56.001491 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:20:56.003308 (MainThread): 
2021-04-30 19:20:56.003775 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:20:56.005417 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:20:56.019914 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:20:56.020064 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:20:56.020155 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:20:57.479399 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.46 seconds
2021-04-30 19:20:57.484586 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:20:57.606586 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:20:57.608754 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:20:57.608887 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:20:57.608993 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-04-30 19:20:58.724748 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.12 seconds
2021-04-30 19:20:58.725821 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:20:59.078766 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt_jeremy_test".
2021-04-30 19:20:59.079131 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt_jeremy_test".
2021-04-30 19:20:59.079339 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt_jeremy_test"
2021-04-30 19:20:59.085070 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt_jeremy_test".
2021-04-30 19:20:59.085210 (ThreadPoolExecutor-0_0): On create_analytics_dbt_jeremy_test: BEGIN
2021-04-30 19:20:59.085314 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-04-30 19:20:59.754278 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.67 seconds
2021-04-30 19:20:59.754500 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt_jeremy_test".
2021-04-30 19:20:59.754621 (ThreadPoolExecutor-0_0): On create_analytics_dbt_jeremy_test: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "create_analytics_dbt_jeremy_test"} */
create schema if not exists analytics.dbt_jeremy_test
2021-04-30 19:20:59.937974 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.18 seconds
2021-04-30 19:20:59.940167 (ThreadPoolExecutor-0_0): On create_analytics_dbt_jeremy_test: COMMIT
2021-04-30 19:20:59.940488 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt_jeremy_test".
2021-04-30 19:20:59.940617 (ThreadPoolExecutor-0_0): On create_analytics_dbt_jeremy_test: COMMIT
2021-04-30 19:21:00.045628 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.10 seconds
2021-04-30 19:21:00.045952 (ThreadPoolExecutor-0_0): On create_analytics_dbt_jeremy_test: Close
2021-04-30 19:21:00.169599 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:21:00.178236 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:21:00.178405 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:21:00.178512 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:21:00.822861 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.64 seconds
2021-04-30 19:21:00.824425 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:21:00.963871 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt_jeremy_test".
2021-04-30 19:21:00.966218 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt_jeremy_test".
2021-04-30 19:21:00.966350 (ThreadPoolExecutor-1_0): On list_analytics_dbt_jeremy_test: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt_jeremy_test"} */

    show terse objects in analytics.dbt_jeremy_test
2021-04-30 19:21:00.966462 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:21:03.486287 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 2.52 seconds
2021-04-30 19:21:03.487002 (ThreadPoolExecutor-1_0): On list_analytics_dbt_jeremy_test: Close
2021-04-30 19:21:03.599155 (MainThread): Using snowflake connection "master".
2021-04-30 19:21:03.599388 (MainThread): On master: BEGIN
2021-04-30 19:21:03.599527 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:21:04.449175 (MainThread): SQL status: SUCCESS 1 in 0.85 seconds
2021-04-30 19:21:04.449421 (MainThread): On master: COMMIT
2021-04-30 19:21:04.449639 (MainThread): Using snowflake connection "master".
2021-04-30 19:21:04.449755 (MainThread): On master: COMMIT
2021-04-30 19:21:04.643649 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2021-04-30 19:21:04.643869 (MainThread): On master: Close
2021-04-30 19:21:04.773997 (MainThread): 12:21:04 | Concurrency: 1 threads (target='dev')
2021-04-30 19:21:04.774234 (MainThread): 12:21:04 | 
2021-04-30 19:21:04.775818 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:21:04.776190 (Thread-1): 12:21:04 | 1 of 5 START table model dbt_jeremy_test.first_model................. [RUN]
2021-04-30 19:21:04.776565 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:21:04.776715 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:21:04.780242 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:21:04.780811 (Thread-1): finished collecting timing info
2021-04-30 19:21:04.816927 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:21:04.818160 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:21:04.818286 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:21:04.818379 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:21:05.573616 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 19:21:05.573895 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:21:05.574047 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_jeremy_test.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:21:06.829720 (Thread-1): SQL status: SUCCESS 1 in 1.26 seconds
2021-04-30 19:21:06.831376 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:21:06.831594 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:21:06.831714 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:21:07.617553 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-04-30 19:21:07.630845 (Thread-1): finished collecting timing info
2021-04-30 19:21:07.631054 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:21:07.743438 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c41c0>]}
2021-04-30 19:21:07.743952 (Thread-1): 12:21:07 | 1 of 5 OK created table model dbt_jeremy_test.first_model............ [SUCCESS 1 in 2.97s]
2021-04-30 19:21:07.744132 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:21:07.744308 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:21:07.744720 (Thread-1): 12:21:07 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:21:07.745653 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:21:07.745860 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:21:07.748978 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:21:07.750010 (Thread-1): finished collecting timing info
2021-04-30 19:21:07.772444 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:21:07.773904 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:21:07.774037 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:21:07.774133 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:21:08.405551 (Thread-1): SQL status: SUCCESS 1 in 0.63 seconds
2021-04-30 19:21:08.405847 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:21:08.406013 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:21:08.765738 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-04-30 19:21:08.767329 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:21:08.767558 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:21:08.767684 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:21:08.893744 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:21:08.895051 (Thread-1): finished collecting timing info
2021-04-30 19:21:08.895278 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:21:09.001354 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111101dc0>]}
2021-04-30 19:21:09.001871 (Thread-1): 12:21:09 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.26s]
2021-04-30 19:21:09.002057 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:21:09.002464 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:21:09.003117 (Thread-1): 12:21:09 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:21:09.003733 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:09.003926 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:21:09.011931 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:21:09.012601 (Thread-1): finished collecting timing info
2021-04-30 19:21:09.042428 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:09.042624 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:21:09.042732 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:21:11.509740 (Thread-1): SQL status: SUCCESS 1 in 2.47 seconds
2021-04-30 19:21:11.521449 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:11.521625 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:21:11.610375 (Thread-1): SQL status: SUCCESS 28 in 0.09 seconds
2021-04-30 19:21:11.616042 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:11.616177 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:21:11.700135 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:21:11.705158 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:11.705359 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:21:11.780701 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:21:11.810448 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:21:11.813443 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:11.813562 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:21:11.941400 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:21:11.941681 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:11.941841 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:21:12.549933 (Thread-1): SQL status: SUCCESS 0 in 0.61 seconds
2021-04-30 19:21:12.551575 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:21:12.551812 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:21:12.551937 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:21:12.777785 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2021-04-30 19:21:12.779206 (Thread-1): finished collecting timing info
2021-04-30 19:21:12.779414 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:21:12.893165 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110e1ac0>]}
2021-04-30 19:21:12.893691 (Thread-1): 12:21:12 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.89s]
2021-04-30 19:21:12.893884 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:21:12.894078 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:21:12.894529 (Thread-1): 12:21:12 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:21:12.895053 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:21:12.895229 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:21:12.897043 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:21:12.897569 (Thread-1): finished collecting timing info
2021-04-30 19:21:12.899754 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:21:12.901038 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:21:12.901165 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:21:12.901279 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:21:13.705231 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2021-04-30 19:21:13.705438 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:21:13.705552 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:21:15.645354 (Thread-1): SQL status: SUCCESS 1 in 1.94 seconds
2021-04-30 19:21:15.646827 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:21:15.647089 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:21:15.647218 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:21:15.833896 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-04-30 19:21:15.834928 (Thread-1): finished collecting timing info
2021-04-30 19:21:15.835133 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:21:15.959636 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f48a0a0>]}
2021-04-30 19:21:15.960153 (Thread-1): 12:21:15 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.06s]
2021-04-30 19:21:15.960349 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:21:15.960541 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:21:15.961119 (Thread-1): 12:21:15 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:21:15.961622 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:21:15.961781 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:21:15.964827 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:21:15.965388 (Thread-1): finished collecting timing info
2021-04-30 19:21:15.967557 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:21:15.968507 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:21:15.968631 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:21:15.968739 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:21:17.212157 (Thread-1): SQL status: SUCCESS 1 in 1.24 seconds
2021-04-30 19:21:17.212522 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:21:17.212742 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_jeremy_test.first_model
where id = 1
      );
2021-04-30 19:21:18.265884 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-04-30 19:21:18.267676 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:21:18.267921 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:21:18.268048 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:21:18.391693 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 19:21:18.392861 (Thread-1): finished collecting timing info
2021-04-30 19:21:18.393061 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:21:19.162373 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '764d336a-4893-4174-a877-ca29990e572e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110e1be0>]}
2021-04-30 19:21:19.162901 (Thread-1): 12:21:19 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.20s]
2021-04-30 19:21:19.163103 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:21:19.164675 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:21:19.164947 (MainThread): Using snowflake connection "master".
2021-04-30 19:21:19.165055 (MainThread): On master: BEGIN
2021-04-30 19:21:19.165154 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:21:19.801148 (MainThread): SQL status: SUCCESS 1 in 0.64 seconds
2021-04-30 19:21:19.801348 (MainThread): On master: COMMIT
2021-04-30 19:21:19.801558 (MainThread): Using snowflake connection "master".
2021-04-30 19:21:19.801656 (MainThread): On master: COMMIT
2021-04-30 19:21:19.937446 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2021-04-30 19:21:19.937682 (MainThread): On master: Close
2021-04-30 19:21:20.103492 (MainThread): 12:21:20 | 
2021-04-30 19:21:20.103742 (MainThread): 12:21:20 | Finished running 3 table models, 1 view model, 1 incremental model in 24.10s.
2021-04-30 19:21:20.103902 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:21:20.104018 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:21:20.109925 (MainThread): 
2021-04-30 19:21:20.110129 (MainThread): Completed successfully
2021-04-30 19:21:20.110276 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-30 19:21:20.110491 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111135190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109bf550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109bfa30>]}
2021-04-30 19:21:20.110735 (MainThread): Flushing usage events
2021-04-30 19:30:32.835757 (MainThread): Running with dbt=0.19.1
2021-04-30 19:30:33.819965 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:30:33.821664 (MainThread): Tracking: tracking
2021-04-30 19:30:33.822051 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104434a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105408dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105408e80>]}
2021-04-30 19:30:33.834817 (MainThread): Partial parsing not enabled
2021-04-30 19:30:33.836230 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:30:33.839757 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:30:33.884061 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:30:33.888315 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:30:33.891483 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:30:33.896802 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:30:33.910609 (MainThread): Parsing macros/core.sql
2021-04-30 19:30:33.915946 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:30:33.926867 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:30:33.929645 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:30:33.952836 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:30:33.991643 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:30:34.019907 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:30:34.022827 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:30:34.030767 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:30:34.048588 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:30:34.057095 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:30:34.064907 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:30:34.071231 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:30:34.073442 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:30:34.075362 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:30:34.077614 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:30:34.088447 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:30:34.091153 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:30:34.093536 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:30:34.147268 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:30:34.150034 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:30:34.152399 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:30:34.155287 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:30:34.163989 (MainThread): Partial parsing not enabled
2021-04-30 19:30:34.189890 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:30:34.202582 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:30:34.208770 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:30:34.213116 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:30:34.219070 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:34.311996 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

2021-04-30 19:30:34.312600 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40c6b2c0-abe0-4b10-ae22-bdce8c913f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069d3520>]}
2021-04-30 19:30:34.318880 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40c6b2c0-abe0-4b10-ae22-bdce8c913f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107111c70>]}
2021-04-30 19:30:34.319187 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:30:34.320134 (MainThread): 
2021-04-30 19:30:34.320446 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:30:34.321416 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:30:34.336142 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:30:34.336312 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:30:34.336409 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:30:35.459501 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.12 seconds
2021-04-30 19:30:35.464454 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:30:35.742707 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:30:35.751869 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:30:35.752054 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:30:35.752173 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:30:36.881224 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.13 seconds
2021-04-30 19:30:36.882619 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:30:37.029558 (MainThread): Using snowflake connection "master".
2021-04-30 19:30:37.029775 (MainThread): On master: BEGIN
2021-04-30 19:30:37.029891 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:30:38.847698 (MainThread): SQL status: SUCCESS 1 in 1.82 seconds
2021-04-30 19:30:38.847973 (MainThread): On master: COMMIT
2021-04-30 19:30:38.848211 (MainThread): Using snowflake connection "master".
2021-04-30 19:30:38.848336 (MainThread): On master: COMMIT
2021-04-30 19:30:39.095502 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-04-30 19:30:39.095708 (MainThread): On master: Close
2021-04-30 19:30:39.875586 (MainThread): 12:30:39 | Concurrency: 1 threads (target='dev')
2021-04-30 19:30:39.878849 (MainThread): 12:30:39 | 
2021-04-30 19:30:39.880882 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:30:39.881306 (Thread-1): 12:30:39 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-04-30 19:30:39.881679 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:30:39.881846 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:30:39.886658 (Thread-1): finished collecting timing info
2021-04-30 19:30:39.887224 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/compilation.py", line 509, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/compilation.py", line 410, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 582, in get_rendered
    return render_template(template, ctx, node)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 533, in render_template
    return template.render(ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 19, in top-level template code
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/context/base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/context/base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:30:39.934001 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40c6b2c0-abe0-4b10-ae22-bdce8c913f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082240d0>]}
2021-04-30 19:30:39.934399 (Thread-1): 12:30:39 | 1 of 5 ERROR creating table model dbt.first_model.................... [ERROR in 0.05s]
2021-04-30 19:30:39.934605 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:30:39.934844 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:30:39.935381 (Thread-1): 12:30:39 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:30:39.935670 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:30:39.935774 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:30:39.938476 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:30:39.938968 (Thread-1): finished collecting timing info
2021-04-30 19:30:39.967335 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:30:39.968953 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:30:39.969065 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:30:39.969161 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:30:40.628117 (Thread-1): SQL status: SUCCESS 1 in 0.66 seconds
2021-04-30 19:30:40.628402 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:30:40.628563 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:30:41.019616 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2021-04-30 19:30:41.021107 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:30:41.021336 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:30:41.021463 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:30:41.338865 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-04-30 19:30:41.347996 (Thread-1): finished collecting timing info
2021-04-30 19:30:41.348231 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:30:41.551882 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40c6b2c0-abe0-4b10-ae22-bdce8c913f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069a3310>]}
2021-04-30 19:30:41.552400 (Thread-1): 12:30:41 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.62s]
2021-04-30 19:30:41.552747 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:30:41.553509 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:30:41.554385 (Thread-1): 12:30:41 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:30:41.555232 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:41.555411 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:30:41.563114 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:30:41.563717 (Thread-1): finished collecting timing info
2021-04-30 19:30:41.606927 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:41.607101 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:30:41.607206 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:30:43.539918 (Thread-1): SQL status: SUCCESS 1 in 1.93 seconds
2021-04-30 19:30:43.551590 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:43.551747 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:30:43.652551 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-04-30 19:30:43.658134 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:43.658303 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:30:43.749750 (Thread-1): SQL status: SUCCESS 28 in 0.09 seconds
2021-04-30 19:30:43.755190 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:43.755396 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:30:44.477552 (Thread-1): SQL status: SUCCESS 28 in 0.72 seconds
2021-04-30 19:30:44.507444 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:30:44.511194 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:44.511383 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:30:44.639738 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:30:44.640015 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:44.640185 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:30:45.311738 (Thread-1): SQL status: SUCCESS 0 in 0.67 seconds
2021-04-30 19:30:45.313095 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:30:45.313329 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:30:45.313464 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:30:45.516194 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-04-30 19:30:45.522616 (Thread-1): finished collecting timing info
2021-04-30 19:30:45.522849 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:30:45.856672 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40c6b2c0-abe0-4b10-ae22-bdce8c913f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fde20>]}
2021-04-30 19:30:45.857210 (Thread-1): 12:30:45 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.30s]
2021-04-30 19:30:45.857408 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:30:45.857672 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:30:45.858040 (Thread-1): 12:30:45 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:30:45.858628 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:30:45.858930 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:30:45.860621 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:30:45.866652 (Thread-1): finished collecting timing info
2021-04-30 19:30:45.881611 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:30:45.883435 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:30:45.883570 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:30:45.883680 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:30:46.671330 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-04-30 19:30:46.671575 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:30:46.671709 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:30:49.046867 (Thread-1): SQL status: SUCCESS 1 in 2.38 seconds
2021-04-30 19:30:49.048881 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:30:49.049137 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:30:49.049266 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:30:49.569320 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2021-04-30 19:30:49.570604 (Thread-1): finished collecting timing info
2021-04-30 19:30:49.570853 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:30:49.747683 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40c6b2c0-abe0-4b10-ae22-bdce8c913f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107191370>]}
2021-04-30 19:30:49.748202 (Thread-1): 12:30:49 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.89s]
2021-04-30 19:30:49.748400 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:30:49.748669 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:30:49.749289 (Thread-1): 12:30:49 | 5 of 5 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-04-30 19:30:49.749589 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:30:49.751222 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:30:49.751636 (MainThread): Using snowflake connection "master".
2021-04-30 19:30:49.751825 (MainThread): On master: BEGIN
2021-04-30 19:30:49.751988 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:30:50.592209 (MainThread): SQL status: SUCCESS 1 in 0.84 seconds
2021-04-30 19:30:50.592463 (MainThread): On master: COMMIT
2021-04-30 19:30:50.592675 (MainThread): Using snowflake connection "master".
2021-04-30 19:30:50.592798 (MainThread): On master: COMMIT
2021-04-30 19:30:50.816249 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-04-30 19:30:50.816502 (MainThread): On master: Close
2021-04-30 19:30:50.953054 (MainThread): 12:30:50 | 
2021-04-30 19:30:50.953322 (MainThread): 12:30:50 | Finished running 3 table models, 1 view model, 1 incremental model in 16.63s.
2021-04-30 19:30:50.953533 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:30:50.953706 (MainThread): Connection 'model.learn_dbt.sf_customer_purchases' was properly closed.
2021-04-30 19:30:50.960475 (MainThread): 
2021-04-30 19:30:50.960686 (MainThread): Completed with 1 error and 0 warnings:
2021-04-30 19:30:50.960830 (MainThread): 
2021-04-30 19:30:50.960964 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:30:50.961084 (MainThread):   Required var 'my_first_variable' not found in config:
2021-04-30 19:30:50.961192 (MainThread):   Vars supplied to my_first_dbt_model = {}
2021-04-30 19:30:50.961299 (MainThread):   
2021-04-30 19:30:50.961406 (MainThread):   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:30:50.961515 (MainThread):   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:30:50.961640 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=1 TOTAL=5
2021-04-30 19:30:50.961841 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c9550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071011f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070ccdf0>]}
2021-04-30 19:30:50.962079 (MainThread): Flushing usage events
2021-04-30 19:31:39.449869 (MainThread): Running with dbt=0.19.1
2021-04-30 19:31:40.055170 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:31:40.056086 (MainThread): Tracking: tracking
2021-04-30 19:31:40.056418 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628aaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107266c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107266dc0>]}
2021-04-30 19:31:40.068329 (MainThread): Partial parsing not enabled
2021-04-30 19:31:40.069503 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:31:40.072418 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:31:40.108029 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:31:40.110342 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:31:40.112036 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:31:40.117027 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:31:40.128904 (MainThread): Parsing macros/core.sql
2021-04-30 19:31:40.133859 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:31:40.144343 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:31:40.146411 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:31:40.167281 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:31:40.205587 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:31:40.228306 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:31:40.230432 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:31:40.237478 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:31:40.253939 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:31:40.261912 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:31:40.268880 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:31:40.274560 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:31:40.275618 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:31:40.276745 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:31:40.278490 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:31:40.288683 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:31:40.291269 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:31:40.293093 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:31:40.342184 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:31:40.344680 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:31:40.346369 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:31:40.348240 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:31:40.357310 (MainThread): Partial parsing not enabled
2021-04-30 19:31:40.382616 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:31:40.395739 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:31:40.400711 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:31:40.403994 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:31:40.407963 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:40.495854 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

2021-04-30 19:31:40.496420 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9a8a207b-53a2-4624-baff-da4bc3fc6873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e5d3d0>]}
2021-04-30 19:31:40.503554 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9a8a207b-53a2-4624-baff-da4bc3fc6873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108faeca0>]}
2021-04-30 19:31:40.504024 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:31:40.505141 (MainThread): 
2021-04-30 19:31:40.505585 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:31:40.507427 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:31:40.525372 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:31:40.525558 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:31:40.525663 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:31:41.548816 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.02 seconds
2021-04-30 19:31:41.553935 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:31:41.675833 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:31:41.684308 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:31:41.684477 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:31:41.684590 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:31:42.324406 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.64 seconds
2021-04-30 19:31:42.325795 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:31:42.453969 (MainThread): Using snowflake connection "master".
2021-04-30 19:31:42.454152 (MainThread): On master: BEGIN
2021-04-30 19:31:42.454264 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:31:43.580582 (MainThread): SQL status: SUCCESS 1 in 1.13 seconds
2021-04-30 19:31:43.580849 (MainThread): On master: COMMIT
2021-04-30 19:31:43.581060 (MainThread): Using snowflake connection "master".
2021-04-30 19:31:43.581170 (MainThread): On master: COMMIT
2021-04-30 19:31:43.746358 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2021-04-30 19:31:43.746681 (MainThread): On master: Close
2021-04-30 19:31:43.863340 (MainThread): 12:31:43 | Concurrency: 1 threads (target='dev')
2021-04-30 19:31:43.863618 (MainThread): 12:31:43 | 
2021-04-30 19:31:43.865657 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:31:43.866228 (Thread-1): 12:31:43 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-04-30 19:31:43.866870 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:31:43.867155 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:31:43.874269 (Thread-1): finished collecting timing info
2021-04-30 19:31:43.874867 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/compilation.py", line 509, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/compilation.py", line 410, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 582, in get_rendered
    return render_template(template, ctx, node)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/clients/jinja.py", line 533, in render_template
    return template.render(ctx)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 19, in top-level template code
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/context/base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/context/base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/Users/jackyho/.local/share/virtualenvs/dbt-playground-GyArrx1M/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:31:43.921816 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a8a207b-53a2-4624-baff-da4bc3fc6873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108751c70>]}
2021-04-30 19:31:43.922181 (Thread-1): 12:31:43 | 1 of 5 ERROR creating table model dbt.first_model.................... [ERROR in 0.06s]
2021-04-30 19:31:43.922321 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:31:43.922458 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:31:43.922648 (Thread-1): 12:31:43 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:31:43.922928 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:31:43.923056 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:31:43.925544 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:31:43.926250 (Thread-1): finished collecting timing info
2021-04-30 19:31:43.955488 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:31:43.957362 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:31:43.957526 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:31:43.957623 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:31:44.823443 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2021-04-30 19:31:44.823725 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:31:44.823886 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:31:45.086824 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 19:31:45.088106 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:31:45.088284 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:31:45.088378 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:31:45.173592 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-04-30 19:31:45.184610 (Thread-1): finished collecting timing info
2021-04-30 19:31:45.184855 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:31:45.314172 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a8a207b-53a2-4624-baff-da4bc3fc6873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10912d940>]}
2021-04-30 19:31:45.314632 (Thread-1): 12:31:45 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.39s]
2021-04-30 19:31:45.314802 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:31:45.314969 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:31:45.315265 (Thread-1): 12:31:45 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:31:45.316023 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:45.316188 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:31:45.324905 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:31:45.327791 (Thread-1): finished collecting timing info
2021-04-30 19:31:45.370344 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:45.370554 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:31:45.370687 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:31:50.562287 (Thread-1): SQL status: SUCCESS 1 in 5.19 seconds
2021-04-30 19:31:50.572669 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:50.572817 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:31:50.676788 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-04-30 19:31:50.682263 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:50.682395 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:31:50.761589 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:31:50.767103 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:50.767343 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:31:50.839870 (Thread-1): SQL status: SUCCESS 28 in 0.07 seconds
2021-04-30 19:31:50.870695 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:31:50.873748 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:50.873875 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:31:50.999086 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:31:50.999364 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:50.999525 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:31:52.068600 (Thread-1): SQL status: SUCCESS 0 in 1.07 seconds
2021-04-30 19:31:52.069766 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:31:52.069990 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:31:52.070098 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:31:52.804448 (Thread-1): SQL status: SUCCESS 1 in 0.73 seconds
2021-04-30 19:31:52.809947 (Thread-1): finished collecting timing info
2021-04-30 19:31:52.810154 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:31:52.956025 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a8a207b-53a2-4624-baff-da4bc3fc6873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fb7b80>]}
2021-04-30 19:31:52.956422 (Thread-1): 12:31:52 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 7.64s]
2021-04-30 19:31:52.956563 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:31:52.956702 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:31:52.957132 (Thread-1): 12:31:52 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:31:52.957545 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:31:52.957672 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:31:52.958875 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:31:52.959320 (Thread-1): finished collecting timing info
2021-04-30 19:31:52.970168 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:31:52.971247 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:31:52.971352 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:31:52.971443 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:31:53.696944 (Thread-1): SQL status: SUCCESS 1 in 0.73 seconds
2021-04-30 19:31:53.697140 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:31:53.697233 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:31:55.663260 (Thread-1): SQL status: SUCCESS 1 in 1.97 seconds
2021-04-30 19:31:55.664344 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:31:55.664532 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:31:55.664624 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:31:56.212570 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-04-30 19:31:56.213321 (Thread-1): finished collecting timing info
2021-04-30 19:31:56.213465 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:31:56.341533 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a8a207b-53a2-4624-baff-da4bc3fc6873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a22d8b0>]}
2021-04-30 19:31:56.342074 (Thread-1): 12:31:56 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.38s]
2021-04-30 19:31:56.342243 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:31:56.342422 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:31:56.342610 (Thread-1): 12:31:56 | 5 of 5 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-04-30 19:31:56.343062 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:31:56.344451 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:31:56.344742 (MainThread): Using snowflake connection "master".
2021-04-30 19:31:56.344858 (MainThread): On master: BEGIN
2021-04-30 19:31:56.344962 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:31:58.034175 (MainThread): SQL status: SUCCESS 1 in 1.69 seconds
2021-04-30 19:31:58.034393 (MainThread): On master: COMMIT
2021-04-30 19:31:58.034569 (MainThread): Using snowflake connection "master".
2021-04-30 19:31:58.034670 (MainThread): On master: COMMIT
2021-04-30 19:31:58.176641 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2021-04-30 19:31:58.177013 (MainThread): On master: Close
2021-04-30 19:31:58.334127 (MainThread): 12:31:58 | 
2021-04-30 19:31:58.334343 (MainThread): 12:31:58 | Finished running 3 table models, 1 view model, 1 incremental model in 17.83s.
2021-04-30 19:31:58.334477 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:31:58.334570 (MainThread): Connection 'model.learn_dbt.sf_customer_purchases' was properly closed.
2021-04-30 19:31:58.341338 (MainThread): 
2021-04-30 19:31:58.341568 (MainThread): Completed with 1 error and 0 warnings:
2021-04-30 19:31:58.341743 (MainThread): 
2021-04-30 19:31:58.341891 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:31:58.342012 (MainThread):   Required var 'my_first_variable' not found in config:
2021-04-30 19:31:58.342134 (MainThread):   Vars supplied to my_first_dbt_model = {}
2021-04-30 19:31:58.342258 (MainThread):   
2021-04-30 19:31:58.342362 (MainThread):   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:31:58.342463 (MainThread):   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-04-30 19:31:58.342586 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=1 TOTAL=5
2021-04-30 19:31:58.342789 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f76e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10900d730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10900d040>]}
2021-04-30 19:31:58.343036 (MainThread): Flushing usage events
2021-04-30 19:33:46.389812 (MainThread): Running with dbt=0.19.1
2021-04-30 19:33:47.306956 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:33:47.308323 (MainThread): Tracking: tracking
2021-04-30 19:33:47.308828 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131fea00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d3d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d3dc0>]}
2021-04-30 19:33:47.321512 (MainThread): Partial parsing not enabled
2021-04-30 19:33:47.323003 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:33:47.326505 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:33:47.366522 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:33:47.369678 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:33:47.371794 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:33:47.377049 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:33:47.391257 (MainThread): Parsing macros/core.sql
2021-04-30 19:33:47.396476 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:33:47.410358 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:33:47.413191 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:33:47.437517 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:33:47.484180 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:33:47.510564 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:33:47.513649 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:33:47.522414 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:33:47.539725 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:33:47.549200 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:33:47.557997 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:33:47.565154 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:33:47.566602 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:33:47.568562 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:33:47.571420 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:33:47.582493 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:33:47.585860 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:33:47.588815 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:33:47.640909 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:33:47.644006 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:33:47.646571 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:33:47.649123 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:33:47.658289 (MainThread): Partial parsing not enabled
2021-04-30 19:33:47.685194 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:33:47.698455 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:33:47.704591 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:33:47.708834 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:33:47.714472 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:47.800395 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11579d9a0>]}
2021-04-30 19:33:47.805434 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115f2dd30>]}
2021-04-30 19:33:47.805703 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:33:47.807056 (MainThread): 
2021-04-30 19:33:47.807537 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:33:47.808520 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:33:47.822401 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:33:47.822549 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:33:47.822641 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:33:49.089750 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.27 seconds
2021-04-30 19:33:49.095056 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:33:49.310754 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:33:49.319427 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:33:49.319617 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:33:49.319744 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:33:50.063546 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.74 seconds
2021-04-30 19:33:50.064660 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:33:50.178087 (MainThread): Using snowflake connection "master".
2021-04-30 19:33:50.178288 (MainThread): On master: BEGIN
2021-04-30 19:33:50.178416 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:33:51.091956 (MainThread): SQL status: SUCCESS 1 in 0.91 seconds
2021-04-30 19:33:51.092260 (MainThread): On master: COMMIT
2021-04-30 19:33:51.092538 (MainThread): Using snowflake connection "master".
2021-04-30 19:33:51.092691 (MainThread): On master: COMMIT
2021-04-30 19:33:51.266837 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2021-04-30 19:33:51.267147 (MainThread): On master: Close
2021-04-30 19:33:51.396629 (MainThread): 12:33:51 | Concurrency: 1 threads (target='dev')
2021-04-30 19:33:51.396886 (MainThread): 12:33:51 | 
2021-04-30 19:33:51.398720 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:33:51.399251 (Thread-1): 12:33:51 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-04-30 19:33:51.399892 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:33:51.400151 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:33:51.405837 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:33:51.411906 (Thread-1): finished collecting timing info
2021-04-30 19:33:51.448018 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:33:51.449287 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:33:51.449415 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:33:51.449510 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:33:52.151804 (Thread-1): SQL status: SUCCESS 1 in 0.70 seconds
2021-04-30 19:33:52.152007 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:33:52.152108 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 2

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:33:52.767609 (Thread-1): SQL status: SUCCESS 1 in 0.62 seconds
2021-04-30 19:33:52.769104 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:33:52.769325 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:33:52.769453 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:33:52.895524 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:33:52.908735 (Thread-1): finished collecting timing info
2021-04-30 19:33:52.908974 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:33:53.031706 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141c0fd0>]}
2021-04-30 19:33:53.032137 (Thread-1): 12:33:53 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 1.63s]
2021-04-30 19:33:53.032305 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:33:53.032460 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:33:53.033026 (Thread-1): 12:33:53 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:33:53.033420 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:33:53.033570 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:33:53.036336 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:33:53.036855 (Thread-1): finished collecting timing info
2021-04-30 19:33:53.058720 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:33:53.060349 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:33:53.060516 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:33:53.060624 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:33:55.215549 (Thread-1): SQL status: SUCCESS 1 in 2.15 seconds
2021-04-30 19:33:55.215917 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:33:55.216138 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:33:55.575763 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-04-30 19:33:55.577291 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:33:55.577519 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:33:55.577644 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:33:55.696047 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 19:33:55.697337 (Thread-1): finished collecting timing info
2021-04-30 19:33:55.697568 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:33:55.830734 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11576c790>]}
2021-04-30 19:33:55.831257 (Thread-1): 12:33:55 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 2.80s]
2021-04-30 19:33:55.831457 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:33:55.831656 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:33:55.831966 (Thread-1): 12:33:55 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:33:55.832614 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:55.832805 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:33:55.840031 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:33:55.840619 (Thread-1): finished collecting timing info
2021-04-30 19:33:55.871312 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:55.871481 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:33:55.871581 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:33:56.927573 (Thread-1): SQL status: SUCCESS 1 in 1.06 seconds
2021-04-30 19:33:56.941056 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:56.941348 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:33:57.042311 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-04-30 19:33:57.047359 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:57.047515 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:33:57.124467 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:33:57.130573 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:57.130770 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:33:57.214529 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:33:57.244432 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:33:57.247349 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:57.247470 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:33:57.372795 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:33:57.373110 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:57.373279 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:33:57.863523 (Thread-1): SQL status: SUCCESS 0 in 0.49 seconds
2021-04-30 19:33:57.866685 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:33:57.867051 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:33:57.867203 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:33:58.123588 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-04-30 19:33:58.124912 (Thread-1): finished collecting timing info
2021-04-30 19:33:58.125169 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:33:58.249972 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117100970>]}
2021-04-30 19:33:58.250461 (Thread-1): 12:33:58 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 2.42s]
2021-04-30 19:33:58.250633 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:33:58.250803 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:33:58.251149 (Thread-1): 12:33:58 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:33:58.251741 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:33:58.251905 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:33:58.253740 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:33:58.254581 (Thread-1): finished collecting timing info
2021-04-30 19:33:58.259132 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:33:58.261238 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:33:58.261497 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:33:58.261668 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:33:59.236082 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-04-30 19:33:59.236369 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:33:59.236527 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:34:00.668426 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-04-30 19:34:00.670099 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:34:00.670355 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:34:00.670552 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:34:01.143296 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2021-04-30 19:34:01.144222 (Thread-1): finished collecting timing info
2021-04-30 19:34:01.144416 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:34:01.300670 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1171072e0>]}
2021-04-30 19:34:01.301293 (Thread-1): 12:34:01 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.05s]
2021-04-30 19:34:01.301520 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:34:01.301766 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:34:01.302402 (Thread-1): 12:34:01 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:34:01.302804 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:34:01.302951 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:34:01.307063 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:34:01.313120 (Thread-1): finished collecting timing info
2021-04-30 19:34:01.315573 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:34:01.316523 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:34:01.316643 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:34:01.316752 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:34:02.128182 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-04-30 19:34:02.128473 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:34:02.128634 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
2021-04-30 19:34:03.688252 (Thread-1): SQL status: SUCCESS 1 in 1.56 seconds
2021-04-30 19:34:03.690668 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:34:03.690981 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:34:03.691246 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:34:04.243962 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-04-30 19:34:04.245014 (Thread-1): finished collecting timing info
2021-04-30 19:34:04.245219 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:34:04.385521 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a240da50-7f25-4317-8621-cad77df197ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1171079d0>]}
2021-04-30 19:34:04.386046 (Thread-1): 12:34:04 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.08s]
2021-04-30 19:34:04.386241 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:34:04.388366 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:34:04.388734 (MainThread): Using snowflake connection "master".
2021-04-30 19:34:04.388881 (MainThread): On master: BEGIN
2021-04-30 19:34:04.388994 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:34:05.575610 (MainThread): SQL status: SUCCESS 1 in 1.19 seconds
2021-04-30 19:34:05.575829 (MainThread): On master: COMMIT
2021-04-30 19:34:05.576005 (MainThread): Using snowflake connection "master".
2021-04-30 19:34:05.576104 (MainThread): On master: COMMIT
2021-04-30 19:34:05.820290 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-04-30 19:34:05.820599 (MainThread): On master: Close
2021-04-30 19:34:05.953570 (MainThread): 12:34:05 | 
2021-04-30 19:34:05.953863 (MainThread): 12:34:05 | Finished running 3 table models, 1 view model, 1 incremental model in 18.15s.
2021-04-30 19:34:05.954098 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:34:05.954344 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:34:05.960568 (MainThread): 
2021-04-30 19:34:05.960780 (MainThread): Completed successfully
2021-04-30 19:34:05.960932 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-30 19:34:05.961140 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115ef4eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a9c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a97c0>]}
2021-04-30 19:34:05.961384 (MainThread): Flushing usage events
2021-04-30 19:35:02.803007 (MainThread): Running with dbt=0.19.1
2021-04-30 19:35:03.699000 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-30 19:35:03.700475 (MainThread): Tracking: tracking
2021-04-30 19:35:03.700833 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109142a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a116dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a116eb0>]}
2021-04-30 19:35:03.713142 (MainThread): Partial parsing not enabled
2021-04-30 19:35:03.714599 (MainThread): Parsing macros/catalog.sql
2021-04-30 19:35:03.717660 (MainThread): Parsing macros/adapters.sql
2021-04-30 19:35:03.752720 (MainThread): Parsing macros/materializations/merge.sql
2021-04-30 19:35:03.755941 (MainThread): Parsing macros/materializations/view.sql
2021-04-30 19:35:03.758646 (MainThread): Parsing macros/materializations/table.sql
2021-04-30 19:35:03.763954 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-30 19:35:03.776021 (MainThread): Parsing macros/core.sql
2021-04-30 19:35:03.780756 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-30 19:35:03.791690 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-30 19:35:03.794352 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-30 19:35:03.815949 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-30 19:35:03.861377 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-30 19:35:03.895400 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-30 19:35:03.898765 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-30 19:35:03.909261 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-30 19:35:03.928086 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-30 19:35:03.940982 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-30 19:35:03.949232 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-30 19:35:03.955696 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-30 19:35:03.957817 (MainThread): Parsing macros/etc/query.sql
2021-04-30 19:35:03.959853 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-30 19:35:03.962474 (MainThread): Parsing macros/etc/datetime.sql
2021-04-30 19:35:03.973464 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-30 19:35:03.976316 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-30 19:35:03.979249 (MainThread): Parsing macros/adapters/common.sql
2021-04-30 19:35:04.033898 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-30 19:35:04.036687 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-30 19:35:04.039121 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-30 19:35:04.042434 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-30 19:35:04.052180 (MainThread): Partial parsing not enabled
2021-04-30 19:35:04.080620 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:35:04.093316 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:35:04.098753 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:35:04.102906 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:35:04.108009 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:04.199289 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6e2490>]}
2021-04-30 19:35:04.204387 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be50c70>]}
2021-04-30 19:35:04.204675 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-30 19:35:04.205855 (MainThread): 
2021-04-30 19:35:04.206228 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:35:04.207302 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-04-30 19:35:04.221533 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-04-30 19:35:04.221686 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-04-30 19:35:04.221780 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-30 19:35:05.404004 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.18 seconds
2021-04-30 19:35:05.409188 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-04-30 19:35:05.525536 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-04-30 19:35:05.532837 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-04-30 19:35:05.532992 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-04-30 19:35:05.533100 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-30 19:35:06.294926 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.76 seconds
2021-04-30 19:35:06.296201 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-04-30 19:35:06.440200 (MainThread): Using snowflake connection "master".
2021-04-30 19:35:06.440409 (MainThread): On master: BEGIN
2021-04-30 19:35:06.440542 (MainThread): Opening a new connection, currently in state init
2021-04-30 19:35:07.033512 (MainThread): SQL status: SUCCESS 1 in 0.59 seconds
2021-04-30 19:35:07.033821 (MainThread): On master: COMMIT
2021-04-30 19:35:07.034097 (MainThread): Using snowflake connection "master".
2021-04-30 19:35:07.034254 (MainThread): On master: COMMIT
2021-04-30 19:35:07.222506 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2021-04-30 19:35:07.222815 (MainThread): On master: Close
2021-04-30 19:35:07.416872 (MainThread): 12:35:07 | Concurrency: 1 threads (target='dev')
2021-04-30 19:35:07.417128 (MainThread): 12:35:07 | 
2021-04-30 19:35:07.418692 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:35:07.419100 (Thread-1): 12:35:07 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-04-30 19:35:07.419522 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:35:07.419679 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-04-30 19:35:07.423822 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:35:07.424378 (Thread-1): finished collecting timing info
2021-04-30 19:35:07.460711 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-04-30 19:35:07.461956 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:35:07.462069 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-04-30 19:35:07.462161 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:35:08.273219 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-04-30 19:35:08.273487 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:35:08.273616 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-04-30 19:35:09.533655 (Thread-1): SQL status: SUCCESS 1 in 1.26 seconds
2021-04-30 19:35:09.535529 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:35:09.535770 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-04-30 19:35:09.535897 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-04-30 19:35:10.481334 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2021-04-30 19:35:10.495164 (Thread-1): finished collecting timing info
2021-04-30 19:35:10.495406 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-04-30 19:35:10.652374 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6d880>]}
2021-04-30 19:35:10.652972 (Thread-1): 12:35:10 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 3.23s]
2021-04-30 19:35:10.653210 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-04-30 19:35:10.653623 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:35:10.654516 (Thread-1): 12:35:10 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-04-30 19:35:10.655457 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:35:10.655669 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:35:10.658736 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:35:10.659316 (Thread-1): finished collecting timing info
2021-04-30 19:35:10.681359 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-04-30 19:35:10.682889 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:35:10.683008 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-04-30 19:35:10.683104 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:35:11.597253 (Thread-1): SQL status: SUCCESS 1 in 0.91 seconds
2021-04-30 19:35:11.597536 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:35:11.597696 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-04-30 19:35:11.969287 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-04-30 19:35:11.970797 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:35:11.971041 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-04-30 19:35:11.971171 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-04-30 19:35:12.096893 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:35:12.097882 (Thread-1): finished collecting timing info
2021-04-30 19:35:12.098077 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-04-30 19:35:12.210981 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b710bb0>]}
2021-04-30 19:35:12.211462 (Thread-1): 12:35:12 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.56s]
2021-04-30 19:35:12.211636 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-04-30 19:35:12.211813 (Thread-1): Began running node model.learn_dbt.dates
2021-04-30 19:35:12.212083 (Thread-1): 12:35:12 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-04-30 19:35:12.212757 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:12.212925 (Thread-1): Compiling model.learn_dbt.dates
2021-04-30 19:35:12.219923 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-04-30 19:35:12.220495 (Thread-1): finished collecting timing info
2021-04-30 19:35:12.251873 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:12.252054 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-04-30 19:35:12.252156 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:35:13.765348 (Thread-1): SQL status: SUCCESS 1 in 1.51 seconds
2021-04-30 19:35:13.779358 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:13.779551 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-04-30 19:35:13.872438 (Thread-1): SQL status: SUCCESS 28 in 0.09 seconds
2021-04-30 19:35:13.878553 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:13.878743 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:35:13.969600 (Thread-1): SQL status: SUCCESS 28 in 0.09 seconds
2021-04-30 19:35:13.975359 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:13.975548 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-04-30 19:35:14.050724 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-04-30 19:35:14.081647 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-04-30 19:35:14.084708 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:14.084846 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-04-30 19:35:14.209681 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-04-30 19:35:14.209960 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:14.210115 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-04-30 19:35:17.786026 (Thread-1): SQL status: SUCCESS 0 in 3.58 seconds
2021-04-30 19:35:17.787578 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:35:17.787814 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-04-30 19:35:17.787942 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-04-30 19:35:18.349809 (Thread-1): SQL status: SUCCESS 1 in 0.56 seconds
2021-04-30 19:35:18.351216 (Thread-1): finished collecting timing info
2021-04-30 19:35:18.351424 (Thread-1): On model.learn_dbt.dates: Close
2021-04-30 19:35:19.224973 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d05d6d0>]}
2021-04-30 19:35:19.225487 (Thread-1): 12:35:19 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 7.01s]
2021-04-30 19:35:19.225680 (Thread-1): Finished running node model.learn_dbt.dates
2021-04-30 19:35:19.225877 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:35:19.226153 (Thread-1): 12:35:19 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-04-30 19:35:19.226951 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:35:19.227126 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-04-30 19:35:19.228878 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:35:19.229453 (Thread-1): finished collecting timing info
2021-04-30 19:35:19.231542 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-04-30 19:35:19.232744 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:35:19.232863 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-04-30 19:35:19.232969 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:35:20.441469 (Thread-1): SQL status: SUCCESS 1 in 1.21 seconds
2021-04-30 19:35:20.441754 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:35:20.441904 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-04-30 19:35:21.905965 (Thread-1): SQL status: SUCCESS 1 in 1.46 seconds
2021-04-30 19:35:21.907612 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:35:21.907839 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-04-30 19:35:21.907962 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-04-30 19:35:22.557609 (Thread-1): SQL status: SUCCESS 1 in 0.65 seconds
2021-04-30 19:35:22.558760 (Thread-1): finished collecting timing info
2021-04-30 19:35:22.558969 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-04-30 19:35:23.235880 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d05ddf0>]}
2021-04-30 19:35:23.236427 (Thread-1): 12:35:23 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 4.01s]
2021-04-30 19:35:23.236629 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-04-30 19:35:23.236857 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:35:23.237150 (Thread-1): 12:35:23 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-04-30 19:35:23.237813 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:35:23.237971 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-04-30 19:35:23.240983 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:35:23.241518 (Thread-1): finished collecting timing info
2021-04-30 19:35:23.243584 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-04-30 19:35:23.244454 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:35:23.244569 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-04-30 19:35:23.244671 (Thread-1): Opening a new connection, currently in state closed
2021-04-30 19:35:24.001333 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-04-30 19:35:24.001604 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:35:24.001786 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
2021-04-30 19:35:24.958051 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2021-04-30 19:35:24.959584 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:35:24.959822 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-04-30 19:35:24.959942 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-04-30 19:35:25.086329 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2021-04-30 19:35:25.087602 (Thread-1): finished collecting timing info
2021-04-30 19:35:25.087801 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-04-30 19:35:25.191716 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2162b628-ba9f-4ff0-bc4e-f513bec49b3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0a7130>]}
2021-04-30 19:35:25.192230 (Thread-1): 12:35:25 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 1.95s]
2021-04-30 19:35:25.192419 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-04-30 19:35:25.193925 (MainThread): Acquiring new snowflake connection "master".
2021-04-30 19:35:25.194205 (MainThread): Using snowflake connection "master".
2021-04-30 19:35:25.194305 (MainThread): On master: BEGIN
2021-04-30 19:35:25.194398 (MainThread): Opening a new connection, currently in state closed
2021-04-30 19:35:25.943321 (MainThread): SQL status: SUCCESS 1 in 0.75 seconds
2021-04-30 19:35:25.943610 (MainThread): On master: COMMIT
2021-04-30 19:35:25.943866 (MainThread): Using snowflake connection "master".
2021-04-30 19:35:25.944014 (MainThread): On master: COMMIT
2021-04-30 19:35:26.225257 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-04-30 19:35:26.225506 (MainThread): On master: Close
2021-04-30 19:35:26.348766 (MainThread): 12:35:26 | 
2021-04-30 19:35:26.349004 (MainThread): 12:35:26 | Finished running 3 table models, 1 view model, 1 incremental model in 22.14s.
2021-04-30 19:35:26.349154 (MainThread): Connection 'master' was properly closed.
2021-04-30 19:35:26.349383 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-04-30 19:35:26.355065 (MainThread): 
2021-04-30 19:35:26.355234 (MainThread): Completed successfully
2021-04-30 19:35:26.355349 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-30 19:35:26.355513 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6d8550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be5af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6d5e0>]}
2021-04-30 19:35:26.355711 (MainThread): Flushing usage events
2021-05-01 05:13:59.433388 (MainThread): Running with dbt=0.19.1
2021-05-01 05:14:00.651030 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-01 05:14:00.654020 (MainThread): Tracking: tracking
2021-05-01 05:14:00.655043 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1037c3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104760ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104760fd0>]}
2021-05-01 05:14:00.682717 (MainThread): Partial parsing not enabled
2021-05-01 05:14:00.684581 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:14:00.689109 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:14:00.749813 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:14:00.755712 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:14:00.758581 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:14:00.766268 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:14:00.782499 (MainThread): Parsing macros/core.sql
2021-05-01 05:14:00.788309 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:14:00.801124 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:14:00.803947 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:14:00.828751 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:14:00.872987 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:14:00.901985 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:14:00.905022 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:14:00.914149 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:14:00.932430 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:14:00.942353 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:14:00.951501 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:14:00.958845 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:14:00.961089 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:14:00.962955 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:14:00.965647 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:14:00.977555 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:14:00.981282 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:14:00.983750 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:14:01.042530 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:14:01.046499 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:14:01.049179 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:14:01.052572 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:14:01.063774 (MainThread): Partial parsing not enabled
2021-05-01 05:14:01.094999 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:14:01.108520 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:14:01.116348 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:14:01.121208 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:14:01.128188 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:01.228636 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d68b50>]}
2021-05-01 05:14:01.234596 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d98ac0>]}
2021-05-01 05:14:01.235019 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:14:01.236284 (MainThread): 
2021-05-01 05:14:01.236696 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:14:01.237743 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-05-01 05:14:01.252782 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-05-01 05:14:01.253012 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-05-01 05:14:01.253121 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-01 05:14:02.568839 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.32 seconds
2021-05-01 05:14:02.573199 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-05-01 05:14:02.712463 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:14:02.721183 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:14:02.721374 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:14:02.721490 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-01 05:14:03.381556 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.66 seconds
2021-05-01 05:14:03.383116 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:14:03.734602 (MainThread): Using snowflake connection "master".
2021-05-01 05:14:03.734897 (MainThread): On master: BEGIN
2021-05-01 05:14:03.735023 (MainThread): Opening a new connection, currently in state init
2021-05-01 05:14:04.544514 (MainThread): SQL status: SUCCESS 1 in 0.81 seconds
2021-05-01 05:14:04.544707 (MainThread): On master: COMMIT
2021-05-01 05:14:04.544866 (MainThread): Using snowflake connection "master".
2021-05-01 05:14:04.544952 (MainThread): On master: COMMIT
2021-05-01 05:14:04.702120 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2021-05-01 05:14:04.702329 (MainThread): On master: Close
2021-05-01 05:14:04.820180 (MainThread): 22:14:04 | Concurrency: 1 threads (target='dev')
2021-05-01 05:14:04.820446 (MainThread): 22:14:04 | 
2021-05-01 05:14:04.822195 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:14:04.822653 (Thread-1): 22:14:04 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-05-01 05:14:04.823067 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:14:04.823298 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-05-01 05:14:04.826653 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:14:04.828158 (Thread-1): finished collecting timing info
2021-05-01 05:14:04.862965 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:14:04.864884 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:14:04.865052 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-05-01 05:14:04.865152 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:14:05.546488 (Thread-1): SQL status: SUCCESS 1 in 0.68 seconds
2021-05-01 05:14:05.546777 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:14:05.547001 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-05-01 05:14:09.157210 (Thread-1): SQL status: SUCCESS 1 in 3.61 seconds
2021-05-01 05:14:09.158892 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:14:09.159139 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:14:09.159271 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:14:09.701878 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2021-05-01 05:14:09.716422 (Thread-1): finished collecting timing info
2021-05-01 05:14:09.716654 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-05-01 05:14:09.835566 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d2f370>]}
2021-05-01 05:14:09.836085 (Thread-1): 22:14:09 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 5.01s]
2021-05-01 05:14:09.836280 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:14:09.836473 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:14:09.836745 (Thread-1): 22:14:09 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-05-01 05:14:09.837379 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:14:09.837742 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:14:09.840791 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:14:09.841388 (Thread-1): finished collecting timing info
2021-05-01 05:14:09.865718 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:14:09.867511 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:14:09.867856 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-05-01 05:14:09.868049 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:14:10.618641 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2021-05-01 05:14:10.618873 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:14:10.619002 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-05-01 05:14:11.012854 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2021-05-01 05:14:11.014112 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:14:11.014328 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:14:11.014441 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:14:11.080970 (Thread-1): SQL status: SUCCESS 1 in 0.07 seconds
2021-05-01 05:14:11.081810 (Thread-1): finished collecting timing info
2021-05-01 05:14:11.081960 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-05-01 05:14:11.186896 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cf3c10>]}
2021-05-01 05:14:11.187358 (Thread-1): 22:14:11 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.35s]
2021-05-01 05:14:11.187526 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:14:11.187694 (Thread-1): Began running node model.learn_dbt.dates
2021-05-01 05:14:11.188097 (Thread-1): 22:14:11 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-05-01 05:14:11.188542 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:11.188695 (Thread-1): Compiling model.learn_dbt.dates
2021-05-01 05:14:11.196530 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-05-01 05:14:11.197072 (Thread-1): finished collecting timing info
2021-05-01 05:14:11.227264 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:11.227441 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-05-01 05:14:11.227539 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:14:13.519496 (Thread-1): SQL status: SUCCESS 1 in 2.29 seconds
2021-05-01 05:14:13.532323 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:13.532516 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-05-01 05:14:14.888312 (Thread-1): SQL status: SUCCESS 28 in 1.36 seconds
2021-05-01 05:14:14.894254 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:14.894439 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:14:15.852765 (Thread-1): SQL status: SUCCESS 28 in 0.96 seconds
2021-05-01 05:14:15.857537 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:15.857677 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:14:15.966691 (Thread-1): SQL status: SUCCESS 28 in 0.11 seconds
2021-05-01 05:14:15.994274 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-05-01 05:14:15.997629 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:15.997761 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-05-01 05:14:16.120036 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2021-05-01 05:14:16.120264 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:16.120391 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-05-01 05:14:17.412960 (Thread-1): SQL status: SUCCESS 0 in 1.29 seconds
2021-05-01 05:14:17.414131 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:14:17.414326 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:14:17.414429 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:14:18.257423 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-05-01 05:14:18.258677 (Thread-1): finished collecting timing info
2021-05-01 05:14:18.258878 (Thread-1): On model.learn_dbt.dates: Close
2021-05-01 05:14:18.406659 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cf100>]}
2021-05-01 05:14:18.407164 (Thread-1): 22:14:18 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 7.22s]
2021-05-01 05:14:18.407383 (Thread-1): Finished running node model.learn_dbt.dates
2021-05-01 05:14:18.407649 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:14:18.408282 (Thread-1): 22:14:18 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-05-01 05:14:18.408915 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:14:18.409111 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-05-01 05:14:18.411495 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:14:18.412437 (Thread-1): finished collecting timing info
2021-05-01 05:14:18.414923 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:14:18.416507 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:14:18.416817 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-05-01 05:14:18.417038 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:14:18.918564 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-05-01 05:14:18.918802 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:14:18.918927 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-05-01 05:14:20.940322 (Thread-1): SQL status: SUCCESS 1 in 2.02 seconds
2021-05-01 05:14:20.942037 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:14:20.942275 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:14:20.942400 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:14:21.554170 (Thread-1): SQL status: SUCCESS 1 in 0.61 seconds
2021-05-01 05:14:21.555222 (Thread-1): finished collecting timing info
2021-05-01 05:14:21.555461 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-05-01 05:14:21.662412 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ac790>]}
2021-05-01 05:14:21.662945 (Thread-1): 22:14:21 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 3.25s]
2021-05-01 05:14:21.663142 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:14:21.663339 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:14:21.663567 (Thread-1): 22:14:21 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-05-01 05:14:21.664137 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:14:21.664292 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-05-01 05:14:21.667282 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:14:21.668056 (Thread-1): finished collecting timing info
2021-05-01 05:14:21.670330 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:14:21.671223 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:14:21.671327 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-05-01 05:14:21.671416 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:14:22.315282 (Thread-1): SQL status: SUCCESS 1 in 0.64 seconds
2021-05-01 05:14:22.315629 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:14:22.315795 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
2021-05-01 05:14:23.200600 (Thread-1): SQL status: SUCCESS 1 in 0.88 seconds
2021-05-01 05:14:23.202049 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:14:23.202284 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:14:23.202393 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:14:23.280796 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2021-05-01 05:14:23.282092 (Thread-1): finished collecting timing info
2021-05-01 05:14:23.282316 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-05-01 05:14:23.393877 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00345c81-6ad2-4e6b-81dd-582e0620661f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ac2b0>]}
2021-05-01 05:14:23.394327 (Thread-1): 22:14:23 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 1.73s]
2021-05-01 05:14:23.394498 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:14:23.395878 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:14:23.396160 (MainThread): Using snowflake connection "master".
2021-05-01 05:14:23.396267 (MainThread): On master: BEGIN
2021-05-01 05:14:23.396366 (MainThread): Opening a new connection, currently in state closed
2021-05-01 05:14:24.231178 (MainThread): SQL status: SUCCESS 1 in 0.83 seconds
2021-05-01 05:14:24.231496 (MainThread): On master: COMMIT
2021-05-01 05:14:24.231708 (MainThread): Using snowflake connection "master".
2021-05-01 05:14:24.231819 (MainThread): On master: COMMIT
2021-05-01 05:14:24.367705 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2021-05-01 05:14:24.368001 (MainThread): On master: Close
2021-05-01 05:14:24.503745 (MainThread): 22:14:24 | 
2021-05-01 05:14:24.503966 (MainThread): 22:14:24 | Finished running 3 table models, 1 view model, 1 incremental model in 23.27s.
2021-05-01 05:14:24.504118 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:14:24.504237 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-05-01 05:14:24.509951 (MainThread): 
2021-05-01 05:14:24.510142 (MainThread): Completed successfully
2021-05-01 05:14:24.510265 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-05-01 05:14:24.510451 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d2040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cda100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cda490>]}
2021-05-01 05:14:24.510660 (MainThread): Flushing usage events
2021-05-01 05:16:15.293489 (MainThread): Running with dbt=0.19.1
2021-05-01 05:16:16.194217 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-05-01 05:16:16.195602 (MainThread): Tracking: tracking
2021-05-01 05:16:16.196417 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11004d9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11102cd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11102c490>]}
2021-05-01 05:16:16.210174 (MainThread): Partial parsing not enabled
2021-05-01 05:16:16.211922 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:16:16.217127 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:16:16.256334 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:16:16.259096 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:16:16.262046 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:16:16.268961 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:16:16.282253 (MainThread): Parsing macros/core.sql
2021-05-01 05:16:16.287585 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:16:16.300561 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:16:16.303453 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:16:16.327285 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:16:16.370284 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:16:16.398534 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:16:16.401340 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:16:16.409598 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:16:16.426996 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:16:16.436721 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:16:16.445762 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:16:16.452946 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:16:16.454764 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:16:16.456973 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:16:16.459706 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:16:16.471697 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:16:16.474558 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:16:16.477308 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:16:16.537679 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:16:16.541885 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:16:16.545034 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:16:16.548713 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:16:16.560646 (MainThread): Partial parsing not enabled
2021-05-01 05:16:16.595570 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:16:16.609096 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:16:16.619152 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:16:16.631536 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:16:16.648532 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:16:16.813960 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'edeaf536-635e-45ca-a1f5-4d30bfdee531', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c1d250>]}
2021-05-01 05:16:16.820658 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'edeaf536-635e-45ca-a1f5-4d30bfdee531', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c53ee0>]}
2021-05-01 05:16:16.820976 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:16:16.822367 (MainThread): 
2021-05-01 05:16:16.822778 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:16:16.824594 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:16:16.840340 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:16:16.840655 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:16:16.840820 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-01 05:16:18.383194 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.54 seconds
2021-05-01 05:16:18.389282 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:16:18.493962 (MainThread): 22:16:18 | Concurrency: 1 threads (target='dev')
2021-05-01 05:16:18.494230 (MainThread): 22:16:18 | 
2021-05-01 05:16:18.496124 (Thread-1): Began running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:16:18.496837 (Thread-1): 22:16:18 | 1 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-05-01 05:16:18.497235 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:16:18.497419 (Thread-1): Compiling test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:16:18.506406 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id"
2021-05-01 05:16:18.507166 (Thread-1): finished collecting timing info
2021-05-01 05:16:18.507751 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:16:18.507869 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: BEGIN
2021-05-01 05:16:18.507978 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:16:19.250216 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2021-05-01 05:16:19.250453 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:16:19.250580 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-05-01 05:16:20.106820 (Thread-1): SQL status: SUCCESS 1 in 0.86 seconds
2021-05-01 05:16:20.107424 (Thread-1): finished collecting timing info
2021-05-01 05:16:20.107602 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:16:20.231916 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: Close
2021-05-01 05:16:20.341633 (Thread-1): 22:16:20 | 1 of 6 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 1.84s]
2021-05-01 05:16:20.341887 (Thread-1): Finished running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:16:20.342088 (Thread-1): Began running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:16:20.342274 (Thread-1): 22:16:20 | 2 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-05-01 05:16:20.342937 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:16:20.343140 (Thread-1): Compiling test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:16:20.348103 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id"
2021-05-01 05:16:20.348733 (Thread-1): finished collecting timing info
2021-05-01 05:16:20.349363 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:16:20.349486 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: BEGIN
2021-05-01 05:16:20.349597 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:16:20.898429 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-05-01 05:16:20.898770 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:16:20.898917 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-05-01 05:16:21.681419 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2021-05-01 05:16:21.681924 (Thread-1): finished collecting timing info
2021-05-01 05:16:21.682135 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:16:21.814479 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: Close
2021-05-01 05:16:21.940721 (Thread-1): 22:16:21 | 2 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.60s]
2021-05-01 05:16:21.940959 (Thread-1): Finished running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:16:21.941149 (Thread-1): Began running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:16:21.941316 (Thread-1): 22:16:21 | 3 of 6 START test not_null_sf_customer_purchases_c_custkey........... [RUN]
2021-05-01 05:16:21.941723 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:16:21.942067 (Thread-1): Compiling test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:16:21.947038 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"
2021-05-01 05:16:21.947584 (Thread-1): finished collecting timing info
2021-05-01 05:16:21.948202 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:16:21.948320 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:16:21.948428 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:16:22.474582 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-05-01 05:16:22.474869 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:16:22.475031 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.sf_customer_purchases
where c_custkey is null
2021-05-01 05:16:22.731215 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-05-01 05:16:22.731794 (Thread-1): finished collecting timing info
2021-05-01 05:16:22.732060 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:16:22.916302 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: Close
2021-05-01 05:16:23.024758 (Thread-1): 22:16:23 | 3 of 6 PASS not_null_sf_customer_purchases_c_custkey................. [PASS in 1.08s]
2021-05-01 05:16:23.025009 (Thread-1): Finished running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:16:23.025265 (Thread-1): Began running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:16:23.025721 (Thread-1): 22:16:23 | 4 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-05-01 05:16:23.026403 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:16:23.026624 (Thread-1): Compiling test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:16:23.037241 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id"
2021-05-01 05:16:23.037802 (Thread-1): finished collecting timing info
2021-05-01 05:16:23.038551 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:16:23.038668 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: BEGIN
2021-05-01 05:16:23.038774 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:16:23.698589 (Thread-1): SQL status: SUCCESS 1 in 0.66 seconds
2021-05-01 05:16:23.698829 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:16:23.698958 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:16:24.041672 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-05-01 05:16:24.042212 (Thread-1): finished collecting timing info
2021-05-01 05:16:24.042422 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:16:24.236514 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: Close
2021-05-01 05:16:24.336478 (Thread-1): 22:16:24 | 4 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 1.31s]
2021-05-01 05:16:24.336706 (Thread-1): Finished running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:16:24.336875 (Thread-1): Began running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:16:24.337030 (Thread-1): 22:16:24 | 5 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-05-01 05:16:24.337458 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:16:24.337622 (Thread-1): Compiling test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:16:24.341769 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id"
2021-05-01 05:16:24.342318 (Thread-1): finished collecting timing info
2021-05-01 05:16:24.343069 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:16:24.343185 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: BEGIN
2021-05-01 05:16:24.343291 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:16:24.904071 (Thread-1): SQL status: SUCCESS 1 in 0.56 seconds
2021-05-01 05:16:24.904284 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:16:24.904391 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:16:25.265654 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-05-01 05:16:25.266250 (Thread-1): finished collecting timing info
2021-05-01 05:16:25.266487 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:16:25.569161 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: Close
2021-05-01 05:16:25.674682 (Thread-1): 22:16:25 | 5 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 1.34s]
2021-05-01 05:16:25.674918 (Thread-1): Finished running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:16:25.675096 (Thread-1): Began running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:16:25.675373 (Thread-1): 22:16:25 | 6 of 6 START test unique_sf_customer_purchases_c_custkey............. [RUN]
2021-05-01 05:16:25.675740 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:16:25.675885 (Thread-1): Compiling test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:16:25.680150 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_sf_customer_purchases_c_custkey"
2021-05-01 05:16:25.680905 (Thread-1): finished collecting timing info
2021-05-01 05:16:25.681799 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:16:25.681945 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:16:25.682064 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:16:26.273572 (Thread-1): SQL status: SUCCESS 1 in 0.59 seconds
2021-05-01 05:16:26.273774 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:16:26.273876 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.sf_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-05-01 05:16:26.751774 (Thread-1): SQL status: SUCCESS 1 in 0.48 seconds
2021-05-01 05:16:26.752258 (Thread-1): finished collecting timing info
2021-05-01 05:16:26.752461 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:16:26.930154 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: Close
2021-05-01 05:16:27.100361 (Thread-1): 22:16:27 | 6 of 6 PASS unique_sf_customer_purchases_c_custkey................... [PASS in 1.42s]
2021-05-01 05:16:27.100600 (Thread-1): Finished running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:16:27.102018 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:16:27.102401 (MainThread): 22:16:27 | 
2021-05-01 05:16:27.102561 (MainThread): 22:16:27 | Finished running 6 tests in 10.28s.
2021-05-01 05:16:27.102721 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:16:27.102836 (MainThread): Connection 'test.learn_dbt.unique_sf_customer_purchases_c_custkey' was properly closed.
2021-05-01 05:16:27.108649 (MainThread): 
2021-05-01 05:16:27.108845 (MainThread): Completed with 1 error and 0 warnings:
2021-05-01 05:16:27.108982 (MainThread): 
2021-05-01 05:16:27.109114 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-05-01 05:16:27.109235 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:16:27.109349 (MainThread): 
2021-05-01 05:16:27.109517 (MainThread):   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-05-01 05:16:27.109711 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-05-01 05:16:27.109922 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dbe490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c1a8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d4fbb0>]}
2021-05-01 05:16:27.110166 (MainThread): Flushing usage events
2021-05-01 05:17:05.771154 (MainThread): Running with dbt=0.19.1
2021-05-01 05:17:06.371225 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-01 05:17:06.372034 (MainThread): Tracking: tracking
2021-05-01 05:17:06.372533 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054b0970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106484dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106484e80>]}
2021-05-01 05:17:06.385584 (MainThread): Partial parsing not enabled
2021-05-01 05:17:06.386772 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:17:06.389682 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:17:06.427899 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:17:06.430667 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:17:06.432564 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:17:06.437100 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:17:06.449945 (MainThread): Parsing macros/core.sql
2021-05-01 05:17:06.454762 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:17:06.465486 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:17:06.467640 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:17:06.488948 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:17:06.529177 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:17:06.554115 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:17:06.556652 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:17:06.564410 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:17:06.581506 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:17:06.590007 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:17:06.597515 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:17:06.603638 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:17:06.605101 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:17:06.606328 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:17:06.608304 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:17:06.619451 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:17:06.622175 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:17:06.624151 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:17:06.678159 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:17:06.680398 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:17:06.682224 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:17:06.684120 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:17:06.693271 (MainThread): Partial parsing not enabled
2021-05-01 05:17:06.721687 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:17:06.734314 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:17:06.739721 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:17:06.743163 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:17:06.747666 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:06.838644 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10805daf0>]}
2021-05-01 05:17:06.844062 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108190c70>]}
2021-05-01 05:17:06.844351 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:17:06.845650 (MainThread): 
2021-05-01 05:17:06.846023 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:17:06.847030 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-05-01 05:17:06.861214 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-05-01 05:17:06.861377 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-05-01 05:17:06.861481 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-01 05:17:07.819845 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 0.96 seconds
2021-05-01 05:17:07.824825 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-05-01 05:17:07.987063 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:17:07.996285 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:17:07.996596 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:17:07.996772 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-01 05:17:09.025598 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.03 seconds
2021-05-01 05:17:09.026691 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:17:09.141758 (MainThread): Using snowflake connection "master".
2021-05-01 05:17:09.141918 (MainThread): On master: BEGIN
2021-05-01 05:17:09.142011 (MainThread): Opening a new connection, currently in state init
2021-05-01 05:17:09.816830 (MainThread): SQL status: SUCCESS 1 in 0.67 seconds
2021-05-01 05:17:09.817221 (MainThread): On master: COMMIT
2021-05-01 05:17:09.817586 (MainThread): Using snowflake connection "master".
2021-05-01 05:17:09.817788 (MainThread): On master: COMMIT
2021-05-01 05:17:10.142453 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-05-01 05:17:10.142657 (MainThread): On master: Close
2021-05-01 05:17:10.271483 (MainThread): 22:17:10 | Concurrency: 1 threads (target='dev')
2021-05-01 05:17:10.271692 (MainThread): 22:17:10 | 
2021-05-01 05:17:10.273396 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:17:10.273827 (Thread-1): 22:17:10 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-05-01 05:17:10.274345 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:17:10.274605 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-05-01 05:17:10.278516 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:17:10.279110 (Thread-1): finished collecting timing info
2021-05-01 05:17:10.324668 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:17:10.326468 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:17:10.326664 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-05-01 05:17:10.326755 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:11.174576 (Thread-1): SQL status: SUCCESS 1 in 0.85 seconds
2021-05-01 05:17:11.174765 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:17:11.174863 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
where id is not null

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-05-01 05:17:11.932255 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-05-01 05:17:11.933464 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:17:11.933649 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:17:11.933799 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:17:12.027191 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-05-01 05:17:12.038176 (Thread-1): finished collecting timing info
2021-05-01 05:17:12.038373 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-05-01 05:17:12.169136 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108099520>]}
2021-05-01 05:17:12.169533 (Thread-1): 22:17:12 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 1.90s]
2021-05-01 05:17:12.169692 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:17:12.169897 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:17:12.170425 (Thread-1): 22:17:12 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-05-01 05:17:12.171057 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:17:12.171191 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:17:12.173664 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:17:12.174134 (Thread-1): finished collecting timing info
2021-05-01 05:17:12.202337 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:17:12.204126 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:17:12.204328 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-05-01 05:17:12.204469 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:12.824744 (Thread-1): SQL status: SUCCESS 1 in 0.62 seconds
2021-05-01 05:17:12.824924 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:17:12.825012 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-05-01 05:17:13.093950 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-05-01 05:17:13.094926 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:17:13.095082 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:17:13.095163 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:17:13.163139 (Thread-1): SQL status: SUCCESS 1 in 0.07 seconds
2021-05-01 05:17:13.163899 (Thread-1): finished collecting timing info
2021-05-01 05:17:13.164048 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-05-01 05:17:13.263499 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10802b730>]}
2021-05-01 05:17:13.263895 (Thread-1): 22:17:13 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.09s]
2021-05-01 05:17:13.264030 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:17:13.264265 (Thread-1): Began running node model.learn_dbt.dates
2021-05-01 05:17:13.264649 (Thread-1): 22:17:13 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-05-01 05:17:13.265053 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:13.265173 (Thread-1): Compiling model.learn_dbt.dates
2021-05-01 05:17:13.270849 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-05-01 05:17:13.271325 (Thread-1): finished collecting timing info
2021-05-01 05:17:13.317082 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:13.317457 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-05-01 05:17:13.317733 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:14.829604 (Thread-1): SQL status: SUCCESS 1 in 1.51 seconds
2021-05-01 05:17:14.852340 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:14.852624 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-05-01 05:17:14.954907 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-05-01 05:17:14.961124 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:14.961307 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:17:15.064082 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-05-01 05:17:15.070564 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:15.070876 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:17:15.146664 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-05-01 05:17:15.185224 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-05-01 05:17:15.188907 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:15.189088 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-05-01 05:17:15.282467 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-05-01 05:17:15.282689 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:15.282814 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-05-01 05:17:15.891665 (Thread-1): SQL status: SUCCESS 0 in 0.61 seconds
2021-05-01 05:17:15.893203 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:17:15.893428 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:15.893551 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:17:16.065709 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-05-01 05:17:16.067199 (Thread-1): finished collecting timing info
2021-05-01 05:17:16.067434 (Thread-1): On model.learn_dbt.dates: Close
2021-05-01 05:17:16.177471 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b1f70>]}
2021-05-01 05:17:16.178011 (Thread-1): 22:17:16 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 2.91s]
2021-05-01 05:17:16.178212 (Thread-1): Finished running node model.learn_dbt.dates
2021-05-01 05:17:16.178487 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:17:16.179292 (Thread-1): 22:17:16 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-05-01 05:17:16.179756 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:17:16.179911 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-05-01 05:17:16.181854 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:17:16.182461 (Thread-1): finished collecting timing info
2021-05-01 05:17:16.184792 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:17:16.186397 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:17:16.186559 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-05-01 05:17:16.186670 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:16.923890 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2021-05-01 05:17:16.924110 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:17:16.924227 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-05-01 05:17:18.339922 (Thread-1): SQL status: SUCCESS 1 in 1.42 seconds
2021-05-01 05:17:18.341327 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:17:18.341535 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:17:18.341646 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:17:18.837162 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-05-01 05:17:18.838457 (Thread-1): finished collecting timing info
2021-05-01 05:17:18.838716 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-05-01 05:17:18.953345 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b15b0>]}
2021-05-01 05:17:18.953871 (Thread-1): 22:17:18 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 2.77s]
2021-05-01 05:17:18.954078 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:17:18.954275 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:17:18.954701 (Thread-1): 22:17:18 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-05-01 05:17:18.955178 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:17:18.955325 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-05-01 05:17:18.958437 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:17:18.958997 (Thread-1): finished collecting timing info
2021-05-01 05:17:18.961151 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:17:18.962082 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:17:18.962200 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-05-01 05:17:18.962306 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:19.852512 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2021-05-01 05:17:19.852800 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:17:19.852957 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
2021-05-01 05:17:21.428298 (Thread-1): SQL status: SUCCESS 1 in 1.58 seconds
2021-05-01 05:17:21.430561 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:17:21.431224 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:17:21.431467 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:17:21.865184 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-05-01 05:17:21.866254 (Thread-1): finished collecting timing info
2021-05-01 05:17:21.866478 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-05-01 05:17:22.158067 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a77f410-7e11-4006-a8ff-e71ccfec7528', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b9460>]}
2021-05-01 05:17:22.158503 (Thread-1): 22:17:22 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.20s]
2021-05-01 05:17:22.158665 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:17:22.159951 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:17:22.160191 (MainThread): Using snowflake connection "master".
2021-05-01 05:17:22.160282 (MainThread): On master: BEGIN
2021-05-01 05:17:22.160369 (MainThread): Opening a new connection, currently in state closed
2021-05-01 05:17:22.711261 (MainThread): SQL status: SUCCESS 1 in 0.55 seconds
2021-05-01 05:17:22.711566 (MainThread): On master: COMMIT
2021-05-01 05:17:22.711830 (MainThread): Using snowflake connection "master".
2021-05-01 05:17:22.711985 (MainThread): On master: COMMIT
2021-05-01 05:17:22.853478 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2021-05-01 05:17:22.853754 (MainThread): On master: Close
2021-05-01 05:17:22.981972 (MainThread): 22:17:22 | 
2021-05-01 05:17:22.982155 (MainThread): 22:17:22 | Finished running 3 table models, 1 view model, 1 incremental model in 16.14s.
2021-05-01 05:17:22.982279 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:17:22.982388 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-05-01 05:17:22.986770 (MainThread): 
2021-05-01 05:17:22.986918 (MainThread): Completed successfully
2021-05-01 05:17:22.987050 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-05-01 05:17:22.987248 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081801f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080887c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108088fa0>]}
2021-05-01 05:17:22.987474 (MainThread): Flushing usage events
2021-05-01 05:17:30.480479 (MainThread): Running with dbt=0.19.1
2021-05-01 05:17:31.464889 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-05-01 05:17:31.466306 (MainThread): Tracking: tracking
2021-05-01 05:17:31.466914 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109240af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21fd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21fdc0>]}
2021-05-01 05:17:31.486051 (MainThread): Partial parsing not enabled
2021-05-01 05:17:31.487333 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:17:31.490878 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:17:31.556086 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:17:31.559856 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:17:31.562285 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:17:31.572959 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:17:31.587786 (MainThread): Parsing macros/core.sql
2021-05-01 05:17:31.595333 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:17:31.610178 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:17:31.612412 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:17:31.651167 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:17:31.717919 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:17:31.750485 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:17:31.761716 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:17:31.784119 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:17:31.840276 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:17:31.892483 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:17:31.910525 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:17:31.927534 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:17:31.929470 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:17:31.931826 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:17:31.936744 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:17:31.953708 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:17:31.956357 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:17:31.958848 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:17:32.058046 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:17:32.068257 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:17:32.073097 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:17:32.078454 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:17:32.091973 (MainThread): Partial parsing not enabled
2021-05-01 05:17:32.130369 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:17:32.146467 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:17:32.154690 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:17:32.159823 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:17:32.167219 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:17:32.278810 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49778984-94dc-4bba-85bf-c8b24ecc626a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be1c850>]}
2021-05-01 05:17:32.284731 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49778984-94dc-4bba-85bf-c8b24ecc626a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf6bca0>]}
2021-05-01 05:17:32.285054 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:17:32.286658 (MainThread): 
2021-05-01 05:17:32.287106 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:17:32.288957 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:17:32.304305 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:17:32.304479 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:17:32.304575 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-01 05:17:33.349756 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.05 seconds
2021-05-01 05:17:33.357105 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:17:33.476735 (MainThread): 22:17:33 | Concurrency: 1 threads (target='dev')
2021-05-01 05:17:33.476977 (MainThread): 22:17:33 | 
2021-05-01 05:17:33.479379 (Thread-1): Began running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:17:33.480451 (Thread-1): 22:17:33 | 1 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-05-01 05:17:33.481217 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:17:33.481567 (Thread-1): Compiling test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:17:33.496323 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id"
2021-05-01 05:17:33.497632 (Thread-1): finished collecting timing info
2021-05-01 05:17:33.498983 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:17:33.499402 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: BEGIN
2021-05-01 05:17:33.499716 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:34.711047 (Thread-1): SQL status: SUCCESS 1 in 1.21 seconds
2021-05-01 05:17:34.712357 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:17:34.713100 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-05-01 05:17:35.125086 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2021-05-01 05:17:35.125700 (Thread-1): finished collecting timing info
2021-05-01 05:17:35.125898 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:17:35.258918 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: Close
2021-05-01 05:17:35.381196 (Thread-1): 22:17:35 | 1 of 6 PASS not_null_my_first_dbt_model_id........................... [PASS in 1.90s]
2021-05-01 05:17:35.381795 (Thread-1): Finished running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:17:35.382441 (Thread-1): Began running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:17:35.382934 (Thread-1): 22:17:35 | 2 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-05-01 05:17:35.383847 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:17:35.384149 (Thread-1): Compiling test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:17:35.393408 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id"
2021-05-01 05:17:35.394906 (Thread-1): finished collecting timing info
2021-05-01 05:17:35.396961 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:17:35.397458 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: BEGIN
2021-05-01 05:17:35.397800 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:36.712380 (Thread-1): SQL status: SUCCESS 1 in 1.31 seconds
2021-05-01 05:17:36.712795 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:17:36.725180 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-05-01 05:17:37.041610 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-05-01 05:17:37.042973 (Thread-1): finished collecting timing info
2021-05-01 05:17:37.043317 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:17:37.257206 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: Close
2021-05-01 05:17:37.421426 (Thread-1): 22:17:37 | 2 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 2.04s]
2021-05-01 05:17:37.421814 (Thread-1): Finished running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:17:37.422136 (Thread-1): Began running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:17:37.423015 (Thread-1): 22:17:37 | 3 of 6 START test not_null_sf_customer_purchases_c_custkey........... [RUN]
2021-05-01 05:17:37.423743 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:17:37.424001 (Thread-1): Compiling test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:17:37.432758 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"
2021-05-01 05:17:37.433622 (Thread-1): finished collecting timing info
2021-05-01 05:17:37.435241 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:17:37.435498 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:17:37.435830 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:41.461465 (Thread-1): SQL status: SUCCESS 1 in 4.03 seconds
2021-05-01 05:17:41.461777 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:17:41.461942 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.sf_customer_purchases
where c_custkey is null
2021-05-01 05:17:41.710748 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-05-01 05:17:41.711397 (Thread-1): finished collecting timing info
2021-05-01 05:17:41.711712 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:17:41.919197 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: Close
2021-05-01 05:17:42.027259 (Thread-1): 22:17:42 | 3 of 6 PASS not_null_sf_customer_purchases_c_custkey................. [PASS in 4.60s]
2021-05-01 05:17:42.027633 (Thread-1): Finished running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:17:42.027940 (Thread-1): Began running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:17:42.028517 (Thread-1): 22:17:42 | 4 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-05-01 05:17:42.029160 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:17:42.029418 (Thread-1): Compiling test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:17:42.046837 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id"
2021-05-01 05:17:42.047831 (Thread-1): finished collecting timing info
2021-05-01 05:17:42.049178 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:17:42.049435 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: BEGIN
2021-05-01 05:17:42.050214 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:43.482285 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-05-01 05:17:43.482488 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:17:43.482589 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:17:43.799940 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-05-01 05:17:43.801057 (Thread-1): finished collecting timing info
2021-05-01 05:17:43.801291 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:17:43.923498 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: Close
2021-05-01 05:17:44.035945 (Thread-1): 22:17:44 | 4 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 2.01s]
2021-05-01 05:17:44.045192 (Thread-1): Finished running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:17:44.045594 (Thread-1): Began running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:17:44.046160 (Thread-1): 22:17:44 | 5 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-05-01 05:17:44.046698 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:17:44.046921 (Thread-1): Compiling test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:17:44.051712 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id"
2021-05-01 05:17:44.052238 (Thread-1): finished collecting timing info
2021-05-01 05:17:44.053040 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:17:44.053182 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: BEGIN
2021-05-01 05:17:44.053294 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:45.852369 (Thread-1): SQL status: SUCCESS 1 in 1.80 seconds
2021-05-01 05:17:45.852553 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:17:45.852643 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:17:46.173504 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-05-01 05:17:46.173948 (Thread-1): finished collecting timing info
2021-05-01 05:17:46.174120 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:17:46.302723 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: Close
2021-05-01 05:17:46.479725 (Thread-1): 22:17:46 | 5 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 2.43s]
2021-05-01 05:17:46.479919 (Thread-1): Finished running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:17:46.480129 (Thread-1): Began running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:17:46.480318 (Thread-1): 22:17:46 | 6 of 6 START test unique_sf_customer_purchases_c_custkey............. [RUN]
2021-05-01 05:17:46.480847 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:17:46.480980 (Thread-1): Compiling test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:17:46.484145 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_sf_customer_purchases_c_custkey"
2021-05-01 05:17:46.484619 (Thread-1): finished collecting timing info
2021-05-01 05:17:46.485247 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:17:46.485341 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:17:46.485426 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:17:47.179522 (Thread-1): SQL status: SUCCESS 1 in 0.69 seconds
2021-05-01 05:17:47.179741 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:17:47.179843 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.sf_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-05-01 05:17:47.477086 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-05-01 05:17:47.477517 (Thread-1): finished collecting timing info
2021-05-01 05:17:47.477696 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:17:47.595453 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: Close
2021-05-01 05:17:47.716386 (Thread-1): 22:17:47 | 6 of 6 PASS unique_sf_customer_purchases_c_custkey................... [PASS in 1.24s]
2021-05-01 05:17:47.717048 (Thread-1): Finished running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:17:47.720311 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:17:47.721168 (MainThread): 22:17:47 | 
2021-05-01 05:17:47.721491 (MainThread): 22:17:47 | Finished running 6 tests in 15.43s.
2021-05-01 05:17:47.721770 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:17:47.722035 (MainThread): Connection 'test.learn_dbt.unique_sf_customer_purchases_c_custkey' was properly closed.
2021-05-01 05:17:47.731210 (MainThread): 
2021-05-01 05:17:47.731630 (MainThread): Completed successfully
2021-05-01 05:17:47.732003 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-05-01 05:17:47.732630 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf075e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21f040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21f0a0>]}
2021-05-01 05:17:47.733213 (MainThread): Flushing usage events
2021-05-01 05:28:28.999485 (MainThread): Running with dbt=0.19.1
2021-05-01 05:28:29.862450 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-01 05:28:29.863758 (MainThread): Tracking: tracking
2021-05-01 05:28:29.864163 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cb08b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c8fd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c8fdc0>]}
2021-05-01 05:28:29.880149 (MainThread): Partial parsing not enabled
2021-05-01 05:28:29.881593 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:28:29.884935 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:28:29.925108 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:28:29.928581 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:28:29.930972 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:28:29.936821 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:28:29.950490 (MainThread): Parsing macros/core.sql
2021-05-01 05:28:29.955993 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:28:29.967634 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:28:29.970389 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:28:29.994606 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:28:30.038354 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:28:30.065533 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:28:30.069242 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:28:30.078380 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:28:30.096196 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:28:30.104968 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:28:30.113592 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:28:30.120147 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:28:30.122114 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:28:30.124096 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:28:30.127126 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:28:30.138574 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:28:30.141465 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:28:30.144245 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:28:30.201276 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:28:30.204288 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:28:30.206355 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:28:30.208726 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:28:30.218119 (MainThread): Partial parsing not enabled
2021-05-01 05:28:30.245162 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:28:30.259892 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:28:30.266416 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:28:30.270703 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:28:30.276877 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:30.296143 (MainThread): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:28:30.381842 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9b7d60>]}
2021-05-01 05:28:30.388430 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b897d90>]}
2021-05-01 05:28:30.388719 (MainThread): Found 5 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:28:30.389765 (MainThread): 
2021-05-01 05:28:30.390130 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:28:30.391389 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-05-01 05:28:30.410003 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-05-01 05:28:30.410288 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-05-01 05:28:30.410535 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-01 05:28:31.411592 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.00 seconds
2021-05-01 05:28:31.416706 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-05-01 05:28:31.533553 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:28:31.544752 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:28:31.544942 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:28:31.545054 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-01 05:28:32.765864 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.22 seconds
2021-05-01 05:28:32.767151 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:28:32.875883 (MainThread): Using snowflake connection "master".
2021-05-01 05:28:32.876151 (MainThread): On master: BEGIN
2021-05-01 05:28:32.876282 (MainThread): Opening a new connection, currently in state init
2021-05-01 05:28:33.548274 (MainThread): SQL status: SUCCESS 1 in 0.67 seconds
2021-05-01 05:28:33.548492 (MainThread): On master: COMMIT
2021-05-01 05:28:33.548673 (MainThread): Using snowflake connection "master".
2021-05-01 05:28:33.548772 (MainThread): On master: COMMIT
2021-05-01 05:28:33.706373 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2021-05-01 05:28:33.706631 (MainThread): On master: Close
2021-05-01 05:28:33.849168 (MainThread): 22:28:33 | Concurrency: 1 threads (target='dev')
2021-05-01 05:28:33.849396 (MainThread): 22:28:33 | 
2021-05-01 05:28:33.850776 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:28:33.851134 (Thread-1): 22:28:33 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-05-01 05:28:33.851497 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:28:33.851659 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-05-01 05:28:33.854898 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:28:33.855496 (Thread-1): finished collecting timing info
2021-05-01 05:28:33.897520 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:28:33.898854 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:28:33.899005 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-05-01 05:28:33.899123 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:28:34.614279 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2021-05-01 05:28:34.614514 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:28:34.614644 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-05-01 05:28:35.678835 (Thread-1): SQL status: SUCCESS 1 in 1.06 seconds
2021-05-01 05:28:35.680173 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:28:35.680373 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:28:35.680479 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:28:36.090100 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2021-05-01 05:28:36.103008 (Thread-1): finished collecting timing info
2021-05-01 05:28:36.103242 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-05-01 05:28:36.232446 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9c0460>]}
2021-05-01 05:28:36.232920 (Thread-1): 22:28:36 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 2.38s]
2021-05-01 05:28:36.233103 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:28:36.233272 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:28:36.233529 (Thread-1): 22:28:36 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-05-01 05:28:36.234294 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:28:36.234467 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:28:36.238154 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:28:36.244282 (Thread-1): finished collecting timing info
2021-05-01 05:28:36.270809 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:28:36.272675 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:28:36.272871 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-05-01 05:28:36.272991 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:28:37.062682 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-05-01 05:28:37.062898 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:28:37.063013 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-05-01 05:28:37.487531 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2021-05-01 05:28:37.489314 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:28:37.489619 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:28:37.489762 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:28:37.568037 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2021-05-01 05:28:37.569157 (Thread-1): finished collecting timing info
2021-05-01 05:28:37.569377 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-05-01 05:28:37.763858 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b807b80>]}
2021-05-01 05:28:37.764380 (Thread-1): 22:28:37 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.53s]
2021-05-01 05:28:37.764631 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:28:37.764960 (Thread-1): Began running node model.learn_dbt.dates
2021-05-01 05:28:37.765968 (Thread-1): 22:28:37 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-05-01 05:28:37.766765 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:37.767036 (Thread-1): Compiling model.learn_dbt.dates
2021-05-01 05:28:37.778017 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-05-01 05:28:37.778617 (Thread-1): finished collecting timing info
2021-05-01 05:28:37.818531 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:37.818774 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-05-01 05:28:37.818997 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:28:39.858422 (Thread-1): SQL status: SUCCESS 1 in 2.04 seconds
2021-05-01 05:28:39.871373 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:39.871569 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-05-01 05:28:40.345540 (Thread-1): SQL status: SUCCESS 28 in 0.47 seconds
2021-05-01 05:28:40.351583 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:40.351731 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:28:40.430653 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-05-01 05:28:40.435775 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:40.435959 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:28:40.533757 (Thread-1): SQL status: SUCCESS 28 in 0.10 seconds
2021-05-01 05:28:40.566652 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-05-01 05:28:40.576186 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:40.576370 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-05-01 05:28:40.731287 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-05-01 05:28:40.731515 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:40.731638 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-05-01 05:28:41.344679 (Thread-1): SQL status: SUCCESS 0 in 0.61 seconds
2021-05-01 05:28:41.346035 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:28:41.346276 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:28:41.346402 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:28:41.544307 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-05-01 05:28:41.545399 (Thread-1): finished collecting timing info
2021-05-01 05:28:41.545600 (Thread-1): On model.learn_dbt.dates: Close
2021-05-01 05:28:41.667614 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb945b0>]}
2021-05-01 05:28:41.668144 (Thread-1): 22:28:41 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.90s]
2021-05-01 05:28:41.668542 (Thread-1): Finished running node model.learn_dbt.dates
2021-05-01 05:28:41.668848 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:28:41.669524 (Thread-1): 22:28:41 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-05-01 05:28:41.670079 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:28:41.670290 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-05-01 05:28:41.672603 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:28:41.673130 (Thread-1): finished collecting timing info
2021-05-01 05:28:41.675787 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:28:41.677501 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:28:41.677762 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-05-01 05:28:41.677914 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:28:42.220701 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2021-05-01 05:28:42.220967 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:28:42.221103 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-05-01 05:28:44.048799 (Thread-1): SQL status: SUCCESS 1 in 1.83 seconds
2021-05-01 05:28:44.050232 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:28:44.050463 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:28:44.050587 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:28:44.348892 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-05-01 05:28:44.350068 (Thread-1): finished collecting timing info
2021-05-01 05:28:44.350330 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-05-01 05:28:44.453118 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8068e0>]}
2021-05-01 05:28:44.453596 (Thread-1): 22:28:44 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 2.78s]
2021-05-01 05:28:44.453875 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:28:44.454225 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:28:44.454900 (Thread-1): 22:28:44 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-05-01 05:28:44.455312 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:28:44.455454 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-05-01 05:28:44.459118 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:28:44.459792 (Thread-1): finished collecting timing info
2021-05-01 05:28:44.462486 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:28:44.463548 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:28:44.463680 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-05-01 05:28:44.463789 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:28:45.304306 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-05-01 05:28:45.304556 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:28:45.304753 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
2021-05-01 05:28:47.424419 (Thread-1): SQL status: SUCCESS 1 in 2.12 seconds
2021-05-01 05:28:47.425540 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:28:47.425860 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:28:47.426007 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:28:48.048061 (Thread-1): SQL status: SUCCESS 1 in 0.62 seconds
2021-05-01 05:28:48.049089 (Thread-1): finished collecting timing info
2021-05-01 05:28:48.049296 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-05-01 05:28:48.165292 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb48e54d-3290-4fc4-a292-bf5399edb8bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb94220>]}
2021-05-01 05:28:48.165756 (Thread-1): 22:28:48 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.71s]
2021-05-01 05:28:48.165928 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:28:48.167288 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:28:48.167557 (MainThread): Using snowflake connection "master".
2021-05-01 05:28:48.167706 (MainThread): On master: BEGIN
2021-05-01 05:28:48.167816 (MainThread): Opening a new connection, currently in state closed
2021-05-01 05:28:48.869976 (MainThread): SQL status: SUCCESS 1 in 0.70 seconds
2021-05-01 05:28:48.870276 (MainThread): On master: COMMIT
2021-05-01 05:28:48.870481 (MainThread): Using snowflake connection "master".
2021-05-01 05:28:48.870597 (MainThread): On master: COMMIT
2021-05-01 05:28:49.020848 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2021-05-01 05:28:49.021184 (MainThread): On master: Close
2021-05-01 05:28:49.145041 (MainThread): 22:28:49 | 
2021-05-01 05:28:49.145281 (MainThread): 22:28:49 | Finished running 3 table models, 1 view model, 1 incremental model in 18.75s.
2021-05-01 05:28:49.145494 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:28:49.145729 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-05-01 05:28:49.151425 (MainThread): 
2021-05-01 05:28:49.151663 (MainThread): Completed successfully
2021-05-01 05:28:49.151884 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-05-01 05:28:49.152157 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b98c7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbe3dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbe3fa0>]}
2021-05-01 05:28:49.152414 (MainThread): Flushing usage events
2021-05-01 05:29:08.356972 (MainThread): Running with dbt=0.19.1
2021-05-01 05:29:08.963750 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-05-01 05:29:08.964855 (MainThread): Tracking: tracking
2021-05-01 05:29:08.965161 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050a44f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10601dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10601ddc0>]}
2021-05-01 05:29:08.977660 (MainThread): Partial parsing not enabled
2021-05-01 05:29:08.978815 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:29:08.981479 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:29:09.017875 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:29:09.021069 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:29:09.022842 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:29:09.027285 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:29:09.039790 (MainThread): Parsing macros/core.sql
2021-05-01 05:29:09.044357 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:29:09.055613 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:29:09.057625 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:29:09.080735 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:29:09.120369 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:29:09.147710 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:29:09.149904 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:29:09.157968 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:29:09.175075 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:29:09.183498 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:29:09.191393 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:29:09.197259 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:29:09.198387 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:29:09.199592 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:29:09.201462 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:29:09.213196 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:29:09.215640 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:29:09.217588 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:29:09.269667 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:29:09.272101 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:29:09.273806 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:29:09.275717 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:29:09.284780 (MainThread): Partial parsing not enabled
2021-05-01 05:29:09.311352 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:29:09.322823 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:29:09.328231 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:29:09.331922 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:29:09.336513 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:29:09.355728 (MainThread): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:09.439252 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '642f32cd-57f5-4752-9499-0bbca8ca6382', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d725b0>]}
2021-05-01 05:29:09.444786 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '642f32cd-57f5-4752-9499-0bbca8ca6382', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c53fa0>]}
2021-05-01 05:29:09.445060 (MainThread): Found 5 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:29:09.446314 (MainThread): 
2021-05-01 05:29:09.446635 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:29:09.448021 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:29:09.462264 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:29:09.462495 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:29:09.462611 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-01 05:29:10.848795 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.39 seconds
2021-05-01 05:29:10.854127 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:29:11.146652 (MainThread): 22:29:11 | Concurrency: 1 threads (target='dev')
2021-05-01 05:29:11.146974 (MainThread): 22:29:11 | 
2021-05-01 05:29:11.149034 (Thread-1): Began running node test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:29:11.149367 (Thread-1): 22:29:11 | 1 of 7 START test assert_under_10_percent_null....................... [RUN]
2021-05-01 05:29:11.149819 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:11.150010 (Thread-1): Compiling test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:29:11.162912 (Thread-1): Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
2021-05-01 05:29:11.163461 (Thread-1): finished collecting timing info
2021-05-01 05:29:11.164185 (Thread-1): Using snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:11.164291 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: BEGIN
2021-05-01 05:29:11.164378 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:11.943692 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2021-05-01 05:29:11.943917 (Thread-1): Using snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:11.944037 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
SELECT
	SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END)/ COUNT(*) AS total_nulls
FROM analytics.dbt.first_model
HAVING SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END) / COUNT(*) > .1
)select count(*) from dbt__CTE__INTERNAL_test
2021-05-01 05:29:12.243123 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-05-01 05:29:12.243669 (Thread-1): finished collecting timing info
2021-05-01 05:29:12.243858 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: ROLLBACK
2021-05-01 05:29:12.868140 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: Close
2021-05-01 05:29:12.984026 (Thread-1): 22:29:12 | 1 of 7 FAIL 1 assert_under_10_percent_null........................... [FAIL 1 in 1.83s]
2021-05-01 05:29:12.984251 (Thread-1): Finished running node test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:29:12.984416 (Thread-1): Began running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:29:12.984570 (Thread-1): 22:29:12 | 2 of 7 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-05-01 05:29:12.985067 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:29:12.985225 (Thread-1): Compiling test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:29:12.993560 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id"
2021-05-01 05:29:12.994084 (Thread-1): finished collecting timing info
2021-05-01 05:29:12.994572 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:29:12.994749 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: BEGIN
2021-05-01 05:29:12.994854 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:13.528530 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-05-01 05:29:13.528755 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:29:13.528875 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-05-01 05:29:14.605747 (Thread-1): SQL status: SUCCESS 1 in 1.08 seconds
2021-05-01 05:29:14.606249 (Thread-1): finished collecting timing info
2021-05-01 05:29:14.606458 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:29:15.097883 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: Close
2021-05-01 05:29:15.207994 (Thread-1): 22:29:15 | 2 of 7 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 2.22s]
2021-05-01 05:29:15.208229 (Thread-1): Finished running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:29:15.208430 (Thread-1): Began running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:29:15.208854 (Thread-1): 22:29:15 | 3 of 7 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-05-01 05:29:15.209375 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:29:15.209528 (Thread-1): Compiling test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:29:15.214601 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id"
2021-05-01 05:29:15.215144 (Thread-1): finished collecting timing info
2021-05-01 05:29:15.215722 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:29:15.215836 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: BEGIN
2021-05-01 05:29:15.215945 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:15.752421 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2021-05-01 05:29:15.752781 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:29:15.752953 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-05-01 05:29:16.054582 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-05-01 05:29:16.055345 (Thread-1): finished collecting timing info
2021-05-01 05:29:16.055645 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:29:16.196862 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: Close
2021-05-01 05:29:16.301262 (Thread-1): 22:29:16 | 3 of 7 FAIL 1 not_null_my_second_dbt_model_id........................ [FAIL 1 in 1.09s]
2021-05-01 05:29:16.301514 (Thread-1): Finished running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:29:16.301845 (Thread-1): Began running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:29:16.302506 (Thread-1): 22:29:16 | 4 of 7 START test not_null_sf_customer_purchases_c_custkey........... [RUN]
2021-05-01 05:29:16.303158 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:29:16.303340 (Thread-1): Compiling test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:29:16.307575 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"
2021-05-01 05:29:16.308174 (Thread-1): finished collecting timing info
2021-05-01 05:29:16.308812 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:29:16.308933 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:29:16.309039 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:17.199328 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2021-05-01 05:29:17.199566 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:29:17.199692 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.sf_customer_purchases
where c_custkey is null
2021-05-01 05:29:17.397496 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-05-01 05:29:17.397971 (Thread-1): finished collecting timing info
2021-05-01 05:29:17.398175 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:29:17.528992 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: Close
2021-05-01 05:29:17.692250 (Thread-1): 22:29:17 | 4 of 7 PASS not_null_sf_customer_purchases_c_custkey................. [PASS in 1.39s]
2021-05-01 05:29:17.692498 (Thread-1): Finished running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:29:17.692681 (Thread-1): Began running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:29:17.692848 (Thread-1): 22:29:17 | 5 of 7 START test unique_my_first_dbt_model_id....................... [RUN]
2021-05-01 05:29:17.693362 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:29:17.693529 (Thread-1): Compiling test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:29:17.702617 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id"
2021-05-01 05:29:17.703382 (Thread-1): finished collecting timing info
2021-05-01 05:29:17.704559 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:29:17.704850 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: BEGIN
2021-05-01 05:29:17.705019 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:18.470752 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2021-05-01 05:29:18.470949 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:29:18.471055 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:29:18.682604 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-05-01 05:29:18.683084 (Thread-1): finished collecting timing info
2021-05-01 05:29:18.683285 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:29:18.798602 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: Close
2021-05-01 05:29:18.905272 (Thread-1): 22:29:18 | 5 of 7 PASS unique_my_first_dbt_model_id............................. [PASS in 1.21s]
2021-05-01 05:29:18.905510 (Thread-1): Finished running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:29:18.905687 (Thread-1): Began running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:29:18.905881 (Thread-1): 22:29:18 | 6 of 7 START test unique_my_second_dbt_model_id...................... [RUN]
2021-05-01 05:29:18.906434 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:29:18.906597 (Thread-1): Compiling test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:29:18.910342 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id"
2021-05-01 05:29:18.910961 (Thread-1): finished collecting timing info
2021-05-01 05:29:18.911762 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:29:18.911877 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: BEGIN
2021-05-01 05:29:18.911975 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:19.684835 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2021-05-01 05:29:19.685130 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:29:19.685300 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:29:20.057749 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-05-01 05:29:20.058419 (Thread-1): finished collecting timing info
2021-05-01 05:29:20.058733 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:29:20.206020 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: Close
2021-05-01 05:29:20.301491 (Thread-1): 22:29:20 | 6 of 7 PASS unique_my_second_dbt_model_id............................ [PASS in 1.40s]
2021-05-01 05:29:20.301759 (Thread-1): Finished running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:29:20.301963 (Thread-1): Began running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:29:20.302153 (Thread-1): 22:29:20 | 7 of 7 START test unique_sf_customer_purchases_c_custkey............. [RUN]
2021-05-01 05:29:20.302761 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:29:20.302986 (Thread-1): Compiling test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:29:20.307806 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_sf_customer_purchases_c_custkey"
2021-05-01 05:29:20.308544 (Thread-1): finished collecting timing info
2021-05-01 05:29:20.309541 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:29:20.309683 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:29:20.309788 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:20.846214 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2021-05-01 05:29:20.846503 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:29:20.846661 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.sf_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-05-01 05:29:21.187124 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-05-01 05:29:21.187919 (Thread-1): finished collecting timing info
2021-05-01 05:29:21.188163 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:29:21.349157 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: Close
2021-05-01 05:29:21.490305 (Thread-1): 22:29:21 | 7 of 7 PASS unique_sf_customer_purchases_c_custkey................... [PASS in 1.19s]
2021-05-01 05:29:21.490526 (Thread-1): Finished running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:29:21.491887 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:29:21.492301 (MainThread): 22:29:21 | 
2021-05-01 05:29:21.492485 (MainThread): 22:29:21 | Finished running 7 tests in 12.05s.
2021-05-01 05:29:21.492666 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:29:21.492820 (MainThread): Connection 'test.learn_dbt.unique_sf_customer_purchases_c_custkey' was properly closed.
2021-05-01 05:29:21.499050 (MainThread): 
2021-05-01 05:29:21.499308 (MainThread): Completed with 3 errors and 0 warnings:
2021-05-01 05:29:21.499631 (MainThread): 
2021-05-01 05:29:21.499843 (MainThread): Failure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)
2021-05-01 05:29:21.500083 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:29:21.500290 (MainThread): 
2021-05-01 05:29:21.500484 (MainThread):   compiled SQL at target/compiled/learn_dbt/tests/assert_under_10_percent_null.sql
2021-05-01 05:29:21.500617 (MainThread): 
2021-05-01 05:29:21.500763 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-05-01 05:29:21.500895 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:29:21.501002 (MainThread): 
2021-05-01 05:29:21.501190 (MainThread):   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-05-01 05:29:21.501362 (MainThread): 
2021-05-01 05:29:21.501541 (MainThread): Failure in test not_null_my_second_dbt_model_id (models/example/schema.yml)
2021-05-01 05:29:21.501700 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:29:21.501824 (MainThread): 
2021-05-01 05:29:21.501944 (MainThread):   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/schema_test/not_null_my_second_dbt_model_id.sql
2021-05-01 05:29:21.502284 (MainThread): 
Done. PASS=4 WARN=0 ERROR=3 SKIP=0 TOTAL=7
2021-05-01 05:29:21.502636 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b7220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c1d130>]}
2021-05-01 05:29:21.502957 (MainThread): Flushing usage events
2021-05-01 05:29:40.183756 (MainThread): Running with dbt=0.19.1
2021-05-01 05:29:40.840416 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-05-01 05:29:40.841238 (MainThread): Tracking: tracking
2021-05-01 05:29:40.841614 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bde09a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd84c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd84cd0>]}
2021-05-01 05:29:40.855224 (MainThread): Partial parsing not enabled
2021-05-01 05:29:40.856378 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:29:40.859536 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:29:40.897902 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:29:40.900319 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:29:40.902083 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:29:40.906951 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:29:40.920685 (MainThread): Parsing macros/core.sql
2021-05-01 05:29:40.927474 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:29:40.938276 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:29:40.940387 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:29:40.964783 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:29:41.006062 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:29:41.032501 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:29:41.034691 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:29:41.042224 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:29:41.058795 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:29:41.069052 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:29:41.077597 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:29:41.087179 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:29:41.088450 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:29:41.089718 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:29:41.091656 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:29:41.103228 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:29:41.105620 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:29:41.107668 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:29:41.163798 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:29:41.166164 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:29:41.168230 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:29:41.170472 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:29:41.180688 (MainThread): Partial parsing not enabled
2021-05-01 05:29:41.208964 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:29:41.221500 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:29:41.227435 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:29:41.231480 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:29:41.235678 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:29:41.253614 (MainThread): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:41.337395 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a06f9d6f-c776-4f94-a044-b070887b0c64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaf8d90>]}
2021-05-01 05:29:41.342760 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a06f9d6f-c776-4f94-a044-b070887b0c64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3bafa0>]}
2021-05-01 05:29:41.343079 (MainThread): Found 5 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:29:41.344767 (MainThread): 
2021-05-01 05:29:41.345190 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:29:41.346694 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:29:41.360284 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:29:41.360466 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:29:41.360564 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-01 05:29:42.297620 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.94 seconds
2021-05-01 05:29:42.302275 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:29:42.410646 (MainThread): 22:29:42 | Concurrency: 1 threads (target='dev')
2021-05-01 05:29:42.410942 (MainThread): 22:29:42 | 
2021-05-01 05:29:42.413298 (Thread-1): Began running node test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:29:42.413580 (Thread-1): 22:29:42 | 1 of 7 START test assert_under_10_percent_null....................... [RUN]
2021-05-01 05:29:42.414114 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:42.414301 (Thread-1): Compiling test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:29:42.427888 (Thread-1): Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
2021-05-01 05:29:42.428917 (Thread-1): finished collecting timing info
2021-05-01 05:29:42.430466 (Thread-1): Using snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:42.430784 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: BEGIN
2021-05-01 05:29:42.431036 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:43.656055 (Thread-1): SQL status: SUCCESS 1 in 1.22 seconds
2021-05-01 05:29:43.656439 (Thread-1): Using snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:29:43.656615 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
SELECT
	SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END)/ COUNT(*) AS total_nulls
FROM analytics.dbt.first_model
HAVING SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END) / COUNT(*) > .1
)select count(*) from dbt__CTE__INTERNAL_test
2021-05-01 05:29:43.800239 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-05-01 05:29:43.800999 (Thread-1): finished collecting timing info
2021-05-01 05:29:43.801283 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: ROLLBACK
2021-05-01 05:29:43.937022 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: Close
2021-05-01 05:29:44.067287 (Thread-1): 22:29:44 | 1 of 7 FAIL 1 assert_under_10_percent_null........................... [FAIL 1 in 1.65s]
2021-05-01 05:29:44.067519 (Thread-1): Finished running node test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:29:44.067702 (Thread-1): Began running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:29:44.067879 (Thread-1): 22:29:44 | 2 of 7 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-05-01 05:29:44.068501 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:29:44.068680 (Thread-1): Compiling test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:29:44.078611 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id"
2021-05-01 05:29:44.079331 (Thread-1): finished collecting timing info
2021-05-01 05:29:44.079943 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:29:44.080066 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: BEGIN
2021-05-01 05:29:44.080176 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:44.796680 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2021-05-01 05:29:44.796990 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:29:44.797149 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-05-01 05:29:44.901232 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2021-05-01 05:29:44.901721 (Thread-1): finished collecting timing info
2021-05-01 05:29:44.901924 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:29:45.045796 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: Close
2021-05-01 05:29:45.156816 (Thread-1): 22:29:45 | 2 of 7 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 1.09s]
2021-05-01 05:29:45.157043 (Thread-1): Finished running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:29:45.157222 (Thread-1): Began running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:29:45.157472 (Thread-1): 22:29:45 | 3 of 7 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-05-01 05:29:45.157954 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:29:45.158127 (Thread-1): Compiling test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:29:45.164112 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id"
2021-05-01 05:29:45.164706 (Thread-1): finished collecting timing info
2021-05-01 05:29:45.165309 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:29:45.165432 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: BEGIN
2021-05-01 05:29:45.165543 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:45.694914 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-05-01 05:29:45.695158 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:29:45.695290 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-05-01 05:29:45.896346 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-05-01 05:29:45.896772 (Thread-1): finished collecting timing info
2021-05-01 05:29:45.896950 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:29:46.033639 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: Close
2021-05-01 05:29:46.147627 (Thread-1): 22:29:46 | 3 of 7 FAIL 1 not_null_my_second_dbt_model_id........................ [FAIL 1 in 0.99s]
2021-05-01 05:29:46.147866 (Thread-1): Finished running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:29:46.148079 (Thread-1): Began running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:29:46.148306 (Thread-1): 22:29:46 | 4 of 7 START test not_null_sf_customer_purchases_c_custkey........... [RUN]
2021-05-01 05:29:46.148831 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:29:46.149190 (Thread-1): Compiling test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:29:46.153127 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"
2021-05-01 05:29:46.153657 (Thread-1): finished collecting timing info
2021-05-01 05:29:46.154292 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:29:46.154418 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:29:46.154528 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:46.909734 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2021-05-01 05:29:46.912223 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:29:46.912574 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.sf_customer_purchases
where c_custkey is null
2021-05-01 05:29:47.197847 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2021-05-01 05:29:47.198298 (Thread-1): finished collecting timing info
2021-05-01 05:29:47.198481 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:29:47.339836 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: Close
2021-05-01 05:29:47.469160 (Thread-1): 22:29:47 | 4 of 7 PASS not_null_sf_customer_purchases_c_custkey................. [PASS in 1.32s]
2021-05-01 05:29:47.469398 (Thread-1): Finished running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:29:47.469677 (Thread-1): Began running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:29:47.470225 (Thread-1): 22:29:47 | 5 of 7 START test unique_my_first_dbt_model_id....................... [RUN]
2021-05-01 05:29:47.470773 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:29:47.470951 (Thread-1): Compiling test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:29:47.480472 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id"
2021-05-01 05:29:47.481084 (Thread-1): finished collecting timing info
2021-05-01 05:29:47.481929 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:29:47.482078 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: BEGIN
2021-05-01 05:29:47.482195 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:48.674072 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-05-01 05:29:48.674280 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:29:48.674393 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:29:48.766040 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-05-01 05:29:48.766528 (Thread-1): finished collecting timing info
2021-05-01 05:29:48.766740 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:29:48.884886 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: Close
2021-05-01 05:29:49.042763 (Thread-1): 22:29:49 | 5 of 7 PASS unique_my_first_dbt_model_id............................. [PASS in 1.57s]
2021-05-01 05:29:49.043167 (Thread-1): Finished running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:29:49.043523 (Thread-1): Began running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:29:49.044001 (Thread-1): 22:29:49 | 6 of 7 START test unique_my_second_dbt_model_id...................... [RUN]
2021-05-01 05:29:49.044642 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:29:49.044848 (Thread-1): Compiling test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:29:49.049000 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id"
2021-05-01 05:29:49.049551 (Thread-1): finished collecting timing info
2021-05-01 05:29:49.050309 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:29:49.050428 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: BEGIN
2021-05-01 05:29:49.050539 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:50.230266 (Thread-1): SQL status: SUCCESS 1 in 1.18 seconds
2021-05-01 05:29:50.230443 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:29:50.230532 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:29:50.382425 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-05-01 05:29:50.382838 (Thread-1): finished collecting timing info
2021-05-01 05:29:50.383009 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:29:50.533184 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: Close
2021-05-01 05:29:50.629898 (Thread-1): 22:29:50 | 6 of 7 PASS unique_my_second_dbt_model_id............................ [PASS in 1.59s]
2021-05-01 05:29:50.630113 (Thread-1): Finished running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:29:50.630274 (Thread-1): Began running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:29:50.630651 (Thread-1): 22:29:50 | 7 of 7 START test unique_sf_customer_purchases_c_custkey............. [RUN]
2021-05-01 05:29:50.631171 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:29:50.631376 (Thread-1): Compiling test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:29:50.634545 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_sf_customer_purchases_c_custkey"
2021-05-01 05:29:50.635007 (Thread-1): finished collecting timing info
2021-05-01 05:29:50.635725 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:29:50.635840 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:29:50.635932 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:29:51.061341 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-05-01 05:29:51.061656 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:29:51.061804 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.sf_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-05-01 05:29:51.159951 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2021-05-01 05:29:51.161043 (Thread-1): finished collecting timing info
2021-05-01 05:29:51.161489 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:29:51.282396 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: Close
2021-05-01 05:29:51.397048 (Thread-1): 22:29:51 | 7 of 7 PASS unique_sf_customer_purchases_c_custkey................... [PASS in 0.77s]
2021-05-01 05:29:51.397321 (Thread-1): Finished running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:29:51.398686 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:29:51.399027 (MainThread): 22:29:51 | 
2021-05-01 05:29:51.399173 (MainThread): 22:29:51 | Finished running 7 tests in 10.05s.
2021-05-01 05:29:51.399294 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:29:51.399388 (MainThread): Connection 'test.learn_dbt.unique_sf_customer_purchases_c_custkey' was properly closed.
2021-05-01 05:29:51.404803 (MainThread): 
2021-05-01 05:29:51.404977 (MainThread): Completed with 3 errors and 0 warnings:
2021-05-01 05:29:51.405092 (MainThread): 
2021-05-01 05:29:51.405203 (MainThread): Failure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)
2021-05-01 05:29:51.405304 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:29:51.405399 (MainThread): 
2021-05-01 05:29:51.405496 (MainThread):   compiled SQL at target/compiled/learn_dbt/tests/assert_under_10_percent_null.sql
2021-05-01 05:29:51.405592 (MainThread): 
2021-05-01 05:29:51.405691 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-05-01 05:29:51.405786 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:29:51.405876 (MainThread): 
2021-05-01 05:29:51.405970 (MainThread):   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-05-01 05:29:51.406065 (MainThread): 
2021-05-01 05:29:51.406164 (MainThread): Failure in test not_null_my_second_dbt_model_id (models/example/schema.yml)
2021-05-01 05:29:51.406257 (MainThread):   Got 1 result, expected 0.
2021-05-01 05:29:51.406347 (MainThread): 
2021-05-01 05:29:51.406440 (MainThread):   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/schema_test/not_null_my_second_dbt_model_id.sql
2021-05-01 05:29:51.406551 (MainThread): 
Done. PASS=4 WARN=0 ERROR=3 SKIP=0 TOTAL=7
2021-05-01 05:29:51.406716 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3a7280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3aa790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eacc850>]}
2021-05-01 05:29:51.406915 (MainThread): Flushing usage events
2021-05-01 05:30:00.695543 (MainThread): Running with dbt=0.19.1
2021-05-01 05:30:01.333923 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-01 05:30:01.334789 (MainThread): Tracking: tracking
2021-05-01 05:30:01.335096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d16fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acaad60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acaae50>]}
2021-05-01 05:30:01.348833 (MainThread): Partial parsing not enabled
2021-05-01 05:30:01.350097 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:30:01.353106 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:30:01.391494 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:30:01.395070 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:30:01.397166 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:30:01.402201 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:30:01.415209 (MainThread): Parsing macros/core.sql
2021-05-01 05:30:01.420628 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:30:01.432494 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:30:01.434579 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:30:01.456597 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:30:01.499059 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:30:01.525405 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:30:01.528572 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:30:01.537217 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:30:01.554358 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:30:01.563785 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:30:01.571671 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:30:01.578056 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:30:01.579489 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:30:01.580726 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:30:01.582742 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:30:01.593954 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:30:01.596758 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:30:01.598830 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:30:01.654364 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:30:01.656893 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:30:01.658930 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:30:01.661523 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:30:01.671227 (MainThread): Partial parsing not enabled
2021-05-01 05:30:01.699756 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:30:01.713910 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:30:01.719336 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:30:01.723430 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:30:01.730800 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:01.753964 (MainThread): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:30:01.842518 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9f8df0>]}
2021-05-01 05:30:01.848412 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8f3250>]}
2021-05-01 05:30:01.848704 (MainThread): Found 5 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:30:01.849798 (MainThread): 
2021-05-01 05:30:01.850151 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:30:01.851151 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-05-01 05:30:01.866040 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-05-01 05:30:01.866209 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-05-01 05:30:01.866303 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-01 05:30:02.790007 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 0.92 seconds
2021-05-01 05:30:02.795313 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-05-01 05:30:02.921798 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:30:02.930369 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:30:02.930548 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:30:02.930664 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-01 05:30:03.500365 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.57 seconds
2021-05-01 05:30:03.501465 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:30:03.620158 (MainThread): Using snowflake connection "master".
2021-05-01 05:30:03.620350 (MainThread): On master: BEGIN
2021-05-01 05:30:03.620461 (MainThread): Opening a new connection, currently in state init
2021-05-01 05:30:05.662811 (MainThread): SQL status: SUCCESS 1 in 2.04 seconds
2021-05-01 05:30:05.663119 (MainThread): On master: COMMIT
2021-05-01 05:30:05.663339 (MainThread): Using snowflake connection "master".
2021-05-01 05:30:05.663463 (MainThread): On master: COMMIT
2021-05-01 05:30:05.818409 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2021-05-01 05:30:05.818666 (MainThread): On master: Close
2021-05-01 05:30:06.058042 (MainThread): 22:30:06 | Concurrency: 1 threads (target='dev')
2021-05-01 05:30:06.058261 (MainThread): 22:30:06 | 
2021-05-01 05:30:06.060375 (Thread-1): Began running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:30:06.060896 (Thread-1): 22:30:06 | 1 of 5 START table model dbt.first_model............................. [RUN]
2021-05-01 05:30:06.061404 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:30:06.061731 (Thread-1): Compiling model.learn_dbt.my_first_dbt_model
2021-05-01 05:30:06.065237 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:30:06.065821 (Thread-1): finished collecting timing info
2021-05-01 05:30:06.112742 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
2021-05-01 05:30:06.114440 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:30:06.114633 (Thread-1): On model.learn_dbt.my_first_dbt_model: BEGIN
2021-05-01 05:30:06.114740 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:06.761173 (Thread-1): SQL status: SUCCESS 1 in 0.65 seconds
2021-05-01 05:30:06.761610 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:30:06.761953 (Thread-1): On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
where id is not null

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-05-01 05:30:10.460102 (Thread-1): SQL status: SUCCESS 1 in 3.70 seconds
2021-05-01 05:30:10.461598 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:30:10.461760 (Thread-1): Using snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:30:10.461844 (Thread-1): On model.learn_dbt.my_first_dbt_model: COMMIT
2021-05-01 05:30:10.853719 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2021-05-01 05:30:10.863939 (Thread-1): finished collecting timing info
2021-05-01 05:30:10.864144 (Thread-1): On model.learn_dbt.my_first_dbt_model: Close
2021-05-01 05:30:11.177276 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c843070>]}
2021-05-01 05:30:11.177809 (Thread-1): 22:30:11 | 1 of 5 OK created table model dbt.first_model........................ [SUCCESS 1 in 5.12s]
2021-05-01 05:30:11.178005 (Thread-1): Finished running node model.learn_dbt.my_first_dbt_model
2021-05-01 05:30:11.178206 (Thread-1): Began running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:30:11.178864 (Thread-1): 22:30:11 | 2 of 5 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-05-01 05:30:11.179422 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:30:11.179578 (Thread-1): Compiling model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:30:11.182506 (Thread-1): Writing injected SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:30:11.183009 (Thread-1): finished collecting timing info
2021-05-01 05:30:11.204645 (Thread-1): Writing runtime SQL for node "model.learn_dbt.cumulative_orders_by_date"
2021-05-01 05:30:11.206147 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:30:11.206293 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: BEGIN
2021-05-01 05:30:11.206394 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:12.135461 (Thread-1): SQL status: SUCCESS 1 in 0.93 seconds
2021-05-01 05:30:12.135714 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:30:12.135841 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

WITH ORDERS_BY_DATE AS (
    SELECT O_ORDERDATE
    , SUM(O_TOTALPRICE) AS ORDERS_BY_DATE
    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS
    GROUP BY O_ORDERDATE
)

SELECT O_ORDERDATE
, SUM(ORDERS_BY_DATE)
    OVER
        (ORDER BY O_ORDERDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS CUMULATIVE_ORDERS_BY_DATE
FROM ORDERS_BY_DATE
ORDER BY O_ORDERDATE
  );
2021-05-01 05:30:12.507556 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-05-01 05:30:12.517690 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:30:12.517920 (Thread-1): Using snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:30:12.518026 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: COMMIT
2021-05-01 05:30:12.604947 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2021-05-01 05:30:12.606005 (Thread-1): finished collecting timing info
2021-05-01 05:30:12.606209 (Thread-1): On model.learn_dbt.cumulative_orders_by_date: Close
2021-05-01 05:30:12.718300 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c861550>]}
2021-05-01 05:30:12.718772 (Thread-1): 22:30:12 | 2 of 5 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 1.54s]
2021-05-01 05:30:12.718948 (Thread-1): Finished running node model.learn_dbt.cumulative_orders_by_date
2021-05-01 05:30:12.719201 (Thread-1): Began running node model.learn_dbt.dates
2021-05-01 05:30:12.719836 (Thread-1): 22:30:12 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-05-01 05:30:12.720351 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:12.720611 (Thread-1): Compiling model.learn_dbt.dates
2021-05-01 05:30:12.727711 (Thread-1): Writing injected SQL for node "model.learn_dbt.dates"
2021-05-01 05:30:12.728269 (Thread-1): finished collecting timing info
2021-05-01 05:30:12.760836 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:12.761036 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

SELECT * 
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM" 
WHERE d_date <= CURRENT_DATE


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-05-01 05:30:12.761149 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:15.289589 (Thread-1): SQL status: SUCCESS 1 in 2.53 seconds
2021-05-01 05:30:15.300126 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:15.300297 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-05-01 05:30:15.780074 (Thread-1): SQL status: SUCCESS 28 in 0.48 seconds
2021-05-01 05:30:15.786068 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:15.786250 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:30:15.873096 (Thread-1): SQL status: SUCCESS 28 in 0.09 seconds
2021-05-01 05:30:15.878249 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:15.878568 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
2021-05-01 05:30:15.962427 (Thread-1): SQL status: SUCCESS 28 in 0.08 seconds
2021-05-01 05:30:15.995730 (Thread-1): Writing runtime SQL for node "model.learn_dbt.dates"
2021-05-01 05:30:15.999945 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:16.000136 (Thread-1): On model.learn_dbt.dates: BEGIN
2021-05-01 05:30:16.100547 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2021-05-01 05:30:16.100773 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:16.100914 (Thread-1): On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-05-01 05:30:17.015718 (Thread-1): SQL status: SUCCESS 0 in 0.91 seconds
2021-05-01 05:30:17.016961 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:30:17.017167 (Thread-1): Using snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:17.017278 (Thread-1): On model.learn_dbt.dates: COMMIT
2021-05-01 05:30:17.288072 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-05-01 05:30:17.289176 (Thread-1): finished collecting timing info
2021-05-01 05:30:17.289401 (Thread-1): On model.learn_dbt.dates: Close
2021-05-01 05:30:17.462680 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc1c5b0>]}
2021-05-01 05:30:17.463154 (Thread-1): 22:30:17 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.74s]
2021-05-01 05:30:17.463336 (Thread-1): Finished running node model.learn_dbt.dates
2021-05-01 05:30:17.463538 (Thread-1): Began running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:30:17.464379 (Thread-1): 22:30:17 | 4 of 5 START table model dbt.sf_customer_purchases................... [RUN]
2021-05-01 05:30:17.464909 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:30:17.465072 (Thread-1): Compiling model.learn_dbt.sf_customer_purchases
2021-05-01 05:30:17.467448 (Thread-1): Writing injected SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:30:17.468069 (Thread-1): finished collecting timing info
2021-05-01 05:30:17.471505 (Thread-1): Writing runtime SQL for node "model.learn_dbt.sf_customer_purchases"
2021-05-01 05:30:17.473395 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:30:17.473821 (Thread-1): On model.learn_dbt.sf_customer_purchases: BEGIN
2021-05-01 05:30:17.474058 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:18.069013 (Thread-1): SQL status: SUCCESS 1 in 0.59 seconds
2021-05-01 05:30:18.069261 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:30:18.069384 (Thread-1): On model.learn_dbt.sf_customer_purchases: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.sf_customer_purchases"} */


      create or replace transient table analytics.dbt.sf_customer_purchases  as
      (SELECT 
    c.c_custkey, 
    c.c_name, 
    c.c_nationkey,
    SUM(o.o_totalprice) AS total_order_price
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" AS c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" AS o
ON  c.c_custkey = o.o_custkey
GROUP BY c.c_custkey, c.c_name, c.c_nationkey
      );
2021-05-01 05:30:19.480551 (Thread-1): SQL status: SUCCESS 1 in 1.41 seconds
2021-05-01 05:30:19.482342 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:30:19.482663 (Thread-1): Using snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:30:19.482796 (Thread-1): On model.learn_dbt.sf_customer_purchases: COMMIT
2021-05-01 05:30:19.750716 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-05-01 05:30:19.751714 (Thread-1): finished collecting timing info
2021-05-01 05:30:19.751960 (Thread-1): On model.learn_dbt.sf_customer_purchases: Close
2021-05-01 05:30:19.954095 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9fe490>]}
2021-05-01 05:30:19.954865 (Thread-1): 22:30:19 | 4 of 5 OK created table model dbt.sf_customer_purchases.............. [SUCCESS 1 in 2.49s]
2021-05-01 05:30:19.955200 (Thread-1): Finished running node model.learn_dbt.sf_customer_purchases
2021-05-01 05:30:19.955508 (Thread-1): Began running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:30:19.955953 (Thread-1): 22:30:19 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-05-01 05:30:19.956698 (Thread-1): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:30:19.957044 (Thread-1): Compiling model.learn_dbt.my_second_dbt_model
2021-05-01 05:30:19.964135 (Thread-1): Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:30:19.964848 (Thread-1): finished collecting timing info
2021-05-01 05:30:19.969495 (Thread-1): Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
2021-05-01 05:30:19.971325 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:30:19.971557 (Thread-1): On model.learn_dbt.my_second_dbt_model: BEGIN
2021-05-01 05:30:19.971702 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:21.071092 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-05-01 05:30:21.071447 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:30:21.071689 (Thread-1): On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
      );
2021-05-01 05:30:21.885432 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-05-01 05:30:21.887355 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:30:21.887761 (Thread-1): Using snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:30:21.887961 (Thread-1): On model.learn_dbt.my_second_dbt_model: COMMIT
2021-05-01 05:30:21.962568 (Thread-1): SQL status: SUCCESS 1 in 0.07 seconds
2021-05-01 05:30:21.964065 (Thread-1): finished collecting timing info
2021-05-01 05:30:21.964569 (Thread-1): On model.learn_dbt.my_second_dbt_model: Close
2021-05-01 05:30:22.074649 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5ff0a-3fc8-42ec-81b0-32d51f424114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9fefa0>]}
2021-05-01 05:30:22.075481 (Thread-1): 22:30:22 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.12s]
2021-05-01 05:30:22.075934 (Thread-1): Finished running node model.learn_dbt.my_second_dbt_model
2021-05-01 05:30:22.078580 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:30:22.079117 (MainThread): Using snowflake connection "master".
2021-05-01 05:30:22.079384 (MainThread): On master: BEGIN
2021-05-01 05:30:22.079582 (MainThread): Opening a new connection, currently in state closed
2021-05-01 05:30:23.493998 (MainThread): SQL status: SUCCESS 1 in 1.41 seconds
2021-05-01 05:30:23.494857 (MainThread): On master: COMMIT
2021-05-01 05:30:23.495372 (MainThread): Using snowflake connection "master".
2021-05-01 05:30:23.495620 (MainThread): On master: COMMIT
2021-05-01 05:30:23.883282 (MainThread): SQL status: SUCCESS 1 in 0.39 seconds
2021-05-01 05:30:23.883517 (MainThread): On master: Close
2021-05-01 05:30:24.015864 (MainThread): 22:30:24 | 
2021-05-01 05:30:24.016195 (MainThread): 22:30:24 | Finished running 3 table models, 1 view model, 1 incremental model in 22.17s.
2021-05-01 05:30:24.016423 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:30:24.016667 (MainThread): Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
2021-05-01 05:30:24.027576 (MainThread): 
2021-05-01 05:30:24.027851 (MainThread): Completed successfully
2021-05-01 05:30:24.028129 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-05-01 05:30:24.028436 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca50040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca500a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc7dc10>]}
2021-05-01 05:30:24.028920 (MainThread): Flushing usage events
2021-05-01 05:30:42.536376 (MainThread): Running with dbt=0.19.1
2021-05-01 05:30:43.544635 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jackyho/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-05-01 05:30:43.546556 (MainThread): Tracking: tracking
2021-05-01 05:30:43.546950 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112429880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134fbb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134fbc40>]}
2021-05-01 05:30:43.560236 (MainThread): Partial parsing not enabled
2021-05-01 05:30:43.562025 (MainThread): Parsing macros/catalog.sql
2021-05-01 05:30:43.565042 (MainThread): Parsing macros/adapters.sql
2021-05-01 05:30:43.603090 (MainThread): Parsing macros/materializations/merge.sql
2021-05-01 05:30:43.606245 (MainThread): Parsing macros/materializations/view.sql
2021-05-01 05:30:43.608916 (MainThread): Parsing macros/materializations/table.sql
2021-05-01 05:30:43.614498 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-01 05:30:43.629546 (MainThread): Parsing macros/core.sql
2021-05-01 05:30:43.637186 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-01 05:30:43.651045 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-01 05:30:43.653789 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-01 05:30:43.676622 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-01 05:30:43.720301 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-01 05:30:43.745974 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-01 05:30:43.749199 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-01 05:30:43.757734 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-01 05:30:43.776013 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-01 05:30:43.785627 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-01 05:30:43.794070 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-01 05:30:43.800585 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-01 05:30:43.802504 (MainThread): Parsing macros/etc/query.sql
2021-05-01 05:30:43.804515 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-01 05:30:43.806944 (MainThread): Parsing macros/etc/datetime.sql
2021-05-01 05:30:43.818386 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-01 05:30:43.821460 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-01 05:30:43.824282 (MainThread): Parsing macros/adapters/common.sql
2021-05-01 05:30:43.877936 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-01 05:30:43.880928 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-01 05:30:43.883535 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-01 05:30:43.886357 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-01 05:30:43.895442 (MainThread): Partial parsing not enabled
2021-05-01 05:30:43.922670 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model".
2021-05-01 05:30:43.934302 (MainThread): Acquiring new snowflake connection "model.learn_dbt.cumulative_orders_by_date".
2021-05-01 05:30:43.940651 (MainThread): Acquiring new snowflake connection "model.learn_dbt.sf_customer_purchases".
2021-05-01 05:30:43.944874 (MainThread): Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model".
2021-05-01 05:30:43.950700 (MainThread): Acquiring new snowflake connection "model.learn_dbt.dates".
2021-05-01 05:30:43.970130 (MainThread): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:30:44.049937 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03de4925-74ff-4f3a-aa4e-7a5bc9c63e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115239d30>]}
2021-05-01 05:30:44.055395 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03de4925-74ff-4f3a-aa4e-7a5bc9c63e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115118f40>]}
2021-05-01 05:30:44.055675 (MainThread): Found 5 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-01 05:30:44.057236 (MainThread): 
2021-05-01 05:30:44.057620 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:30:44.059228 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-05-01 05:30:44.072908 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-05-01 05:30:44.073056 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-05-01 05:30:44.073144 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-01 05:30:45.346522 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.27 seconds
2021-05-01 05:30:45.352387 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-05-01 05:30:45.488605 (MainThread): 22:30:45 | Concurrency: 1 threads (target='dev')
2021-05-01 05:30:45.488846 (MainThread): 22:30:45 | 
2021-05-01 05:30:45.490810 (Thread-1): Began running node test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:30:45.491071 (Thread-1): 22:30:45 | 1 of 7 START test assert_under_10_percent_null....................... [RUN]
2021-05-01 05:30:45.491443 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:30:45.491600 (Thread-1): Compiling test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:30:45.505915 (Thread-1): Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
2021-05-01 05:30:45.506609 (Thread-1): finished collecting timing info
2021-05-01 05:30:45.507593 (Thread-1): Using snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:30:45.507781 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: BEGIN
2021-05-01 05:30:45.507900 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:46.163451 (Thread-1): SQL status: SUCCESS 1 in 0.66 seconds
2021-05-01 05:30:46.163725 (Thread-1): Using snowflake connection "test.learn_dbt.assert_under_10_percent_null".
2021-05-01 05:30:46.163864 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
SELECT
	SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END)/ COUNT(*) AS total_nulls
FROM analytics.dbt.first_model
HAVING SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END) / COUNT(*) > .1
)select count(*) from dbt__CTE__INTERNAL_test
2021-05-01 05:30:46.531711 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-05-01 05:30:46.532503 (Thread-1): finished collecting timing info
2021-05-01 05:30:46.532899 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: ROLLBACK
2021-05-01 05:30:46.734175 (Thread-1): On test.learn_dbt.assert_under_10_percent_null: Close
2021-05-01 05:30:47.037530 (Thread-1): 22:30:47 | 1 of 7 PASS assert_under_10_percent_null............................. [PASS in 1.55s]
2021-05-01 05:30:47.038019 (Thread-1): Finished running node test.learn_dbt.assert_under_10_percent_null
2021-05-01 05:30:47.038452 (Thread-1): Began running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:30:47.039038 (Thread-1): 22:30:47 | 2 of 7 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-05-01 05:30:47.039558 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:30:47.041927 (Thread-1): Compiling test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:30:47.051079 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id"
2021-05-01 05:30:47.051630 (Thread-1): finished collecting timing info
2021-05-01 05:30:47.052201 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:30:47.052315 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: BEGIN
2021-05-01 05:30:47.052423 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:47.553249 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-05-01 05:30:47.553544 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id".
2021-05-01 05:30:47.553702 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-05-01 05:30:47.791562 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2021-05-01 05:30:47.792147 (Thread-1): finished collecting timing info
2021-05-01 05:30:47.792398 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:30:47.912251 (Thread-1): On test.learn_dbt.not_null_my_first_dbt_model_id: Close
2021-05-01 05:30:48.015747 (Thread-1): 22:30:48 | 2 of 7 PASS not_null_my_first_dbt_model_id........................... [PASS in 0.98s]
2021-05-01 05:30:48.016009 (Thread-1): Finished running node test.learn_dbt.not_null_my_first_dbt_model_id
2021-05-01 05:30:48.016207 (Thread-1): Began running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:30:48.016395 (Thread-1): 22:30:48 | 3 of 7 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-05-01 05:30:48.017088 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:30:48.017322 (Thread-1): Compiling test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:30:48.022409 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id"
2021-05-01 05:30:48.023055 (Thread-1): finished collecting timing info
2021-05-01 05:30:48.023643 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:30:48.023760 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: BEGIN
2021-05-01 05:30:48.023868 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:49.314572 (Thread-1): SQL status: SUCCESS 1 in 1.29 seconds
2021-05-01 05:30:49.314947 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id".
2021-05-01 05:30:49.315184 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-05-01 05:30:49.539088 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-05-01 05:30:49.539517 (Thread-1): finished collecting timing info
2021-05-01 05:30:49.539697 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:30:49.667687 (Thread-1): On test.learn_dbt.not_null_my_second_dbt_model_id: Close
2021-05-01 05:30:49.816412 (Thread-1): 22:30:49 | 3 of 7 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.80s]
2021-05-01 05:30:49.816687 (Thread-1): Finished running node test.learn_dbt.not_null_my_second_dbt_model_id
2021-05-01 05:30:49.816999 (Thread-1): Began running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:30:49.817559 (Thread-1): 22:30:49 | 4 of 7 START test not_null_sf_customer_purchases_c_custkey........... [RUN]
2021-05-01 05:30:49.818091 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:30:49.818276 (Thread-1): Compiling test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:30:49.822503 (Thread-1): Writing injected SQL for node "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"
2021-05-01 05:30:49.823083 (Thread-1): finished collecting timing info
2021-05-01 05:30:49.823708 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:30:49.823829 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:30:49.823939 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:50.660117 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-05-01 05:30:50.660357 (Thread-1): Using snowflake connection "test.learn_dbt.not_null_sf_customer_purchases_c_custkey".
2021-05-01 05:30:50.660563 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.not_null_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.sf_customer_purchases
where c_custkey is null
2021-05-01 05:30:51.138912 (Thread-1): SQL status: SUCCESS 1 in 0.48 seconds
2021-05-01 05:30:51.139394 (Thread-1): finished collecting timing info
2021-05-01 05:30:51.139590 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:30:51.269540 (Thread-1): On test.learn_dbt.not_null_sf_customer_purchases_c_custkey: Close
2021-05-01 05:30:51.371624 (Thread-1): 22:30:51 | 4 of 7 PASS not_null_sf_customer_purchases_c_custkey................. [PASS in 1.55s]
2021-05-01 05:30:51.371865 (Thread-1): Finished running node test.learn_dbt.not_null_sf_customer_purchases_c_custkey
2021-05-01 05:30:51.372043 (Thread-1): Began running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:30:51.372208 (Thread-1): 22:30:51 | 5 of 7 START test unique_my_first_dbt_model_id....................... [RUN]
2021-05-01 05:30:51.372788 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:30:51.372959 (Thread-1): Compiling test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:30:51.383544 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id"
2021-05-01 05:30:51.384185 (Thread-1): finished collecting timing info
2021-05-01 05:30:51.384926 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:30:51.385042 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: BEGIN
2021-05-01 05:30:51.385150 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:52.112903 (Thread-1): SQL status: SUCCESS 1 in 0.73 seconds
2021-05-01 05:30:52.113087 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id".
2021-05-01 05:30:52.113179 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:30:52.400593 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2021-05-01 05:30:52.401080 (Thread-1): finished collecting timing info
2021-05-01 05:30:52.401282 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: ROLLBACK
2021-05-01 05:30:52.540853 (Thread-1): On test.learn_dbt.unique_my_first_dbt_model_id: Close
2021-05-01 05:30:52.664665 (Thread-1): 22:30:52 | 5 of 7 PASS unique_my_first_dbt_model_id............................. [PASS in 1.29s]
2021-05-01 05:30:52.664925 (Thread-1): Finished running node test.learn_dbt.unique_my_first_dbt_model_id
2021-05-01 05:30:52.665111 (Thread-1): Began running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:30:52.665573 (Thread-1): 22:30:52 | 6 of 7 START test unique_my_second_dbt_model_id...................... [RUN]
2021-05-01 05:30:52.666249 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:30:52.666464 (Thread-1): Compiling test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:30:52.671366 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id"
2021-05-01 05:30:52.671992 (Thread-1): finished collecting timing info
2021-05-01 05:30:52.672944 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:30:52.673216 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: BEGIN
2021-05-01 05:30:52.673358 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:53.493838 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-05-01 05:30:53.494023 (Thread-1): Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id".
2021-05-01 05:30:53.494109 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-05-01 05:30:53.814088 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-05-01 05:30:53.814506 (Thread-1): finished collecting timing info
2021-05-01 05:30:53.814644 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: ROLLBACK
2021-05-01 05:30:54.274889 (Thread-1): On test.learn_dbt.unique_my_second_dbt_model_id: Close
2021-05-01 05:30:54.371979 (Thread-1): 22:30:54 | 6 of 7 PASS unique_my_second_dbt_model_id............................ [PASS in 1.71s]
2021-05-01 05:30:54.372302 (Thread-1): Finished running node test.learn_dbt.unique_my_second_dbt_model_id
2021-05-01 05:30:54.372552 (Thread-1): Began running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:30:54.372820 (Thread-1): 22:30:54 | 7 of 7 START test unique_sf_customer_purchases_c_custkey............. [RUN]
2021-05-01 05:30:54.373267 (Thread-1): Acquiring new snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:30:54.373429 (Thread-1): Compiling test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:30:54.413892 (Thread-1): Writing injected SQL for node "test.learn_dbt.unique_sf_customer_purchases_c_custkey"
2021-05-01 05:30:54.422176 (Thread-1): finished collecting timing info
2021-05-01 05:30:54.432904 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:30:54.440664 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: BEGIN
2021-05-01 05:30:54.441610 (Thread-1): Opening a new connection, currently in state closed
2021-05-01 05:30:55.066744 (Thread-1): SQL status: SUCCESS 1 in 0.63 seconds
2021-05-01 05:30:55.067030 (Thread-1): Using snowflake connection "test.learn_dbt.unique_sf_customer_purchases_c_custkey".
2021-05-01 05:30:55.067188 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "snowflake-test-db", "target_name": "dev", "node_id": "test.learn_dbt.unique_sf_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.sf_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-05-01 05:30:55.546081 (Thread-1): SQL status: SUCCESS 1 in 0.48 seconds
2021-05-01 05:30:55.546460 (Thread-1): finished collecting timing info
2021-05-01 05:30:55.546613 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: ROLLBACK
2021-05-01 05:30:55.738907 (Thread-1): On test.learn_dbt.unique_sf_customer_purchases_c_custkey: Close
2021-05-01 05:30:55.851196 (Thread-1): 22:30:55 | 7 of 7 PASS unique_sf_customer_purchases_c_custkey................... [PASS in 1.48s]
2021-05-01 05:30:55.851460 (Thread-1): Finished running node test.learn_dbt.unique_sf_customer_purchases_c_custkey
2021-05-01 05:30:55.852891 (MainThread): Acquiring new snowflake connection "master".
2021-05-01 05:30:55.853248 (MainThread): 22:30:55 | 
2021-05-01 05:30:55.853398 (MainThread): 22:30:55 | Finished running 7 tests in 11.80s.
2021-05-01 05:30:55.853556 (MainThread): Connection 'master' was properly closed.
2021-05-01 05:30:55.853710 (MainThread): Connection 'test.learn_dbt.unique_sf_customer_purchases_c_custkey' was properly closed.
2021-05-01 05:30:55.859256 (MainThread): 
2021-05-01 05:30:55.859433 (MainThread): Completed successfully
2021-05-01 05:30:55.859559 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-05-01 05:30:55.859730 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11527e100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11354e670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11354e8b0>]}
2021-05-01 05:30:55.859929 (MainThread): Flushing usage events
